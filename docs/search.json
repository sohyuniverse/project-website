[
  {
    "objectID": "reading.html",
    "href": "reading.html",
    "title": "Reading Archive",
    "section": "",
    "text": "By James Ladyman and Karoline Wiesner\nMy final-year MSci project involved the study of a complex system, foreign exchange markets. Each individual currency was treated as a spin in the Ising model, and by applying E.T. Jaynes’s principle of maximum entropy, we discovered the structure of interactions between these entities. Remarkably, this simple model of magnetism can also describe the phase transitions of liquid-gas systems, as they fall into the same universality class. This model has even been extended to study how critical our brain is, giving rise to the field of the critical brain hypothesis. Therefore, many ideas during my research project were derived from neuroscience papers. The financial market and the brain: both are complex systems.\nAbout a year ago, I read a paper published by James Ladyman, a professor of philosophy of science at Bristol, titled ‘What is a Complex System?’ (Ladyman, Lambert, and Wiesner 2013). As I started my PhD at Bristol, my second supervisor, Francesco, mentioned that he also published a book about complexity. It became clear to me that I should read this book.\n\nLadyman, James, James Lambert, and Karoline Wiesner. 2013. “What Is a Complex System?” European Journal for Philosophy of Science 3: 33–67.\nChapter 1 presents The Truisms of Complexity Science as follows:\n1. More is different.\n2. Nonliving systems can generate order.\n3. Complexity can come from simplicity.\n4. Coordinated behaviour does not require an overall controller.\n5. Complex systems are often modelled as networks or information processing systems.\n6. There are various kinds of invariance and forms of universal behaviour in complex systems.\n7. Complexity science is computational and probabilistic.\n8. Complexity science involves multiple disciplines.\n9. There is a difference between the order that complex systems produce and the order of the complex systems themselves.\nFeatures that are necessary and sufficient for which kinds of complexity and complex system are as follows:\n1. Numerosity: complex systems involve many interactions among many components.\n2. Disorder and diversity: the interactions in a complex system are not coordinated or controlled centrally, and the components may differ.\n3. Feedback: the interactions in complex systems are iterated so that there is feedback from previous interactions on a time scale relevant to the system’s emergent dynamics.\n4. Non-equilibrium: complex systems are open to the environment and are often driven by something external.\n5. Spontaneous order and self-organisation: complex systems exhibit structure and order that arises out of the interactions among their parts.\n6. Nonlinearity: complex systems exhibit nonlinear dependence on parameters or external drivers.\n7. Robustness: the structure and function of complex systems is stable under relevant perturbations.\n8. Nested structure and modularity: there may be multiple scales of structure, clustering and specialisation of function in complex systems.\n9. History and memory: complex systems often require a very long history to exist and often store information about history.\n10. Adaptive behaviour: complex systems are often able to modify their behaviour depending on the state of the environment and the predictions they make about it.\n\n2024/9/27\nReading What is a Complex System? by James Ladyman and Karoline Wiesner. The purpose of reading is to understand how systems out of thermodynamic equilibrium (a feature of complex systems) relate to a wide range of concepts associated with complexity.\n• There was a video that helped clarify what is meant by a Markov chain and a stochastic process being stationary: Markov Chains Clearly Explained! Part - 1. His other videos are helpful as well. For example, when I saw \\(P_{ij}^{(n)} = A_{ij}^n\\) from the n-Step Transition Matrix video (Part 3), it was quite surprising. However, the Part 5 video on hidden Markov models wasn’t very helpful, but reading the appendix in the book was sufficient.\n• What I’ve felt from reading this book (currently at p.90) is that it presents a lot of different ideas and has interesting discussions on the history of science, but I only seem to get excited when it starts mentioning the brain. I’m not sure if I’m necessarily interested in quantifying complexity. From the Apple notes on 28/9/2024:\nAs I’m reading through What is a Complex System?, it seems that the description of a complex system arises as we have more representations at different scales of analysis. The concept of ‘complexity’ was destined to arise as the scientific era evolved.\nNon-equilibrium systems arise because we define what systems are in thermodynamic equilibrium, which are idealisations.\nThings that fail to be idealised fall into this dualistic concept: non-equilibrium.\n\n2024/10/3\nIt took about two weeks to finish this book. It was an accessible read until I reached chapter 4, which was Measuring Features of Complex Systems. In the end, I’m glad that I read it, even though I somehow felt rushed to finish as there were other responsibilities to manage continuously, such as setting up clusters for my university Mac, teaching, office setup, etc. Most importantly, from now on, I am going to focus on reading material that is directly related to my project since it may give the impression to my supervisors that I’m not working hard. Reading a book like this takes a long time, as there are many new terms I had not encountered before.\nAnyway, it was a good read. Would I buy a physical copy for myself? Maybe not, but it was a good one.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#what-is-a-complex-system",
    "href": "reading.html#what-is-a-complex-system",
    "title": "Reading Archive",
    "section": "",
    "text": "By James Ladyman and Karoline Wiesner\nMy final-year MSci project involved the study of a complex system, foreign exchange markets. Each individual currency was treated as a spin in the Ising model, and by applying E.T. Jaynes’s principle of maximum entropy, we discovered the structure of interactions between these entities. Remarkably, this simple model of magnetism can also describe the phase transitions of liquid-gas systems, as they fall into the same universality class. This model has even been extended to study how critical our brain is, giving rise to the field of the critical brain hypothesis. Therefore, many ideas during my research project were derived from neuroscience papers. The financial market and the brain: both are complex systems.\nAbout a year ago, I read a paper published by James Ladyman, a professor of philosophy of science at Bristol, titled ‘What is a Complex System?’ (Ladyman, Lambert, and Wiesner 2013). As I started my PhD at Bristol, my second supervisor, Francesco, mentioned that he also published a book about complexity. It became clear to me that I should read this book.\n\nLadyman, James, James Lambert, and Karoline Wiesner. 2013. “What Is a Complex System?” European Journal for Philosophy of Science 3: 33–67.\nChapter 1 presents The Truisms of Complexity Science as follows:\n1. More is different.\n2. Nonliving systems can generate order.\n3. Complexity can come from simplicity.\n4. Coordinated behaviour does not require an overall controller.\n5. Complex systems are often modelled as networks or information processing systems.\n6. There are various kinds of invariance and forms of universal behaviour in complex systems.\n7. Complexity science is computational and probabilistic.\n8. Complexity science involves multiple disciplines.\n9. There is a difference between the order that complex systems produce and the order of the complex systems themselves.\nFeatures that are necessary and sufficient for which kinds of complexity and complex system are as follows:\n1. Numerosity: complex systems involve many interactions among many components.\n2. Disorder and diversity: the interactions in a complex system are not coordinated or controlled centrally, and the components may differ.\n3. Feedback: the interactions in complex systems are iterated so that there is feedback from previous interactions on a time scale relevant to the system’s emergent dynamics.\n4. Non-equilibrium: complex systems are open to the environment and are often driven by something external.\n5. Spontaneous order and self-organisation: complex systems exhibit structure and order that arises out of the interactions among their parts.\n6. Nonlinearity: complex systems exhibit nonlinear dependence on parameters or external drivers.\n7. Robustness: the structure and function of complex systems is stable under relevant perturbations.\n8. Nested structure and modularity: there may be multiple scales of structure, clustering and specialisation of function in complex systems.\n9. History and memory: complex systems often require a very long history to exist and often store information about history.\n10. Adaptive behaviour: complex systems are often able to modify their behaviour depending on the state of the environment and the predictions they make about it.\n\n2024/9/27\nReading What is a Complex System? by James Ladyman and Karoline Wiesner. The purpose of reading is to understand how systems out of thermodynamic equilibrium (a feature of complex systems) relate to a wide range of concepts associated with complexity.\n• There was a video that helped clarify what is meant by a Markov chain and a stochastic process being stationary: Markov Chains Clearly Explained! Part - 1. His other videos are helpful as well. For example, when I saw \\(P_{ij}^{(n)} = A_{ij}^n\\) from the n-Step Transition Matrix video (Part 3), it was quite surprising. However, the Part 5 video on hidden Markov models wasn’t very helpful, but reading the appendix in the book was sufficient.\n• What I’ve felt from reading this book (currently at p.90) is that it presents a lot of different ideas and has interesting discussions on the history of science, but I only seem to get excited when it starts mentioning the brain. I’m not sure if I’m necessarily interested in quantifying complexity. From the Apple notes on 28/9/2024:\nAs I’m reading through What is a Complex System?, it seems that the description of a complex system arises as we have more representations at different scales of analysis. The concept of ‘complexity’ was destined to arise as the scientific era evolved.\nNon-equilibrium systems arise because we define what systems are in thermodynamic equilibrium, which are idealisations.\nThings that fail to be idealised fall into this dualistic concept: non-equilibrium.\n\n2024/10/3\nIt took about two weeks to finish this book. It was an accessible read until I reached chapter 4, which was Measuring Features of Complex Systems. In the end, I’m glad that I read it, even though I somehow felt rushed to finish as there were other responsibilities to manage continuously, such as setting up clusters for my university Mac, teaching, office setup, etc. Most importantly, from now on, I am going to focus on reading material that is directly related to my project since it may give the impression to my supervisors that I’m not working hard. Reading a book like this takes a long time, as there are many new terms I had not encountered before.\nAnyway, it was a good read. Would I buy a physical copy for myself? Maybe not, but it was a good one.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#hydrophobicity-across-length-scales-the-role-of-surface-criticality",
    "href": "reading.html#hydrophobicity-across-length-scales-the-role-of-surface-criticality",
    "title": "Reading Archive",
    "section": "2024/10/4 - Hydrophobicity Across Length Scales: The Role of Surface Criticality",
    "text": "2024/10/4 - Hydrophobicity Across Length Scales: The Role of Surface Criticality\nBy Mary Kathryn Coe\n\nQ1. Resolved\n\n\n\nOn page 35, Chapter 2.1\n\n\nI’m not entirely sure why the surface tension is defined in that way, as it’s normally considered force per unit area. So, I asked ChatGPT:\n\n\nClick to reveal the answer!\n\nThe definition of surface tension in this context is derived from the thermodynamic perspective, which connects surface tension to the grand potential difference between a bulk fluid and a system with an interface. The reasoning follows these steps:\n\nGrand Potential Definition: The grand potential, \\(\\Omega\\), is given by: \\[\n\\Omega = U - TS - \\mu N\n\\] This expression is crucial for systems where particle number and volume are allowed to fluctuate, such as liquid-vapour interfaces.\nSurface Tension from Thermodynamics: Surface tension, \\(\\gamma\\), represents the energy cost per unit area to create an interface. In thermodynamic terms, this corresponds to how much the grand potential increases when introducing an interface between coexisting phases (liquid and vapour).\nDifference between Bulk and Interface: The bulk grand potential, \\(\\Omega_b\\), corresponds to a system without an interface (uniform bulk). When an interface is introduced, the grand potential changes, denoted as \\(\\Omega_{\\text{ex}}\\), the excess grand potential: \\[\n\\Omega_{\\text{ex}} = \\Omega - \\Omega_b\n\\]\nSurface Tension as Excess Grand Potential per Unit Area: The surface tension is then defined as the excess grand potential per unit area, \\(A\\), required to form the interface: \\[\n\\gamma = \\frac{\\Omega_{\\text{ex}}}{A} = \\frac{\\Omega - \\Omega_b}{A}\n\\] This formulation makes sense because surface tension describes the energetic cost to create a unit area of interface between two phases.\n\nIn summary, while surface tension is often discussed in terms of force per unit length in simpler mechanical contexts, in thermodynamics, it is expressed as the excess grand potential per unit area. This ties into how interfaces modify the system’s energy in comparison to the bulk. The two definitions are equivalent but applied in different contexts: mechanical (force/length) vs. thermodynamic (energy/area).\n\n\n\nDerivation of equation 2.1.8, 2.1.9, 2.1.10\n\n\\[\n\\Omega_b(\\mu, V, T) = U - TS - \\mu N = -pV\n\\]\nTaking the differential:\n\\[\nd\\Omega_b = d(U - TS - \\mu N)\n\\]\nUsing the first law of thermodynamics:\n\\[\ndU = TdS - pdV + \\mu dN\n\\]\nDifferentiating \\(TS\\):\n\\[\nd(TS) = TdS + SdT\n\\]\nDifferentiating \\(\\mu N\\):\n\\[\nd(\\mu N) = \\mu dN + N d\\mu\n\\]\nSubstituting these into the differential for \\(\\Omega_b\\):\n\\[\nd\\Omega_b = (TdS - pdV + \\mu dN) - (TdS + SdT) - (\\mu dN + N d\\mu)\n\\]\nSimplifying:\n\\[\nd\\Omega_b = -S_b dT - N_b d\\mu - p dV\n\\]\nFor constant volume (\\(dV = 0\\)), the volume is assumed to remain constant because we are focusing on surface effects rather than bulk volume changes.:\n\\[\nd\\Omega_b = -S_b dT - N_b d\\mu\n\\]\nNow for equation (2.1.6):\n\\[\n\\Omega(\\mu, V, T) = U - TS - \\mu N = -pV + \\gamma A\n\\]\nTaking the differential:\n\\[\nd\\Omega = d(U - TS - \\mu N + \\gamma A)\n\\]\nSubstituting differentials:\n\\[\nd\\Omega = TdS - pdV + \\mu dN - (TdS + SdT) - (\\mu dN + N d\\mu) + \\gamma dA + A d\\gamma\n\\]\nSimplifying:\n\\[\nd\\Omega = -S dT - N d\\mu + \\gamma dA\n\\]\nNow subtract:\n\\[\nd\\Omega - d\\Omega_b = (-S dT - N d\\mu + \\gamma dA) - (-S_b dT - N_b d\\mu)\n\\]\nSimplifying:\n\\[\nd\\Omega - d\\Omega_b = -(S - S_b)dT - (N - N_b)d\\mu + \\gamma dA\n\\]\nThis is equation (2.1.8).\n\nFrom equation (2.1.7):\n\\[\n\\gamma = \\frac{\\Omega_{\\text{ex}}}{A} = \\frac{\\Omega - \\Omega_b}{A}\n\\]\nTaking the differential:\n\\[\nd\\gamma = \\frac{d\\Omega_{\\text{ex}}}{A} = \\frac{d\\Omega - d\\Omega_b}{A}\n\\]\nNow, use the result from equation (2.1.8):\n\\[\nd\\Omega - d\\Omega_b = -(S - S_b) dT - (N - N_b) d\\mu + \\gamma dA\n\\]\nSo:\n\\[\nd\\Omega_{\\text{ex}} = -s_{\\text{ex}} A dT - \\Gamma d\\mu + \\gamma dA\n\\]\nwhere:\n\n\\(s_{\\text{ex}} = \\frac{S - S_b}{A}\\) is the surface excess entropy per unit area,\n\\(\\Gamma = N - N_b\\) is the excess number of particles (adsorption).\n\nDividing through by \\(A\\), we get:\n\\[\n\\frac{d\\Omega_{\\text{ex}}}{A} = -s_{\\text{ex}} dT - \\frac{\\Gamma}{A} d\\mu + \\gamma \\frac{dA}{A}\n\\]\nNow, using the fact that \\(\\gamma \\frac{dA}{A}\\) is small for constant area, we can ignore this term, giving:\n\\[\ns_{\\text{ex}} dT + \\frac{\\Gamma}{A} d\\mu + d\\gamma = 0\n\\]\nThis is equation (2.1.9).\n\nRearrange equation (2.1.9):\n\\[\n\\frac{\\Gamma}{A} d\\mu = -s_{\\text{ex}} dT - d\\gamma\n\\]\nAt constant temperature (\\(dT = 0\\)), this simplifies to:\n\\[\n\\frac{\\Gamma}{A} d\\mu = -d\\gamma\n\\]\nNow, dividing both sides by \\(d\\mu\\), we get:\n\\[\n\\frac{\\Gamma}{A} = -\\left(\\frac{\\partial \\gamma}{\\partial \\mu}\\right)_T\n\\]\nThis is equation (2.1.10).\n\nAnd I need to ask about equations 2.1.11 to 2.1.13, as I cannot find reference [40].\n\n\nQ2. Resolved\n\n\n\nOn page 40, Chapter 2.3\n\n\nI wasn’t sure what the one-particle density is or its use, so I asked ChatGPT:\n\n\nClick to reveal the answer!\n\nThe one-particle density function, often denoted as \\(\\rho^{(1)}(\\mathbf{r})\\), represents the probability density of finding a particle at a specific position \\(\\mathbf{r}\\) in a system of particles. It describes how particles are distributed in space on average and is a key observable in statistical mechanics and the study of fluids.\nThe equation given is:\n\\[\n\\hat{\\rho}^{(1)}(\\mathbf{r}) = \\sum_{j=1}^{N} \\delta(\\mathbf{r} - \\mathbf{r}_j)\n\\]\nThis is the one-particle density operator, and it has the following meaning:\n\nDirac Delta Function: \\(\\delta(\\mathbf{r} - \\mathbf{r}_j)\\) is a Dirac delta function that ‘picks out’ the position of the \\(j\\)-th particle. It is equal to zero everywhere except at \\(\\mathbf{r}_j\\), where it is infinite, ensuring that it integrates to 1. Thus, it counts the presence of a particle at \\(\\mathbf{r}_j\\).\nSummation over All Particles: The sum runs over all particles \\(j\\) from 1 to \\(N\\), so this operator adds up the contributions from all particles in the system, effectively counting the number of particles at position \\(\\mathbf{r}\\).\n\nIn essence, the one-particle density operator \\(\\hat{\\rho}^{(1)}(\\mathbf{r})\\) gives the total number of particles at position \\(\\mathbf{r}\\) in the system. Since it is an operator, the actual one-particle density \\(\\langle \\hat{\\rho}^{(1)}(\\mathbf{r}) \\rangle\\), as defined in equation (2.3.2), is obtained by averaging over all possible configurations of the system in the given ensemble (such as the grand canonical ensemble).\nWhy Does It Look Like This?\nThe form of equation (2.3.1) stems from how we represent the microscopic distribution of particles in space. The Dirac delta function ensures that for each particle, its position contributes to the overall density only at the exact location where that particle exists. This is a standard way to construct density operators in statistical mechanics because:\n\nThe delta function precisely pinpoints the position of a particle.\nSumming over all particles ensures that the density operator accounts for the total number of particles present in the system.\n\nThis representation allows us to describe spatially inhomogeneous systems where the density may vary across different regions (e.g., near a surface or an external potential). For homogeneous fluids, where particles are evenly distributed, this density would reduce to a constant value (the bulk density \\(\\rho_b\\)).\nSummary\nThe one-particle density operator, \\(\\hat{\\rho}^{(1)}(\\mathbf{r})\\), reflects how particles are distributed in space at a microscopic level. The delta functions track the positions of individual particles, and summing over all particles gives the total density at position \\(\\mathbf{r}\\). The actual one-particle density function \\(\\rho^{(1)}(\\mathbf{r})\\) is then the ensemble average of this operator over all configurations of the system.\n\n\n\nQ3. Resolved\n\n\n\nOn page 43, Chapter 2.3\n\n\nI wasn’t sure why each variable is specifically chosen to form those equations. For example, in section 2.4.3, I do not understand why λ can be factored out of g on the right-hand side when λ has two different exponents, a and b. So, I asked ChatGPT:\n\n\nClick to reveal the answer!\n\nStarting with Equation (2.4.3):\n\\[\ng(\\lambda^a u, \\lambda^b v) = \\lambda g(u, v)\n\\]\nThis equation states that the function \\(g(u, v)\\) is a generalised homogeneous function. To understand why it takes this form and why \\(\\lambda\\) appears outside the function on the right-hand side, let’s break this down:\n\nHomogeneous Functions: A function is called homogeneous of degree \\(\\alpha\\) if, when all its arguments are scaled by a factor \\(\\lambda\\), the function itself scales by \\(\\lambda^\\alpha\\). Mathematically, for a homogeneous function \\(f(x, y)\\), we would have: \\[\nf(\\lambda x, \\lambda y) = \\lambda^\\alpha f(x, y)\n\\] This property is common in critical phenomena where we are dealing with power-law behaviour near critical points.\nGeneralised Homogeneous Functions: The function \\(g(u, v)\\) is a generalised homogeneous function because it allows different exponents for different variables. In this case, the variables \\(u\\) and \\(v\\) scale with different exponents \\(a\\) and \\(b\\) under the same scaling factor \\(\\lambda\\).\n\n\\(\\lambda^a u\\): Here, \\(u\\) is scaled by \\(\\lambda^a\\). This implies that \\(u\\) behaves differently under scaling compared to \\(v\\).\n\\(\\lambda^b v\\): Similarly, \\(v\\) is scaled by \\(\\lambda^b\\).\n\nWhy \\(\\lambda\\) can be factored out: The key to understanding why \\(\\lambda\\) can be factored out on the right-hand side despite having different exponents for \\(u\\) and \\(v\\) lies in the definition of a generalised homogeneous function. By construction, we impose that when the variables are scaled in a particular way (with exponents \\(a\\) and \\(b\\)), the function scales by \\(\\lambda\\) itself. This is a property we assign to \\(g(u, v)\\). It doesn’t mean that \\(\\lambda\\) is constant; rather, the entire function \\(g(u, v)\\) is designed to respond to the scaling in this specific manner.\nThe exponents \\(a\\) and \\(b\\) control how \\(u\\) and \\(v\\) individually respond to scaling, but the overall response of the function is to scale as \\(\\lambda\\). The scaling of the function on the right-hand side doesn’t contradict the fact that \\(\\lambda\\) has different exponents inside the arguments. This is simply a mathematical constraint on how the function \\(g(u, v)\\) behaves under scaling.\nIn other words, the form: \\[\ng(\\lambda^a u, \\lambda^b v)\n\\] ensures that the function scales uniformly by \\(\\lambda\\), despite the individual variables scaling differently.\n\nEquation (2.4.4):\nNow, let’s explain how this scaling idea applies to the singular part of the free energy in equation (2.4.4):\n\\[\n\\omega_{\\text{sing}}(\\delta \\mu, t) = \\lambda^{-d} \\omega_{\\text{sing}}(\\lambda^a \\delta \\mu, \\lambda^b t)\n\\]\n\nVariables:\n\n\\(\\delta \\mu = \\mu - \\mu_{\\text{co}}\\) is the difference between the chemical potential \\(\\mu\\) and the critical chemical potential \\(\\mu_{\\text{co}}\\).\n\\(t\\) is the reduced temperature: \\(t = \\frac{T - T_c}{T_c}\\).\n\\(d\\) is the dimensionality of the system (important for scaling relations).\n\nApplying the Scaling Relation: Here, the function \\(\\omega_{\\text{sing}}\\), which represents the singular part of the free energy, is assumed to be a generalised homogeneous function. This means it should follow a scaling law similar to the one introduced in equation (2.4.3).\nThe variables \\(\\delta \\mu\\) and \\(t\\) are scaled by \\(\\lambda^a\\) and \\(\\lambda^b\\), respectively, where \\(a\\) and \\(b\\) are scaling exponents that determine how \\(\\delta \\mu\\) and \\(t\\) change when scaled by \\(\\lambda\\).\nWhy \\(\\lambda^{-d}\\)?\n\nThe factor \\(\\lambda^{-d}\\) appears because we are dealing with free energy, which is an extensive quantity. In thermodynamics, extensive quantities scale with the volume of the system, and in \\(d\\)-dimensional space, the volume scales as \\(\\lambda^d\\). Since we are dealing with the singular part of the free energy, the scaling reflects the dimensionality of the system. The minus sign arises because, under scaling, the free energy decreases as the system grows larger.\n\nThe Free Choice of \\(\\lambda\\): The scaling factor \\(\\lambda\\) is arbitrary, meaning you can choose its value to simplify the equation. In this case, we choose \\(\\lambda^b = t^{-1}\\), which simplifies the second argument (the temperature dependence) of \\(\\omega_{\\text{sing}}\\). By doing this, we reduce the complexity of the equation and make the temperature scaling explicit.\n\nEquation (2.4.5):\nThis equation shows the final form after choosing \\(\\lambda^b = t^{-1}\\):\n\\[\n\\omega_{\\text{sing}}(\\delta \\mu, t) = t^{d/b} \\omega_{\\text{sing}}(t^{-a/b} \\delta \\mu, 1)\n\\]\n\nWhy this form? By setting \\(\\lambda^b = t^{-1}\\), we have scaled out the temperature dependence in the second argument of \\(\\omega_{\\text{sing}}\\). This isolates the temperature dependence into the prefactor \\(t^{d/b}\\), while leaving a scaling function that depends only on the ratio \\(\\delta \\mu / t^{a/b}\\), which is now the only scaling variable.\n\n\\(t^{d/b}\\): This represents how the singular part of the free energy depends on temperature near the critical point. The exponent \\(d/b\\) dictates how strongly the free energy diverges as \\(t \\to 0\\) (the critical point).\n\\(\\Sigma\\left( \\frac{\\delta \\mu}{t^{a/b}} \\right)\\): The function \\(\\Sigma\\) is the scaling function, which encodes the remaining dependence on the scaled chemical potential \\(\\delta \\mu / t^{a/b}\\).\n\n\nIn Summary: - In equation (2.4.3), the exponents \\(a\\) and \\(b\\) control how the variables \\(u\\) and \\(v\\) scale. Despite their different scaling behaviours, the overall function scales by \\(\\lambda\\) because it is designed as a generalised homogeneous function. - In equation (2.4.4), the singular part of the free energy near the critical point follows a similar scaling law, with the dimensionality \\(d\\) appearing as a factor to reflect the extensive nature of free energy. - In equation (2.4.5), we choose \\(\\lambda^b = t^{-1}\\) to simplify the scaling form, making the dependence on temperature explicit and reducing the complexity of the equation. The resulting expression separates the prefactor \\(t^{d/b}\\) and leaves a scaling function that depends only on the ratio \\(\\delta \\mu / t^{a/b}\\), which captures the critical behaviour.\n\n\n\nFluctuations? One correlated entity?\n\nIn the context of phase transitions, particularly near a critical point, the term “fluctuations” refers to fluctuations in the local density of the system. Let’s explain in detail what this means, especially in the context of critical opalescence and long-range correlations.\n\nDensity Fluctuations: When we talk about “density” in this context, we mean the number density of particles in a given volume. In simple terms, it’s how densely packed the particles are in a particular region. The density can fluctuate due to thermal motion, and these fluctuations are typically small and localised in non-critical conditions.\n\nHowever, as a system approaches the critical point of a phase transition (e.g., a liquid-vapour transition), the magnitude of these fluctuations grows dramatically.\n\nWhat happens near the critical point?\n\nCorrelation Length (\\(\\xi\\)): The correlation length \\(\\xi\\) represents the distance over which particles in the system are correlated or “communicate” with each other. Normally, this length is finite, and beyond this distance, the properties of the system in one region do not affect another region.\nNear the critical point, however, \\(\\xi \\to \\infty\\). This means that particles separated by very large distances (even macroscopic scales) are correlated with each other. The entire system essentially becomes one correlated entity.\nDiverging Fluctuations: As the correlation length grows, the fluctuations in the local density (i.e., how many particles are in a given region at any time) also grow larger. This happens because, when the correlation length is large, particles across large distances influence each other. As a result, fluctuations occur over all length scales, from small to very large.\nDensity Fluctuations: Specifically, these are fluctuations in the number of particles in a given volume. Imagine regions in a fluid where the particle density becomes temporarily higher or lower than the average. At the critical point, these fluctuations become very large and occur over very large distances, leading to the system appearing “cloudy” or “milky” — this is the phenomenon of critical opalescence.\n\n\nWhat exactly is fluctuating? At the critical point, density is the key fluctuating quantity, but more generally, the term “fluctuations” can refer to:\n\n\nOrder Parameter Fluctuations: Near a critical point, there is typically an order parameter that characterises the phase transition. For example, in the liquid-vapour transition, this order parameter could be the difference in density between the liquid and vapour phases. As the system approaches the critical point, the fluctuations in the order parameter become large.\nFor example, in a fluid near the liquid-vapour critical point:\n\nIn the liquid phase, particles are densely packed.\nIn the vapour phase, particles are more spread out.\n\nNear the critical point, there is no sharp distinction between liquid and vapour phases. Instead, the system fluctuates between states that resemble both phases. You might see a region that has the density of a liquid next to a region that has the density of a vapour, and these regions appear and disappear rapidly.\n\n\nWhy do these fluctuations occur? At the critical point, the system is in a delicate balance between two phases (e.g., liquid and vapour). The free energy landscape becomes very flat near the critical point, meaning that the system can fluctuate easily between different configurations with very little energy cost. These fluctuations span all length scales, leading to the phenomenon where large regions of the system can fluctuate in density.\nCritical Opalescence: The critical opalescence mentioned in the text is a direct consequence of these large fluctuations in density. Light passing through the fluid is scattered by the density fluctuations. Since the fluctuations occur over a wide range of length scales (from very small to very large), they scatter light across all wavelengths, leading to the “milky” appearance of the fluid near the critical point.\n\n\nWhy does light scatter? Light is scattered by regions of varying density because the refractive index of the fluid depends on its density. When the density fluctuates significantly over large distances, light passing through the fluid encounters regions of different densities, leading to scattering in all directions.\n\nSummary:\n\nWhat is fluctuating near the critical point?: Primarily, the number density (i.e., the number of particles per unit volume) fluctuates near the critical point.\nWhy do these fluctuations grow?: As the correlation length \\(\\xi\\) becomes large, regions of the system separated by large distances become correlated, allowing large-scale fluctuations in density.\nWhat’s the physical manifestation?: These fluctuations lead to observable phenomena such as critical opalescence, where light is scattered by the large fluctuations in density, causing the fluid to appear milky or cloudy.\n\nIn short, the “fluctuations” near the critical point refer to density fluctuations, which are tied to the divergence of the correlation length, and these fluctuations grow larger and affect larger regions of the system as the critical point is approached.\n\n\nFrom chapter 2.4.3, I decided to skim through this document as it became too technical to understand the entire thesis when it began with perturbation theory. Additionally, many concepts here are primarily from equilibrium statistical physics.\n\n\n\n\n\n\nNote\n\n\n\nChapter 2.4.5: Wetting and Drying Phase Transitions is very well written and full of useful knowledge. For the next project meeting, let’s prepare a slide to go over this.\n\n\nWetting and Drying Phase Transitions\nI’ve been reading up to Views of Hydrophobicity, but I realised that I’m not sure how much of the stuff I learn from this thesis is related to active systems. So, I decided to review all articles given by my supervisors.",
    "crumbs": [
      "Project Notes",
      "Reading Archive"
    ]
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Weekly Notes",
    "section": "",
    "text": "View from Brandon Hill\n\n\nWhen we observe clouds appearing at the same height, it’s often due to a phenomenon where a particular layer of the atmosphere has the right conditions for cloud formation. In the troposphere (the lowest layer of the atmosphere), clouds form when the air cools to its dew point, causing water vapour to condense into droplets or ice crystals. This typically happens at specific altitudes where temperature and pressure conditions are ideal for condensation.\nClouds that seem to form at the same height are likely part of the same atmospheric layer, known as a cloud base. The cloud base marks the altitude at which rising air reaches its dew point. If the conditions across the sky are uniform, we’ll see many clouds forming at roughly the same altitude, giving the illusion of a flat layer of clouds.\nCloud formation is fundamentally a non-equilibrium process. It results from dynamic atmospheric conditions like rising air currents, changes in temperature and pressure, and the continuous exchange of energy. These factors drive processes such as condensation and evaporation, which are inherently out of equilibrium. This aligns with the behaviour of active matter systems, where each particle consumes energy to move, keeping the system perpetually out of equilibrium.\nTo create an effective repulsion in our ABP simulations, we consider modifying the wall-fluid interactions to induce a torque that reorients particles away from the surface. One approach might be to introduce an anisotropic interaction potential near the wall. When an ABP approaches the surface, this potential could apply a torque that turns the particle’s propulsion direction away from the wall, effectively reducing its tendency to accumulate there.\n\n\n\nAn idea of beginning the introduction of phase transitions\nThis thesis is ultimately about phase transitions. The central question is: what happens during a transition, for example, from water to ice, from a fluid to a superfluid, or from a paramagnet to a ferromagnet? The physics of such transitions is rich and complex. There are a number of different theoretical tools available to understand them. The study begins by examining thermodynamics and extends to the application of statistical mechanics to these transitions. Additionally, statistical field theory, a fully-fledged field theory similar to what is seen in particle physics or general relativity, will be applied. The goal is to use these approaches, along with concepts of symmetry and other properties, to understand different phases of matter.\nFor a long time, understanding phase transitions was a mystery, especially what’s known as a critical point. It’s an interesting situation: we have something as familiar as water, and it was not until the mid-20th century that significant progress was made. The phase behaviour of water can be examined using a pressure-temperature diagram:\n\n\n\nPhase diagram of water (Cmglee n.d.)\n\nCmglee. n.d. “Phase Diagram of Water Simplified.” https://commons.wikimedia.org/wiki/File:Phase_diagram_of_water_simplified.svg.\n\n\n\nOn the horizontal axis is temperature, and on the vertical axis is pressure.\nThe phase diagram for water features three regions: steam, water, and ice.\nThere’s a point called the triple point, where all three phases coexist, and a critical point, which marks the end of the liquid-gas boundary.\n\nWater is essential, as most of us are mostly water, and yet the physics of what happens at this critical point wasn’t understood for the longest time. It’s a system that is incredibly close to us, yet to understand it requires some of the deepest ideas in physics, particularly the renormalisation group.\nIn this sense, phase transitions form a uniquely positioned subject. They are simultaneously very close to our everyday experience and yet require extremely deep ideas to understand properly. Most other areas of physics are typically far removed from daily life. Quantum mechanics operates on microscopic scales, and astrophysics on cosmological scales, both far from what can be intuitively grasped. But here, some really deep, beautiful puzzles are found in the world around us.\nAn idea of beginning the introduction of renormalisation group\nSo we’re finally at the point now where we can look at the renormalisation group, or RG. We have gathered a bunch of pieces of evidence. Here’s our phase diagram; we have a critical point here. What have we seen near a critical point? We’ve seen that the correlation length goes to infinity; length scales diverge.\nWe’ve also seen the idea of universality, where different systems (for example, the liquid-gas phase transition and the Ising model) are the same. So we’ve observed that the correlation length \\(\\xi\\) goes to infinity, and many systems become similar near the critical point.\nThe renormalisation group is an idea that arises from these two observations. What’s really happening is that at the critical point, the system becomes scale-invariant. Suppose I have a physical system, and these are sort of blobs, say, of up spins or some kind of physical structure. If the correlation length is infinite, there are structures at all length scales. If I zoom out, if I coarse-grain the system, it should look similar. Because if I’m rescaling my system, and if the correlation length is finite, by zooming out, the correlation length of my new system becomes smaller. In my rescaled system, after I’ve zoomed out, things that were on long scales become short scales. As a result, the correlation length, which was on long scales, is now on short scales; the correlations become smaller.\nBut if the correlation length was infinite, when I zoomed out and rescaled my system, it would still look infinite. So what we see is that when I zoom out and rescale my system, I should see the same thing if the correlation length goes to infinity. And what this means immediately is that universality emerges. Because if I do that—if I have a system where I zoom out, rescale, and it looks the same, zoom out, rescale, and it looks the same—near the critical point only, then all the microscopic details of my system just fall away. What I’m left with is some kind of universal theory, a universal theory of physics which doesn’t depend on the details of my model. So the fact that it was a liquid-gas transition or a magnet doesn’t make any difference to me. The only things that matter are the basic ideas of dimensionality and symmetry that underlie the transition, and everything else is irrelevant at the critical point because the correlation length diverges.\nThe renormalisation group is a way to implement this mathematically or in an actual model. So the whole idea is to take your system near criticality, rescale it, and study how it changes under these rescalings. What we hope to find are fixed points of the rescaling—so where you zoom out, and the system looks the same—and these fixed points become critical points of the system. The fixed points of the RG transformations correspond to critical points of the physical system. From this, you can derive the critical exponents from the sort of scaling near the critical points.\nSo this is the idea of the renormalisation group, and you can see how it emerges naturally and explains basically everything. There’s this idea that fluctuations become very important, and the correlation length diverges, and therefore we can look at this rescaling transformation. In this sense, the theory gives us the non-mean-field critical exponents, and we also see this universality emerge.\nSo the renormalisation group is really an idea that ties a lot of puzzles together, a lot of systems together, and it’s sufficiently important that it was awarded a Nobel Prize for pure condensed matter theory, which is a rare achievement for Ken Wilson in the 1970s.\nThat’s the basic idea of the renormalisation group. The problem ultimately with RG is that to implement it in anything other than the simplest of systems is a technical nightmare. It’s extremely difficult, takes a long time, and the results are very hard to obtain. However, people have done that, and it’s correct—it works; it’s just very hard. So that’s the idea, the philosophy of the RG, and it’s one of the most beautiful ideas in theoretical physics.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#week-2",
    "href": "notes.html#week-2",
    "title": "Weekly Notes",
    "section": "",
    "text": "Busy weeks due to starting three teaching modules: Weekly update of my TSR (Teaching Support Roles). Looking back, I wish I could have completed more reading, as there isn’t much to talk about in terms of active matter research for the next project meeting on Monday.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#week-3",
    "href": "notes.html#week-3",
    "title": "Weekly Notes",
    "section": "",
    "text": "View from Brandon Hill\n\n\nWhen we observe clouds appearing at the same height, it’s often due to a phenomenon where a particular layer of the atmosphere has the right conditions for cloud formation. In the troposphere (the lowest layer of the atmosphere), clouds form when the air cools to its dew point, causing water vapour to condense into droplets or ice crystals. This typically happens at specific altitudes where temperature and pressure conditions are ideal for condensation.\nClouds that seem to form at the same height are likely part of the same atmospheric layer, known as a cloud base. The cloud base marks the altitude at which rising air reaches its dew point. If the conditions across the sky are uniform, we’ll see many clouds forming at roughly the same altitude, giving the illusion of a flat layer of clouds.\nCloud formation is fundamentally a non-equilibrium process. It results from dynamic atmospheric conditions like rising air currents, changes in temperature and pressure, and the continuous exchange of energy. These factors drive processes such as condensation and evaporation, which are inherently out of equilibrium. This aligns with the behaviour of active matter systems, where each particle consumes energy to move, keeping the system perpetually out of equilibrium.\nTo create an effective repulsion in our ABP simulations, we consider modifying the wall-fluid interactions to induce a torque that reorients particles away from the surface. One approach might be to introduce an anisotropic interaction potential near the wall. When an ABP approaches the surface, this potential could apply a torque that turns the particle’s propulsion direction away from the wall, effectively reducing its tendency to accumulate there.\n\n\n\nAn idea of beginning the introduction of phase transitions\nThis thesis is ultimately about phase transitions. The central question is: what happens during a transition, for example, from water to ice, from a fluid to a superfluid, or from a paramagnet to a ferromagnet? The physics of such transitions is rich and complex. There are a number of different theoretical tools available to understand them. The study begins by examining thermodynamics and extends to the application of statistical mechanics to these transitions. Additionally, statistical field theory, a fully-fledged field theory similar to what is seen in particle physics or general relativity, will be applied. The goal is to use these approaches, along with concepts of symmetry and other properties, to understand different phases of matter.\nFor a long time, understanding phase transitions was a mystery, especially what’s known as a critical point. It’s an interesting situation: we have something as familiar as water, and it was not until the mid-20th century that significant progress was made. The phase behaviour of water can be examined using a pressure-temperature diagram:\n\n\n\nPhase diagram of water (Cmglee n.d.)\n\nCmglee. n.d. “Phase Diagram of Water Simplified.” https://commons.wikimedia.org/wiki/File:Phase_diagram_of_water_simplified.svg.\n\n\n\nOn the horizontal axis is temperature, and on the vertical axis is pressure.\nThe phase diagram for water features three regions: steam, water, and ice.\nThere’s a point called the triple point, where all three phases coexist, and a critical point, which marks the end of the liquid-gas boundary.\n\nWater is essential, as most of us are mostly water, and yet the physics of what happens at this critical point wasn’t understood for the longest time. It’s a system that is incredibly close to us, yet to understand it requires some of the deepest ideas in physics, particularly the renormalisation group.\nIn this sense, phase transitions form a uniquely positioned subject. They are simultaneously very close to our everyday experience and yet require extremely deep ideas to understand properly. Most other areas of physics are typically far removed from daily life. Quantum mechanics operates on microscopic scales, and astrophysics on cosmological scales, both far from what can be intuitively grasped. But here, some really deep, beautiful puzzles are found in the world around us.\nAn idea of beginning the introduction of renormalisation group\nSo we’re finally at the point now where we can look at the renormalisation group, or RG. We have gathered a bunch of pieces of evidence. Here’s our phase diagram; we have a critical point here. What have we seen near a critical point? We’ve seen that the correlation length goes to infinity; length scales diverge.\nWe’ve also seen the idea of universality, where different systems (for example, the liquid-gas phase transition and the Ising model) are the same. So we’ve observed that the correlation length \\(\\xi\\) goes to infinity, and many systems become similar near the critical point.\nThe renormalisation group is an idea that arises from these two observations. What’s really happening is that at the critical point, the system becomes scale-invariant. Suppose I have a physical system, and these are sort of blobs, say, of up spins or some kind of physical structure. If the correlation length is infinite, there are structures at all length scales. If I zoom out, if I coarse-grain the system, it should look similar. Because if I’m rescaling my system, and if the correlation length is finite, by zooming out, the correlation length of my new system becomes smaller. In my rescaled system, after I’ve zoomed out, things that were on long scales become short scales. As a result, the correlation length, which was on long scales, is now on short scales; the correlations become smaller.\nBut if the correlation length was infinite, when I zoomed out and rescaled my system, it would still look infinite. So what we see is that when I zoom out and rescale my system, I should see the same thing if the correlation length goes to infinity. And what this means immediately is that universality emerges. Because if I do that—if I have a system where I zoom out, rescale, and it looks the same, zoom out, rescale, and it looks the same—near the critical point only, then all the microscopic details of my system just fall away. What I’m left with is some kind of universal theory, a universal theory of physics which doesn’t depend on the details of my model. So the fact that it was a liquid-gas transition or a magnet doesn’t make any difference to me. The only things that matter are the basic ideas of dimensionality and symmetry that underlie the transition, and everything else is irrelevant at the critical point because the correlation length diverges.\nThe renormalisation group is a way to implement this mathematically or in an actual model. So the whole idea is to take your system near criticality, rescale it, and study how it changes under these rescalings. What we hope to find are fixed points of the rescaling—so where you zoom out, and the system looks the same—and these fixed points become critical points of the system. The fixed points of the RG transformations correspond to critical points of the physical system. From this, you can derive the critical exponents from the sort of scaling near the critical points.\nSo this is the idea of the renormalisation group, and you can see how it emerges naturally and explains basically everything. There’s this idea that fluctuations become very important, and the correlation length diverges, and therefore we can look at this rescaling transformation. In this sense, the theory gives us the non-mean-field critical exponents, and we also see this universality emerge.\nSo the renormalisation group is really an idea that ties a lot of puzzles together, a lot of systems together, and it’s sufficiently important that it was awarded a Nobel Prize for pure condensed matter theory, which is a rare achievement for Ken Wilson in the 1970s.\nThat’s the basic idea of the renormalisation group. The problem ultimately with RG is that to implement it in anything other than the simplest of systems is a technical nightmare. It’s extremely difficult, takes a long time, and the results are very hard to obtain. However, people have done that, and it’s correct—it works; it’s just very hard. So that’s the idea, the philosophy of the RG, and it’s one of the most beautiful ideas in theoretical physics.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#week-4",
    "href": "notes.html#week-4",
    "title": "Weekly Notes",
    "section": "Week 4",
    "text": "Week 4\n\n2024/10/8 Analytical Mechanics\nI’ve been watching Tom’s lectures on Analytical Mechanics once more. I’ve just finished part 2. The topics are:\n\nCalculus of variations\nLagrangian mechanics\nHamiltonian mechanics\n\nWhy did I start watching it?\nWell, during the last project meeting, I had a naïve question about whether we could formulate a Lagrangian for the drying scenario. For example, in my supervisor’s papers, they couldn’t manage to observe the drying transition in their setup. So, I asked if, when the trajectory of all particles is away from the surface, we could possibly derive an analytical equation of forces between the particles and the wall to induce torque. Just a pure naïve idea.\nNigel mentioned that the principle of least action makes sense in equilibrium settings, so I had to revise that concept. The Lagrangian is the kinetic energy minus the potential energy, whatever this quantity is. In non-equilibrium systems, energy keeps changing since active agents continuously consume energy. Also, the effective potential depends on the properties of the wall. So, the Lagrangian would become time-dependent, which now makes sense based on what Nigel said.\nThe beautiful theorem was revisited from his lectures: Noether’s theorem.\n\nIf the laws of physics don’t depend on time, energy is conserved.\nSimilarly, if the system has translational or rotational invariance, momentum or angular momentum is conserved, respectively.\n\nThis is beautiful: conserved quantities derive from the symmetries of the system. It also implies that since energy is not conserved for the system I’m interested in, the equations of motion would be time-dependent. I think it would be useful to pay attention to how the equations of motion for active Brownian particles are formulated once I revise their papers.\nAs for his lectures, I’ll continue with part 3 since I’ve already watched the first two. That said, I remember his lecture notes being better than the video recordings, although his video lectures on phase transitions were much more inspiring. So, a note for my future self: when revising the content of the analytical formulation of mechanics, read his lecture notes.\n\n\nPrograms I made\nBefore doing that, I made a Python program that:\n\ndownloads all lectures from Mediasite from the unit I select,\ndetects and removes sections of silence in both the video and audio tracks, applying a buffer of 0.5 seconds before and after each silence to make the transitions smoother,\nsyncs the video and audio together seamlessly to create an mp4 file (the original files were mov, which were almost 10x larger in size),\nkeeps the system active throughout the process by using caffeinate to prevent the computer from going to sleep,\ntracks and reports the download status, ensuring that any interrupted downloads are handled smoothly by automatically updating cookies for authentication,\nensures frame rate consistency to avoid any sync issues that might arise due to different frame rates,\nautomatically manages temporary files created during the silence detection process, keeping the system clean after the task is done.\n\nI’m not sure if I’m allowed to share this code on GitHub, but it was a fun project.\n\n\n\nDownloaded lectures\n\n\nWhy did I make it? Because…\n\nI’ve always felt lazy logging into Blackboard (the university website) every time I wanted to watch videos during my undergraduate years.\nI personally wanted to collect the lectures before they disappeared from the website.\nThere are many pauses in the lectures where the lecturer doesn’t speak while writing equations or words. Removing these pauses also saves total viewing time. Observe the difference:\n\nTotal time to watch all videos of AM (Analytical Mechanics):\n\nAM: 9 hours, 18 minutes, 34 seconds\nProcessed_AM: 8 hours, 23 minutes, 50 seconds\nProcessed_AM (no buffer of 0.5s): 7 hours, 23 minutes, 28 seconds\n\nTotal time to watch all videos of PT (Physics of Phase Transitions):\n\nPT: 11 hours, 42 minutes, 19 seconds\nProcessed_PT: 10 hours, 49 minutes, 18 seconds\nProcessed_PT (no buffer of 0.5s): 9 hours, 45 minutes, 29 seconds\n\nThe buffer is necessary as it makes the transitions feel more natural by introducing a brief pause rather than cutting the silences completely. Watch an example below (duration change: 18:09 (before processing) → 15:29 (after processing with buffers)):\n\n\nVideo\nAM 2.5a Noether’s Theorem\n\n\n\nA beautiful quote from Tom:\nFrom AM 3.4, classical mechanics is the geometry of phase space. All of the geometries (symplectic form, canonical transformations, etc.) describe the phenomenology of classical mechanics.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Project Description",
    "section": "",
    "text": "In terms of the project on ‘Active Drying’, drying is an equilibrium surface phase transition that occurs when a fluid at liquid-vapour coexistence is in contact with an infinite planar substrate that is sufficiently weakly attractive to the fluid particles, such that the vapour phase prefers to be at the substrate. Surface phase transitions can be first-order or critical, and previous results (see [1, 2]) show that drying is generally a critical surface phase transition.\nPrevious work on ABPs has shown that they can exhibit a first-order wetting transition (see [3, 4]). This effect has been investigated by looking at liquid-vapour ‘slabs’ and droplets, showing consistent results. However, the mechanism by which the wetting transition is traversed does not seem to allow for the possibility of a drying transition. To have a chance of observing this, we need to understand the mechanism by which ABPs interact with a surface.\nThe aggregation effect at a hard wall arises because ABPs become trapped at the wall and cannot diffuse away quickly enough. The project will attempt to induce a drying transition by coupling the ABP velocity vector to the wall-fluid interaction in such a way as to produce a torque that creates an effective wall-fluid repulsion, possibly enabling a drying transition. Our task will be to modify a standard MD simulation package to introduce this torque and then proceed similarly to the Turci and Wilding paper in PRL 2021 (see [4]), to try to observe a drying transition. If evidence for this is seen, then we will try to quantify the character of the transition and analyse its critical properties.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#general",
    "href": "index.html#general",
    "title": "Project Description",
    "section": "General",
    "text": "General\nWeekly update of my TSR (Teaching Support Roles)\nDocument search\nClarity portal\nCourses to audit\nMPAGS Training Modules\nPhysics PGR SharePoint site: These pages should provide you with a ‘one-stop-shop’ for all of your PGR needs, including information about progress procedures, forms and examinations.\nMyERP",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#it",
    "href": "index.html#it",
    "title": "Project Description",
    "section": "IT",
    "text": "IT\nACRC HPC Documentation and User Guides\nBuying and borrowing IT\nIntroducing HOOMD-blue: HOOMD-blue is a Python package that performs Molecular Dynamics and hard particle Monte Carlo simulations. HOOMD-blue is general and can be used to model nanoparticles, bead-spring polymers, active matter, and many other types of systems.\nData Science and Research Software Engineering Training\nBDDS Python workshops\nQuarto Tutorial",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Purpose of this Website",
    "section": "",
    "text": "Purpose of this Website\nAs I ended week 2 on the 27th of September, I thought it would be useful to keep track of the following from next week (week 3):\n\nWhat I did every day (mostly bookmarking or a summary)\nA brief summary of what was discussed in project meetings\nThings I hope to discuss or ask in the next project meeting\nUseful resources as links, since I often don’t keep track of what I bookmarked in Safari\n\nAuthor: Sohyun Park\nSupervisors: Prof. Nigel Wilding, Dr. Francesco Turci",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "tutorial-document.html",
    "href": "tutorial-document.html",
    "title": "Quarto Document",
    "section": "",
    "text": "Quarto Document",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Document"
    ]
  },
  {
    "objectID": "tutorial-document.html#colors",
    "href": "tutorial-document.html#colors",
    "title": "Quarto Document",
    "section": "1.1 Colors",
    "text": "1.1 Colors\n\nRed\nGreen\nBlue",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Document"
    ]
  },
  {
    "objectID": "tutorial-document.html#shapes",
    "href": "tutorial-document.html#shapes",
    "title": "Quarto Document",
    "section": "1.2 Shapes",
    "text": "1.2 Shapes\n\nSquare\nCircle\nTriangle",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Document"
    ]
  },
  {
    "objectID": "tutorial-document.html#textures",
    "href": "tutorial-document.html#textures",
    "title": "Quarto Document",
    "section": "1.3 Textures",
    "text": "1.3 Textures\n\nSmooth\nBumpy\nFuzzy",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Document"
    ]
  },
  {
    "objectID": "tutorial-document.html#equations",
    "href": "tutorial-document.html#equations",
    "title": "Quarto Document",
    "section": "1.4 Equations",
    "text": "1.4 Equations\nEinstein’s theory of special relatively that expresses the equivalence of mass and energy:\nE = mc^{2}",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Document"
    ]
  },
  {
    "objectID": "tutorial-document.html#sec-plot",
    "href": "tutorial-document.html#sec-plot",
    "title": "Quarto Document",
    "section": "3.1 Plot",
    "text": "3.1 Plot\n\n\nCode\nimport matplotlib.pyplot as plt\nplt.plot([1,23,2,4])\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3.1: Simple Plot",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Document"
    ]
  },
  {
    "objectID": "tutorial-document.html#sec-equation",
    "href": "tutorial-document.html#sec-equation",
    "title": "Quarto Document",
    "section": "3.2 Equation",
    "text": "3.2 Equation\n\ns = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2}\n\\tag{3.1}",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Document"
    ]
  },
  {
    "objectID": "tutorial-basics.html",
    "href": "tutorial-basics.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "Quarto Basics\nFor a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Basics"
    ]
  },
  {
    "objectID": "tutorial-computations.html",
    "href": "tutorial-computations.html",
    "title": "Quarto Computations",
    "section": "",
    "text": "Quarto Computations",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Computations"
    ]
  },
  {
    "objectID": "tutorial-computations.html#numpy",
    "href": "tutorial-computations.html#numpy",
    "title": "Quarto Computations",
    "section": "NumPy",
    "text": "NumPy\n\n\nCode\nimport numpy as np\na = np.arange(15).reshape(3, 5)\na\n\n\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14]])",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Computations"
    ]
  },
  {
    "objectID": "tutorial-computations.html#matplotlib",
    "href": "tutorial-computations.html#matplotlib",
    "title": "Quarto Computations",
    "section": "Matplotlib",
    "text": "Matplotlib\n\n\nCode\nimport matplotlib.pyplot as plt\n\nfig = plt.figure()\n# fig.set_size_inches(12, 7)\nx = np.arange(10)\ny = 2.5 * np.sin(x / 20 * np.pi)\nyerr = np.linspace(0.05, 0.2, 10)\n\nplt.errorbar(x, y + 3, yerr=yerr, label='both limits (default)')\nplt.errorbar(x, y + 2, yerr=yerr, uplims=True, label='uplims=True')\nplt.errorbar(x, y + 1, yerr=yerr, uplims=True, lolims=True,\n             label='uplims=True, lolims=True')\n\nupperlimits = [True, False] * 5\nlowerlimits = [False, True] * 5\nplt.errorbar(x, y, yerr=yerr, uplims=upperlimits, lolims=lowerlimits,\n             label='subsets of uplims and lolims')\n\nplt.legend(loc='lower right')\nplt.show(fig)\n\n\n\n\n\n\n\n\nFigure 1: Errorbar limit selector",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Computations"
    ]
  },
  {
    "objectID": "tutorial-computations.html#plotly",
    "href": "tutorial-computations.html#plotly",
    "title": "Quarto Computations",
    "section": "Plotly",
    "text": "Plotly\n\nCode\n\"\"\"\nThis allows our figure display to span out beyond the normal body text column.\n#| column: page\n\"\"\"\n\nimport plotly.express as px\nimport plotly.io as pio\ngapminder = px.data.gapminder()\ndef gapminder_plot(year):\n    gapminderYear = gapminder.query(\"year == \" + \n                                    str(year))\n    fig = px.scatter(gapminderYear, \n                     x=\"gdpPercap\", y=\"lifeExp\",\n                     size=\"pop\", size_max=60,\n                     hover_name=\"country\")\n    fig.show()\n    \ngapminder_plot(1957)\ngapminder_plot(2007)\n\n\n\n\n\n\n\n\n\n                                                \n\n\n(a) Gapminder: 1957\n\n\n\n\n\n\n\n\n                                                \n\n\n(b) Gapminder: 2007\n\n\n\n\n\n\n\nFigure 2: Life Expectancy and GDP",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Quarto Tutorial",
      "Quarto Computations"
    ]
  },
  {
    "objectID": "theme.html",
    "href": "theme.html",
    "title": "Theme Showdown",
    "section": "",
    "text": "From a pool of 25 themes, the chosen ones are:\n• default\n• flatly\n• minty\n• sandstone\n• united\n• yeti\nCue the dramatic music…\n\n\n\nRound 1: flatly vs default\nWinner: flatly!\nRound 2: minty vs sandstone\nResult: A tie!\nRound 3: united vs yeti\nWinner: united!\n\n\n\nMatch 1: flatly vs minty\nWinner: flatly (Minty was fresh, but flatly had the edge!)\nMatch 2: united vs sandstone\nWinner: united!\n\n\n\n\nflatly vs united\nWinner: flatly! More professional, less adorable. But honestly, united put up a cute fight.\nFor now, flatly reigns supreme… but united is right there, ready for a rematch.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Theme Showdown"
    ]
  },
  {
    "objectID": "theme.html#semi-finals",
    "href": "theme.html#semi-finals",
    "title": "Theme Showdown",
    "section": "",
    "text": "Match 1: flatly vs minty\nWinner: flatly (Minty was fresh, but flatly had the edge!)\nMatch 2: united vs sandstone\nWinner: united!",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Theme Showdown"
    ]
  },
  {
    "objectID": "theme.html#final-round",
    "href": "theme.html#final-round",
    "title": "Theme Showdown",
    "section": "",
    "text": "flatly vs united\nWinner: flatly! More professional, less adorable. But honestly, united put up a cute fight.\nFor now, flatly reigns supreme… but united is right there, ready for a rematch.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Theme Showdown"
    ]
  },
  {
    "objectID": "notes.html#introduction",
    "href": "notes.html#introduction",
    "title": "Hydrophobicity Across Length Scales: Wetting and Drying Phase Transitions",
    "section": "Introduction",
    "text": "Introduction\nIn this presentation, we explore the theoretical underpinnings of hydrophobicity by examining wetting and drying phase transitions. The phenomena are driven by surface tension and critical temperature scaling, providing insights into surface phase transitions across different substrates.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#youngs-equation",
    "href": "notes.html#youngs-equation",
    "title": "Hydrophobicity Across Length Scales: Wetting and Drying Phase Transitions",
    "section": "Young’s Equation",
    "text": "Young’s Equation\nConsider a droplet of liquid on a surface. The contact angle, denoted as θ, quantifies the affinity between the liquid and the surface. This angle is determined by resolving the surface tensions of the interfaces involved. The relationship is given by Young’s equation:\n\\[\n\\cos \\theta = \\frac{\\gamma_{sv} - \\gamma_{sl}}{\\gamma_{lv}} \\tag{1}\n\\]\nWhere: - \\(\\gamma_{sv}\\) is the surface-vapour tension - \\(\\gamma_{sl}\\) is the surface-liquid tension - \\(\\gamma_{lv}\\) is the liquid-vapour tension\n\nHydrophobic vs Hydrophilic\n\nHydrophobic surfaces: \\(90^\\circ &lt; \\theta &lt; 180^\\circ\\)\nHydrophilic surfaces: \\(0^\\circ &lt; \\theta &lt; 90^\\circ\\)\n\nAt two extremes: - \\(\\theta = 0^\\circ\\): Full wetting. - \\(\\theta = 180^\\circ\\): Perfect drying.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#surface-phase-transitions",
    "href": "notes.html#surface-phase-transitions",
    "title": "Hydrophobicity Across Length Scales: Wetting and Drying Phase Transitions",
    "section": "Surface Phase Transitions",
    "text": "Surface Phase Transitions\nThe approach to the two limiting cases represents surface phase transitions—wetting for \\(\\theta = 0^\\circ\\) and drying for \\(\\theta = 180^\\circ\\).\n\nCahn’s Scaling Law\nCahn’s theory explains the scaling behaviour of surface tensions as the critical temperature \\(T_c\\) is approached. The surface tension vanishes following the power law:\n\\[\n\\gamma_{lv} \\sim (-t)^\\mu \\quad \\text{with} \\quad \\mu = (d-1)\\nu\n\\]\nFor a fluid with \\(d = 3\\), the critical exponent is \\(\\nu \\approx 0.63\\), yielding \\(\\mu \\approx 1.26\\).\n\n\nContact Angle Near \\(T_c\\)\nAs \\(T_c\\) is approached, the contact angle vanishes:\n\\[\n\\cos \\theta \\sim t^{\\beta - \\mu} \\quad \\text{with} \\quad \\beta \\approx 0.33\n\\]\nThus, \\(\\cos \\theta\\) diverges as \\(t^{-0.93}\\), but is constrained to \\(|\\cos \\theta| \\leq 1\\).",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#wetting-and-drying-transitions",
    "href": "notes.html#wetting-and-drying-transitions",
    "title": "Hydrophobicity Across Length Scales: Wetting and Drying Phase Transitions",
    "section": "Wetting and Drying Transitions",
    "text": "Wetting and Drying Transitions\nThe phase transition occurs at a specific temperature: - Wetting occurs at \\(T_W\\), where \\(\\cos \\theta = 1\\). - Drying occurs at \\(T_D\\), where \\(\\cos \\theta = -1\\).\nAt these temperatures, a macroscopic layer of liquid or vapour forms at the surface.\n\nCritical vs First-Order Transitions\nThe nature of these transitions can be: - Critical: The equilibrium film width \\(\\ell_{eq}\\) grows continuously as \\(T_D\\) is approached. - First-order: The film width jumps discontinuously.\nBelow are illustrations of critical and first-order transitions for drying:\n\n# Insert visual figure using code or links to diagrams",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#predrying-transitions",
    "href": "notes.html#predrying-transitions",
    "title": "Hydrophobicity Across Length Scales: Wetting and Drying Phase Transitions",
    "section": "Predrying Transitions",
    "text": "Predrying Transitions\nIn systems undergoing first-order drying, predrying can occur at temperatures \\(T &gt; T_D\\). In this case, the vapour film transitions from a thin to a thick layer before the full drying transition at \\(T_D\\).\n\nScaling Behaviour\nThe equilibrium film width \\(\\ell_{eq}\\) exhibits different behaviours depending on the order of the transition:\n\\[\n\\ell_{eq} = \\frac{-\\Gamma}{A_{sv} \\Delta \\rho}\n\\]\nWhere: - \\(\\Gamma\\) is the adsorption - \\(A_{sv}\\) is the surface area of the substrate-vapour interface - \\(\\Delta \\rho = \\rho_l - \\rho_v\\) is the difference between the liquid and vapour densities",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#conclusion",
    "href": "notes.html#conclusion",
    "title": "Hydrophobicity Across Length Scales: Wetting and Drying Phase Transitions",
    "section": "Conclusion",
    "text": "Conclusion\nWetting and drying phase transitions provide critical insights into the behaviour of hydrophobic and hydrophilic surfaces. These transitions are influenced by surface tension, temperature, and the nature of interactions between fluid and substrate. Theoretical models such as Cahn’s scaling law and simulation studies guide our understanding of these phenomena.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#references",
    "href": "notes.html#references",
    "title": "Hydrophobicity Across Length Scales: Wetting and Drying Phase Transitions",
    "section": "",
    "text": "A beautiful quote from Tom:\nFrom AM 3.4, classical mechanics is the geometry of phase space. All of the geometries (symplectic form, canonical transformations, etc.) describe the phenomenology of classical mechanics.\n2024/10/12 Making a presentation\nIntroduction\nIn this presentation, I’m going to explain the theoretical foundations of hydrophobicity by examining wetting and drying phase transitions. The phenomena are driven by surface tension and critical temperature scaling.\nYoung’s Equation\nConsider a droplet of liquid on a surface. The contact angle, denoted as θ, quantifies the affinity between the liquid and the surface. This angle is determined by resolving the surface tensions of the interfaces involved. The relationship is given by Young’s equation:\n\\[\n\\cos \\theta = \\frac{\\gamma_{sv} - \\gamma_{sl}}{\\gamma_{lv}} \\tag{1}\n\\]\nWhere: - \\(\\gamma_{sv}\\) is the surface-vapour tension - \\(\\gamma_{sl}\\) is the surface-liquid tension - \\(\\gamma_{lv}\\) is the liquid-vapour tension\nHydrophobic vs Hydrophilic\n\nHydrophobic surfaces: \\(90^\\circ &lt; \\theta &lt; 180^\\circ\\)\nHydrophilic surfaces: \\(0^\\circ &lt; \\theta &lt; 90^\\circ\\)\n\nAt two extremes:\n\n\\(\\theta = 0^\\circ\\): Full wetting.\n\\(\\theta = 180^\\circ\\): Perfect drying.\n\nSurface Phase Transitions\nThe approach to the two limiting cases represents surface phase transitions—wetting for \\(\\theta = 0^\\circ\\) and drying for \\(\\theta = 180^\\circ\\).\nCahn’s Scaling Law\nCahn’s theory explains the scaling behaviour of surface tensions as the critical temperature \\(T_c\\) is approached (see: (Cahn 1977)). The surface tension vanishes following the power law:\n\\[\n\\gamma_{lv} \\sim (-t)^\\mu \\quad \\text{with} \\quad \\mu = (d-1)\\nu\n\\]\nFor a fluid with \\(d = 3\\), the critical exponent is \\(\\nu \\approx 0.63\\), yielding \\(\\mu \\approx 1.26\\).\nContact Angle Near \\(T_c\\)\nAs \\(T_c\\) is approached, the contact angle vanishes:\n\\[\n\\cos \\theta \\sim t^{\\beta - \\mu} \\quad \\text{with} \\quad \\beta \\approx 0.33\n\\]\nThus, \\(\\cos \\theta\\) diverges as \\(t^{-0.93}\\), but is constrained to \\(|\\cos \\theta| \\leq 1\\).\nWhy \\(\\beta - \\mu\\)?\nNear the critical temperature, both \\(\\gamma_{sv}\\) and \\(\\gamma_{sl}\\) vanish. As \\(T\\) approaches \\(T_c\\), \\(\\gamma_{lv}\\) tends to zero as \\((-t)^\\mu\\). The numerator \\(\\gamma_{sv} - \\gamma_{sl}\\) scales with the order parameter difference \\(\\Delta \\rho = \\rho_l - \\rho_v\\), because the distinction between liquid and vapour phases diminishes. This gives:\n\\[\n\\gamma_{sv} - \\gamma_{sl} \\sim (-t)^\\beta\n\\]\nBy substituting the scaling behaviours of \\(\\gamma_{lv}\\) and \\(\\gamma_{sv} - \\gamma_{sl}\\) into Young’s equation, we get:\n\\[\n\\cos \\theta \\sim \\frac{(-t)^\\beta}{(-t)^\\mu} = t^{\\beta - \\mu}\n\\]\nWetting and Drying Transitions\nThe phase transition occurs at a specific temperature:\n\nWetting occurs at \\(T_W\\), where \\(\\cos \\theta = 1\\).\nDrying occurs at \\(T_D\\), where \\(\\cos \\theta = -1\\).\n\nAt these temperatures, a macroscopic layer of liquid or vapour forms at the surface.\nCritical vs First-Order Transitions\nThe nature of these transitions can be:\n\nCritical: The equilibrium film width \\(\\ell_{eq}\\) grows continuously as \\(T_D\\) is approached.\nFirst-order: The film width jumps discontinuously.\n\nBelow are illustrations of critical and first-order transitions for drying:\n\nPredrying Transitions\nIn systems undergoing first-order drying, predrying can occur at temperatures \\(T &gt; T_D\\). In this case, the vapour film transitions from a thin to a thick layer before the full drying transition at \\(T_D\\).\nScaling Behaviour\nThe equilibrium film width \\(\\ell_{eq}\\) exhibits different behaviours depending on the order of the transition:\n\\[\n\\ell_{eq} = \\frac{-\\Gamma}{A_{sv} \\Delta \\rho}\n\\]\nWhere:\n\n\\(\\Gamma = \\int \\mathrm{d}r \\, [\\rho(r) - \\rho_b]\\) is the adsorption, which describes the excess of fluid near the surface relative to the bulk.\n\\(A_{sv}\\) is the surface area of the substrate-vapour interface\n\\(\\Delta \\rho = \\rho_l - \\rho_v\\) is the difference between the liquid and vapour densities\n\nFor \\(\\rho(r)\\), we know from the statistical mechanics of fluids that the one-particle density \\(\\rho^{(1)}(r)\\) can be written in the form of an ensemble average.:\n\\[\n\\langle \\hat{\\rho}^{(1)}(r) \\rangle = \\frac{1}{\\Xi} \\sum_{j=1}^\\infty \\frac{e^{\\beta \\mu N}}{\\Lambda^{3N}(N-1)!} \\int \\mathrm{d}r^{N-1} e^{-\\beta[\\Phi(r^N) + V_{\\text{ext}}(r^N)]}\n\\]\nThis defines the fluid’s spatially varying density at a microscopic level.\n\n\n\n\n\n\n\n\nCahn, John W. 1977. “Critical Point Wetting.” The Journal of Chemical Physics 66 (8): 3667–72.\n\n\nCmglee. n.d. “Phase Diagram of Water Simplified.” https://commons.wikimedia.org/wiki/File:Phase_diagram_of_water_simplified.svg.",
    "crumbs": [
      "Project Notes",
      "Hydrophobicity Across Length Scales: Wetting and Drying Phase Transitions"
    ]
  },
  {
    "objectID": "reading.html#colloquium-inclusions-boundaries-and-disorder-in-scalar-active-matter",
    "href": "reading.html#colloquium-inclusions-boundaries-and-disorder-in-scalar-active-matter",
    "title": "Reading Archive",
    "section": "2024/10/14 - Colloquium: Inclusions, boundaries, and disorder in scalar active matter",
    "text": "2024/10/14 - Colloquium: Inclusions, boundaries, and disorder in scalar active matter\nThree different models of active matter are discussed here: ABP (active Brownian particles), RTP (run-and-tumble particles), and AOUP (active Ornstein-Uhlenbeck particles). ABP is a model that I’m going to investigate initially because it’s the simplest particle model, but I want to be aware that there are other models. From page 3, what is interesting is this, since I saw somewhere that detailed balance doesn’t hold for non-equilibrium systems:\n\n\n\n\n\n\nNote\n\n\n\nOn the contrary, in a harmonic potential AOUPs always have a steady state given by a centered Gaussian distribution (Szamel, 2014) and, somewhat surprisingly, their dynamics obey detailed balance (Fodor et al., 2016).\n\n\nI wanted to revisit the detailed balance algorithm more deeply, so I started reading Understanding Molecular Simulation.",
    "crumbs": [
      "Project Notes",
      "Reading Archive"
    ]
  },
  {
    "objectID": "notes.html#week-5",
    "href": "notes.html#week-5",
    "title": "Weekly Notes",
    "section": "Week 5",
    "text": "Week 5\n\n2024/10/17 Summary of project meetings so far\n\n\nPre-PhD discussions with Nigel\n\nSelf-propelled particles are a big topic at the moment. Many researchers are interested in active matter, which is different from passive matter, the subject we mostly learn about in our undergraduate studies of statistical mechanics. Statistical mechanics is a beautiful way of describing systems with a vast number of components. When we have an Avogadro number of components, we cannot expect to write down the equations of motion for each one and solve them because there are simply too many. Instead, we have to step back and ask, “What can we say about the averages and the fluctuations?” People like Boltzmann and Gibbs gave us a great theory for understanding equilibrium statistical mechanics. Now, we want to move beyond that to study non-equilibrium systems.\nPhysicists want to have simple models that capture the essential elements of the real systems they are studying. We start with basic models, like self-propelled particles. Francesco and Nigel have been studying these, and they are fascinating. For example, purely repulsive particles in an equilibrium system would not exhibit much behaviour. They do not have a liquid-vapour transition because attraction is required for condensation from vapour into liquid. Purely repulsive particles can crystallise, but they do not exhibit a liquid-vapour transition.\nHowever, if we take those same purely repulsive particles and make them self-propelling, a liquid-vapour transition suddenly emerges. This is an example of how interactions between many simply interacting bodies can lead to large-scale emergent properties. These active Brownian particles, which are self-propelled and repulsive, show this phase transition into a liquid-vapour phase. This is not just about bulk phase transitions but also about what happens at surfaces. How do they interact with a surface? Can phase transitions occur at a surface, such as wetting or drying transitions?\nThese are very new areas of research. Francesco and Nigel have been exploring some of these questions, and their recent papers reflect that. They realise there are many interesting directions this research could take. One of the main tools here, since we do not have advanced theories like those for equilibrium systems, is computer simulation. We are fortunate to have great high-performance computing resources in Bristol. Some of these problems need high performance, as they require large systems with many particles.\nAnother area Nigel is interested in is hydrophobic interactions. We have particles that are either entirely hydrophobic or amphiphilic, meaning they have both hydrophobic and hydrophilic parts. These particles can self-assemble into large-scale structures, but there are still aspects of that process that are not well understood. For instance, it is known experimentally that heating amphiphiles promotes self-assembly. Normally, heating increases disorder, so why is it different here? What is happening with hydrophobic or amphiphilic interactions that leads to this interesting temperature dependence? This is not well understood at the moment, and it is an open question that he hopes to address soon using computer simulation.\nHe thinks there may be other factors at play here, relating to surface phase transitions. They have made some progress in understanding how water behaves at a planar surface, like a hydrophobic planar surface. That behaviour is essentially the physics of a drying transition. All these things are connected. Applying our understanding of what happens at a planar surface to hydrophobic entities like solute particles, molecules, amphiphiles, or proteins brings basic physics closer to biological systems and non-equilibrium systems. This is an exciting area because it links traditional equilibrium phase transition concepts to how nature exploits them for function.\nProfessor Paul Bartlett in the chemistry department also works in this area, conducting colloidal experiments. Colloids are used in a range of industrial products, such as paints, shampoos, personal care products, and foodstuffs. They are important in the industry, but making new products with new functionality is challenging because these products are often mixtures of many different components. The space of possible combinations is enormous, making it difficult to determine the right mix to achieve a desired property.\nThe question is whether simulation, something like digital twins, can help us find useful mixtures more efficiently and avoid trial-and-error. Much of what happens now is trial and error. If we could create a digital twin or simulation based on real data, it could guide us. AI and neural networks could be used to incorporate real data into simulations, teaching the system the interactions between the components to reproduce real behaviour. Then, we could explore new directions, new types of mixtures, or new areas of phase space more quickly and at lower cost.\nWe are still some way from that goal, but he believes we are ready to take the first steps in that direction. Simulations with an AI or neural network overlay, which learn how to reproduce experimental data, would be the first step.\nRegarding the specific project, how do active Brownian particles interact with a surface? What if that surface is flexible, like a lipid membrane, or penetrable so that the particles can pass through it like a thin membrane? We want to study these systems through simulation and use our knowledge of statistical physics to understand them.\nIt is not biology, but it is not far removed. There are many exciting aspects to explore, but the focus will be on a simulation approach. One attractive feature of statistical physics is the abundance of problems to choose from, allowing researchers to make real progress, often with just one or two people. In particle physics or astrophysics, researchers are often part of large collaborations and do not have the freedom to determine the direction of the research. Success in such fields is shared among many, whereas in our field, a small number of people can have a significant impact, giving more freedom and satisfaction. Some of the work may be patented, but most of it is published in the open literature, with your name at the top, not among a thousand others. You really feel that your contribution is valued.\nFor active Brownian particles, we use a method called Brownian Dynamics. It is similar to Molecular Dynamics, but for passive particles in equilibrium, Molecular Dynamics is quite straightforward. We calculate all the forces; every particle interacts via some potential, and we determine the force on each particle due to the others it interacts with. Then, we integrate the equations of motion, Newton’s equations, through time.\nEssentially, we evolve the particle positions through time in a stepwise manner. We increase time from T to T+ΔT and determine where all the particles will be, then iterate and repeat this process. The particles move around the system according to Newton’s equations of motion, making it physically realistic.\nFor active Brownian particles, in addition to the passive interactions between the particles, each particle experiences a driving force along a specific direction, which we represent as an arrow. In the case of Janus particles, this driving force may be due to a chemical reaction, such as with peroxide, which creates movement along a particular vector. Because of interactions with other particles, this vector diffuses over time, and we treat this stochastically using random numbers. Like in Molecular Dynamics, we advance the system in time steps, but we also add a random displacement to the driving force. At each time step, the arrow may point in a slightly different direction, and the force acts along that direction. The dynamics of the system result from both the passive interaction forces between the particles and the driving force, which can diffuse over time. This is the algorithm we use, known as Active Brownian Dynamics.\nThe term “Brownian” refers to the diffusion of the force vector for each particle. The programs for these simulations are quite simple. We do not always need to write our own from scratch, as some major Molecular Dynamics packages can handle this for us. In some cases, we can use pre-existing, optimised community codes that are efficient, fast, and parallelised. However, we often do specialised work that requires writing our own code, so there is plenty of opportunity to develop custom code as well.\nActive Brownian Dynamics is distinct from Monte Carlo methods, which are mainly used for equilibrium systems. Unlike Molecular Dynamics, which evolves the system according to Newton’s equations of motion, Monte Carlo does not produce realistic dynamics. In Monte Carlo simulations, the transition from one configuration of particles to the next is not physically realistic, but the generated configurations are correctly distributed according to their Boltzmann weights in terms of free energy. Monte Carlo is used to generate equilibrium-distributed configurations from which we can measure various properties, but it does not provide dynamical information.\nMonte Carlo methods are very efficient at generating different, uncorrelated configurations because they allow for large jumps between configurations, exploiting fictitious dynamics. In contrast, Molecular Dynamics or Active Brownian Dynamics involve gradual changes, making it more like a shuffle that takes longer to reach a completely different configuration. Monte Carlo methods enable much larger leaps, making them more efficient at collecting uncorrelated statistics.\nMonte Carlo is better at exploring phase space. Nigel has spent much of his career developing algorithms to explore new areas in configuration space. For example, to study the phase transition from a liquid state to a crystal state, where particles arrange on a lattice, it is difficult to determine the parameters at which the transition occurs using Molecular Dynamics because of effects like hysteresis. One of the innovations he developed for Monte Carlo was a method that, instead of gradually nucleating a crystal and letting it grow, jumps completely from a fluid configuration to a crystal configuration in a single move. This approach, called “Phase Switch Monte Carlo”, allows the system to explore each state and then jump back, enabling the calculation of free energy differences and the precise determination of coexistence points.\nThis is the sort of technique that makes Monte Carlo powerful, something Molecular Dynamics cannot easily do. Different phenomena require different techniques. If we are interested in dynamics, we need one technique; if we are interested in phase transitions between very different structures, we need another. The lack of symmetry is what makes these problems challenging. By exploiting fictitious dynamics in Monte Carlo, we can map a liquid configuration onto a solid configuration, even though this cannot physically occur in reality. In practice, a small region would nucleate and grow into a crystal, eventually filling the entire simulation box. If we are only interested in the coexistence conditions, then Monte Carlo is far more powerful.\nI have enjoyed Tom’s phase transitions course, which introduced many important ideas. It covered models of phase transitions, Landau theory, and aspects of the renormalisation group. It also discussed the different ensembles, the relationship between the system and its surroundings, and the various free energies relevant to each case.\n\nSupervisor: The other thing that may drive you—okay, this is different. This is morphogenesis. This concept dates back to the 19th century. It’s related to mathematical physics. The question is, how does shape emerge? At that time, it typically boiled down to geometries. But then, it’s not always just geometry. What I want to say is, if you are interested in biological motivation or the connection between physics and biology, that’s another possibility—taking the angle of active matter as a model for biological systems.\nWe’re not direct experts in this, but we have connections that we could explore if you’re interested in linking the theoretical approach to some kind of experimental test. That’s always possible. The last angle is linking artificial systems, like robots. In Bristol, there’s a big robotics centre—actually, the largest nationwide—the Bristol Robotics Laboratory. It’s a collaboration between us and the University of the West of England (UWE), but it’s not here on this campus; it’s at the UWE campus.\nThere are researchers here who do this as well. The most famous, at least relevant to my interests, is Sabine Hauert. You will see she has a series of TED Talks. If you watch them, you’ll get a sense of what she does. She’s interested in swarm robotics. There’s a very small step between what she does and what we’re discussing. I don’t know if all her talks are available online—there should be plenty of material. Watching them might give you a sense of the kinds of things they do.\nSwarm robotics, in many ways, aligns with what we’re doing in active matter. It’s just at a different scale. They study behaviours from the very small—the microscopic level—all the way to larger scales. For example, they have projects involving drug delivery. You can say that this would be a kind of morphogenesis. These are actual videos of “kilobots,” which are two-dimensional systems made up of many small robots. They have limited sensing but can communicate.\nIn the systems we study, there’s no direct communication like that; there’s not even inherent activity in the same way. However, with swarms, they study how collective behaviour and communication can lead to emergent properties. Even in engineering, they’re already thinking in terms that we consider in physics. Our role is to support them with a somewhat broader picture.\nWhat we do now is provide model systems, classes of problems, and minimal models. That’s what we can contribute from the physics side. We try to reduce the complexity and say, “If you perturb these few ingredients, you have this space of parameters that opens into different phases—maybe phase transitions or some kind of controlled behaviour.” That’s what we can do as physicists.\nTypically, engineers aren’t interested in that level of abstraction. They say, “I have all these parameters; I perturb them, and this is what happens.” We try to provide a coherent picture. However, there is the possibility of collaborating. We can take some generic problems that have the potential to interface with biology, engineering, and other aspects of physics.\nIt also depends on whether you want to go for a more theoretical or more applied angle. We can start with the theoretical basics to get the foundation covered, and then we can move in different directions later. It’s really a matter of seeing what your driving interest is. If you’re not sure, we’ll provide you with an initial exploratory project to work on. This will give you the opportunity to identify what aspect you find the most interesting and would like to pursue for the next couple of years.\nIf you wanted to, there would be the opportunity to engage with this. For instance, there’s no issue in asking Sabine, “We have this good PhD student who is interested in testing her results in the field.” I managed to set up the kilobots, saw them moving around. It wasn’t very exciting, but it was doable. If I can do it, you can do it too.\nI’ve already chatted with Sabine because I’ll have a PhD student myself next year or the following year, beyond you. The idea is to set up multiple projects in that direction. She’s interested, so if swarms are a topic that interests you, we can have an interdisciplinary project in that direction. That wouldn’t be hard to arrange.\nSupervisor: So, entropy is not just disorder, okay? This notion of entropy as disorder is a popular message that simplifies a lot of the storytelling around statistical mechanics. The classical example that we often give in this department is that if you take only hard spheres—a purely repulsive system—there is no energy, right, apart from infinite energy when they overlap. So, the energy is always zero because all the acceptable configurations are at zero energy. Then, the free energy is only entropic, just entropy.\nYou might think, “Okay, with only entropy, you will just have disorder.” That would be the natural assumption. In this simple system, there’s no kind of interaction, just hard spheres. However, what you actually observe is that if you increase the density of such systems, you spontaneously observe a transition from a fluid to a crystal.\nYou: Really?\nSupervisor: Yes, you spontaneously observe this transition. The crystal that forms is essentially FCC-like (face-centred cubic). So somehow, even though this system is maximising entropy—because there is only entropy involved—it results in an ordered state at these very high densities. This occurs because the crystal packing is better, so every single sphere has a little bit of extra wiggle room, more local configurations. The effective volume accessible to each sphere is larger, even though they are in an ordered configuration.\nSo, you can obtain crystalline order by maximising entropy. It’s quite counterintuitive. You would think that maximising entropy means just getting disorder and taking the system very far away from any kind of ordered pattern. But in fact, no. If you take this simplest system, it goes into the most obvious ordered state—a crystal—by maximising entropy.\nThis idea that entropy equals disorder is just a story we tell that simplifies things. Entropy can take you in many different directions; it’s not just disorder. It means the choice of possible states is broader than what you may think initially. Entropic interactions do not necessarily lead to disorder; on the contrary, they can lead to packing, to crystallisation, and so on.\nYou: Interesting. How does this relate to active systems?\nSupervisor: In the case of active systems, this construction becomes even further apart. Energy is there, but it is not the only relevant force. You have these intrinsic forces in such systems, so they cannot be written directly in the same form. The notion of accessible states, the statistical nature of entropy, can still come back if you have at least steady states. The free energy becomes more about the log of the probability distribution, as you’ve seen in your project.\nYour project was all equilibrium, but not really. The financial data was some kind of steady state; you assumed some steady state. All this is to say that, for example, self-assembly in biological systems—biological molecules or macromolecules—yes, it is driven by free energies, at least in our picture, because you have some solvent, and they tend to minimise the free energy. But the energy landscape is very complicated due to this competition between many different states that entropy actually can favour.\nThese states are not necessarily disordered; they are just different from the ones that energy alone would pull toward. The main picture here is that not all of the rest is disorder. It’s essentially about simple basins versus complex basins in free energy. That’s the problem, for example, in protein folding. The free energy landscape is very structured, not just because of the energy, but also because of all the possibilities that entropy adds to it. It’s not just about misfolding—all the different configurations represent different structures.\nYou: I’m curious about how life emerges. That’s the question I want to answer.\nSupervisor: If you want to narrow it down to something that’s researchable, maybe you want to clarify—emerges from what, under what conditions? Maybe imagine a particular setup. This kind of problem, for example, has been tackled here in chemistry by taking the approach of constructing proto-cellular structures from purely synthetic components. It’s sort of a bottom-up approach, asking, “If I add this, this, and this ingredient, how far can I go?”\nThis is the group of Professor Stephen Mann. They are quite successful and have managed to produce very plausible membrane-like structures that assemble similarly to how natural membranes do. From our point of view in physics, it means many different things. The active matter angle is more about how, for example, morphogenesis occurs—not how life itself emerges, but how patterns in biological structures emerge. This is a related question but leans more towards mathematical and physical understanding.\nFor instance, you could try to cast it into a set of partial differential equations. I was trying to reproduce a paper on this topic recently. It’s fascinating because this isn’t active matter at all; it’s simply a set of differential equations. The study focuses on diatoms—not diatomic molecules, but little organisms that produce intricate shells. The paper attempts to create a minimal model that can manifest similar patterns.\nWhat they do is take the obvious route: they write down a partial differential equation, essentially a reaction-diffusion model. Turing demonstrated that with suitable parameters, these models break into bifurcation-like phenomena, leading to pattern formation. They explore their model by selecting certain initial conditions and letting the system evolve, showing how various patterns emerge.\nYou: Is this computationally intensive?\nSupervisor: Not necessarily. It’s just about evolving a partial differential equation on paper. It’s fairly simple—around four equations in total. I should be able to reproduce it; I’m just fighting with the package I’m trying to use. This is an example of a minimal model. In the spirit of this, you’re assuming some nonlinearity in the relationships between suitable fields. This is doable in physics.\nThere is always an element of relaxation towards equilibrium in these models. Active matter, typically, is more concerned with steady states far from equilibrium, where you have strong intrinsic forces driving the system, pushing it away from equilibrium. However, you may still observe phases that resemble equilibrium phases, like a crystalline or liquid phase with characteristic density fluctuations.\nYou can’t always address where the driving force is coming from. In these models, even in the partial differential equations, we often put some ingredients in by hand. The central questions, like “How does life emerge?” are not fully addressed in physics; they might belong more to chemistry because they involve molecular-level processes. Life involves some kind of chemical cycle that transforms into a stable mechanism.\nYou: So, the emergence of life is more of a chemical question?\nSupervisor: Yes, at its core, it’s more of a chemical question. It’s about looking at chemical networks and how they transform into stable mechanisms. We’re not really experts in chemical networks, but there’s a lot of work on understanding non-equilibrium chemical networks and their structures. You’re asking an enormous question—how does life emerge? One way to approach this is by narrowing it down to a more specific problem that can be explored from a particular perspective.\nYou need to accept a set of assumptions and focus on a particular aspect, whether it’s morphogenesis, collective behaviour in bio-inspired systems, or understanding how chemical networks are affected by non-equilibrium forces, or what is the best mathematical description that allows you to categorise different chemical networks. This is a very broad question, and it’s huge in scope. We need to be inspired by that motivation but narrow it down to something achievable in the span of four years. It sounds like a lot of time, but it’s not that much.\nI think we’ve preempted a conversation that we’ll probably have with you in the next few months. This is just food for thought for now. If you need input, you can drop by. Let’s say you find an article and want to know more about its background or how it links to what you’ve done or plan to do—we can help with that.\nYou: Can I ask you one question? All these physics fields—or I would probably call them games because they are like tools to play with to a large extent—what are the things that you’re most curious about?\nSupervisor: Personally, I’m interested in going towards the biophysics angle. I’ve been working on abstract models of liquids for a long time. For example, I’ve simulated liquids in four dimensions on a curved three-dimensional surface. No one can actually sample those configurations; they don’t exist in reality. So, I would like to connect back to more concrete problems inspired by biophysics.\nMorphogenesis is one of the directions I would like to explore—using our understanding of active systems to make sense of the emergence of patterns in biological systems. But you can’t just jump into this field directly; you need to take a particular angle. In my case, it would be coupled to things like network formation or slow dynamics—problems where I already have some expertise.\nAt the same time, we are currently working on a basic but significant question: what drives the hydrophobic effect? When I give talks on biophysics, I can’t properly explain the hydrophobic effect—the one I mentioned earlier. If you talk to different people in this department or in chemistry, each person will tell you a different story about what they think causes the hydrophobic effect.\nSome will say, and you’ll find this on Wikipedia, that around a hydrophobic solute, water forms an ice-like structure, creating some sort of clathrate shape. It’s a story people tell themselves, but there’s no real evidence for it. The idea comes from an interpretation of experimental results. The experiments do show that there is some enthalpic and possibly entropic contribution, but it’s not clear that there is a structural change like that occurring. It’s more like a heuristic story we tell ourselves.\nYou: That makes sense. So, it’s more of a model or hypothesis?\nSupervisor: Yes, exactly. For example, if you look at surface phase transitions in liquids, these are actual phase transitions. You have a well-defined surface in contact with the liquid, and everything is more straightforward. The wall is infinite, so integrals converge, and you get proper correlation lengths. However, these transitions are challenging to sample numerically because you need to simulate both the bulk and the surface, ensuring that the surface is large enough to capture all the fluctuations.\nNow, when you introduce a solute in a fluid, everything is rounded by definition—there’s no thermodynamic limit in the same way. The solute has a finite surface, and the interactions are what they are. This solute might be roughly the same size as the fluid molecules, so there has to be a crossover regime where you can’t really coarse-grain. The question is, how much of this physics of surface phase transitions still controls those effects?\nHere, I’m not even talking about activity. We have looked at wetting and drying in active systems, but for hydrophobicity and related phenomena, the question is, can we relate the strength of the effect? Let’s say we take a protein. In this picture, a protein is just a blob, and it’s more complicated than that, but you could say it’s a blob with areas that are hydrophobic and others that are hydrophilic. What does that truly mean?\nStatistically, you see that it tends to stay in contact with other proteins like itself and away from water. That’s actually all you know—it tends to come together and not expose itself to water. For example, if you put it on a membrane, it sticks in one way and not the other. There are many other ideas linked to being hydrophobic, but it’s not a mechanistic explanation. We are just saying, “That’s what we observe.” It’s more of an effective, statistical statement.\nYou: So, it’s more about the properties of the solvent around the molecule?\nSupervisor: Yes, exactly. We want to measure the properties of the solvent around it. In this case, the solvent is water, but it could be something else. Quantities that seem to be interesting include some kind of measure of local compressibility. What does it mean to be “local”? What is the compressibility when you only have a few molecules? Can you still define it?\nIt seems like we can define something. Correlating the existing metrics of hydrophobicity with whatever we have as a metric for the behaviour of the fluid around a molecule is something we’re exploring at the moment. Before jumping straight into proteins, we look at simpler cases that we can control.\nFor example, we have a solute, a rigid molecule shaped like a lock—a sphere with a concavity. The curvature of this object changes, which is relevant because proteins have complex shapes with pockets and holes. The solvent here is water, and we observe effects that are not captured by true dynamics. We use Molecular Dynamics with some bias. If you let it go without bias, the solute just sticks there and never gets out. Even though the particles are all repulsive apart from the water, the solvent pushes the solute into the cavity, creating a large effective potential that keeps it there.\nThat’s the hydrophobic force—an effective potential of mean force, which can be seen as the logarithm of a probability. So, we’re trying to calculate the logarithm of this probability.\nYou: That makes a lot of sense. This is very enlightening.\nSupervisor: Yes, it’s a fascinating topic. There’s a lot more to explore, especially in how we understand the interactions between solutes and solvents. In the end, it’s about connecting abstract models back to real, observable phenomena and seeing how far we can push those models to explain complex behaviour in biological systems.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#hydrophobic-vs-hydrophilic",
    "href": "notes.html#hydrophobic-vs-hydrophilic",
    "title": "Weekly Notes",
    "section": "Hydrophobic vs Hydrophilic",
    "text": "Hydrophobic vs Hydrophilic\n\nHydrophobic surfaces: \\(90^\\circ &lt; \\theta &lt; 180^\\circ\\)\nHydrophilic surfaces: \\(0^\\circ &lt; \\theta &lt; 90^\\circ\\)\n\nAt two extremes:\n\n\\(\\theta = 0^\\circ\\): Full wetting.\n\\(\\theta = 180^\\circ\\): Perfect drying.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#cahns-scaling-law",
    "href": "notes.html#cahns-scaling-law",
    "title": "Weekly Notes",
    "section": "Cahn’s Scaling Law",
    "text": "Cahn’s Scaling Law\nCahn’s theory explains the scaling behaviour of surface tensions as the critical temperature \\(T_c\\) is approached (see: (Cahn 1977)). The surface tension vanishes following the power law:\n\nCahn, John W. 1977. “Critical Point Wetting.” The Journal of Chemical Physics 66 (8): 3667–72.\n\\[\n\\gamma_{lv} \\sim (-t)^\\mu \\quad \\text{with} \\quad \\mu = (d-1)\\nu\n\\]\nFor a fluid with \\(d = 3\\), the critical exponent is \\(\\nu \\approx 0.63\\), yielding \\(\\mu \\approx 1.26\\).",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#contact-angle-near-t_c",
    "href": "notes.html#contact-angle-near-t_c",
    "title": "Weekly Notes",
    "section": "Contact Angle Near \\(T_c\\)",
    "text": "Contact Angle Near \\(T_c\\)\nAs \\(T_c\\) is approached, the contact angle vanishes:\n\\[\n\\cos \\theta \\sim t^{\\beta - \\mu} \\quad \\text{with} \\quad \\beta \\approx 0.33\n\\]\nThus, \\(\\cos \\theta\\) diverges as \\(t^{-0.93}\\), but is constrained to \\(|\\cos \\theta| \\leq 1\\).\n\nWhy \\(\\beta - \\mu\\)?\nNear the critical temperature, both \\(\\gamma_{sv}\\) and \\(\\gamma_{sl}\\) vanish. As \\(T\\) approaches \\(T_c\\), \\(\\gamma_{lv}\\) tends to zero as \\((-t)^\\mu\\). The numerator \\(\\gamma_{sv} - \\gamma_{sl}\\) scales with the order parameter difference \\(\\Delta \\rho = \\rho_l - \\rho_v\\), because the distinction between liquid and vapour phases diminishes. This gives:\n\\[\n\\gamma_{sv} - \\gamma_{sl} \\sim (-t)^\\beta\n\\]\nBy substituting the scaling behaviours of \\(\\gamma_{lv}\\) and \\(\\gamma_{sv} - \\gamma_{sl}\\) into Young’s equation, we get:\n\\[\n\\cos \\theta \\sim \\frac{(-t)^\\beta}{(-t)^\\mu} = t^{\\beta - \\mu}\n\\]",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#critical-vs-first-order-transitions",
    "href": "notes.html#critical-vs-first-order-transitions",
    "title": "Weekly Notes",
    "section": "Critical vs First-Order Transitions",
    "text": "Critical vs First-Order Transitions\nThe nature of these transitions can be:\n\nCritical: The equilibrium film width \\(\\ell_{eq}\\) grows continuously as \\(T_D\\) is approached.\nFirst-order: The film width jumps discontinuously.\n\nBelow are illustrations of critical and first-order transitions for drying:",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#scaling-behaviour",
    "href": "notes.html#scaling-behaviour",
    "title": "Weekly Notes",
    "section": "Scaling Behaviour",
    "text": "Scaling Behaviour\nThe equilibrium film width \\(\\ell_{eq}\\) exhibits different behaviours depending on the order of the transition:\n\\[\n\\ell_{eq} = \\frac{-\\Gamma}{A_{sv} \\Delta \\rho}\n\\]\nWhere:\n\n\\(\\Gamma = \\int \\mathrm{d}r \\, [\\rho(r) - \\rho_b]\\) is the adsorption, which describes the excess of fluid near the surface relative to the bulk.\n\\(A_{sv}\\) is the surface area of the substrate-vapour interface\n\\(\\Delta \\rho = \\rho_l - \\rho_v\\) is the difference between the liquid and vapour densities\n\nFor \\(\\rho(r)\\), we know from the statistical mechanics of fluids that the one-particle density \\(\\rho^{(1)}(r)\\) can be written in the form of an ensemble average.:\n\\[\n\\langle \\hat{\\rho}^{(1)}(r) \\rangle = \\frac{1}{\\Xi} \\sum_{j=1}^\\infty \\frac{e^{\\beta \\mu N}}{\\Lambda^{3N}(N-1)!} \\int \\mathrm{d}r^{N-1} e^{-\\beta[\\Phi(r^N) + V_{\\text{ext}}(r^N)]}\n\\]\nThis defines the fluid’s spatially varying density at a microscopic level.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "reading.html#what-is-a-complex-system-completed",
    "href": "reading.html#what-is-a-complex-system-completed",
    "title": "List of My Reading",
    "section": "",
    "text": "By James Ladyman and Karoline Wiesner\nMy final-year MSci project involved the study of a complex system, foreign exchange markets. Each individual currency was treated as a spin in the Ising model, and by applying E.T. Jaynes’s principle of maximum entropy, we discovered the structure of interactions between these entities. Remarkably, this simple model of magnetism can also describe the phase transitions of liquid-gas systems, as they fall into the same universality class. This model has even been extended to study how critical our brain is, giving rise to the field of the critical brain hypothesis. Therefore, many ideas during my research project were derived from neuroscience papers. The financial market and the brain: both are complex systems.\nAbout a year ago, I read a paper published by James Ladyman, a professor of philosophy of science at Bristol, titled ‘What is a Complex System?’ (Ladyman, Lambert, and Wiesner 2013). As I started my PhD at Bristol, my second supervisor, Francesco, mentioned that he also published a book about complexity. It became clear to me that I should read this book.\n\nLadyman, James, James Lambert, and Karoline Wiesner. 2013. “What Is a Complex System?” European Journal for Philosophy of Science 3: 33–67.\nChapter 1 presents The Truisms of Complexity Science as follows:\n1. More is different.\n2. Nonliving systems can generate order.\n3. Complexity can come from simplicity.\n4. Coordinated behaviour does not require an overall controller.\n5. Complex systems are often modelled as networks or information processing systems.\n6. There are various kinds of invariance and forms of universal behaviour in complex systems.\n7. Complexity science is computational and probabilistic.\n8. Complexity science involves multiple disciplines.\n9. There is a difference between the order that complex systems produce and the order of the complex systems themselves.\nFeatures that are necessary and sufficient for which kinds of complexity and complex system are as follows:\n1. Numerosity: complex systems involve many interactions among many components.\n2. Disorder and diversity: the interactions in a complex system are not coordinated or controlled centrally, and the components may differ.\n3. Feedback: the interactions in complex systems are iterated so that there is feedback from previous interactions on a time scale relevant to the system’s emergent dynamics.\n4. Non-equilibrium: complex systems are open to the environment and are often driven by something external.\n5. Spontaneous order and self-organisation: complex systems exhibit structure and order that arises out of the interactions among their parts.\n6. Nonlinearity: complex systems exhibit nonlinear dependence on parameters or external drivers.\n7. Robustness: the structure and function of complex systems is stable under relevant perturbations.\n8. Nested structure and modularity: there may be multiple scales of structure, clustering and specialisation of function in complex systems.\n9. History and memory: complex systems often require a very long history to exist and often store information about history.\n10. Adaptive behaviour: complex systems are often able to modify their behaviour depending on the state of the environment and the predictions they make about it.\n\n2024/9/27\nReading What is a Complex System? by James Ladyman and Karoline Wiesner. The purpose of reading is to understand how systems out of thermodynamic equilibrium (a feature of complex systems) relate to a wide range of concepts associated with complexity.\n• There was a video that helped clarify what is meant by a Markov chain and a stochastic process being stationary: Markov Chains Clearly Explained! Part - 1. His other videos are helpful as well. For example, when I saw \\(P_{ij}^{(n)} = A_{ij}^n\\) from the n-Step Transition Matrix video (Part 3), it was quite surprising. However, the Part 5 video on hidden Markov models wasn’t very helpful, but reading the appendix in the book was sufficient.\n• What I’ve felt from reading this book (currently at p.90) is that it presents a lot of different ideas and has interesting discussions on the history of science, but I only seem to get excited when it starts mentioning the brain. I’m not sure if I’m necessarily interested in quantifying complexity. From the Apple notes on 28/9/2024:\nAs I’m reading through What is a Complex System?, it seems that the description of a complex system arises as we have more representations at different scales of analysis. The concept of ‘complexity’ was destined to arise as the scientific era evolved.\nNon-equilibrium systems arise because we define what systems are in thermodynamic equilibrium, which are idealisations.\nThings that fail to be idealised fall into this dualistic concept: non-equilibrium.\n\n2024/10/3\nIt took about two weeks to finish this book. It was an accessible read until I reached chapter 4, which was Measuring Features of Complex Systems. In the end, I’m glad that I read it, even though I somehow felt rushed to finish as there were other responsibilities to manage continuously, such as setting up clusters for my university Mac, teaching, office setup, etc. Most importantly, from now on, I am going to focus on reading material that is directly related to my project since it may give the impression to my supervisors that I’m not working hard. Reading a book like this takes a long time, as there are many new terms I had not encountered before.\nAnyway, it was a good read. Would I buy a physical copy for myself? Maybe not, but it was a good one.",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#on-the-motion-of-small-particles-suspended-in-liquids-at-rest-required-by-the-molecular-kinetic-theory-of-heat-completed",
    "href": "reading.html#on-the-motion-of-small-particles-suspended-in-liquids-at-rest-required-by-the-molecular-kinetic-theory-of-heat-completed",
    "title": "List of My Reading",
    "section": "2024/10/18 - 10/19 On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat (Completed)",
    "text": "2024/10/18 - 10/19 On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat (Completed)\nBy Albert Einstein\nSince I am studying a model called active Brownian particles, a thought occurred to me: I should actually read where this understanding of Brownian motion came from! This was done by the very man: Albert Einstein in 1905 (Einstein et al. 1905). I normally leave my iPad in my office so whenever I needed derivations, I used a pen and note, quite a classical way while reading a classical paper:\n\nEinstein, Albert et al. 1905. “On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat.” Annalen Der Physik 17 (549-560): 208.\nMy handwritten notes\nI’m so glad that I read this. It reminded me of how much I loved studying thermodynamics during my undergraduate studies. It was kind of like studying geometry (or topology). I consider a system subject to constraints and investigate how the particle behaves given the state variables. The paper wasn’t straightforward to read, as I had to remind myself of several concepts such as the continuous form of entropy, perturbation theory, and Fourier transforms to find a solution for diffusion equations.\nI really liked the way he displayed his logic. He considers a system: a pure solvent and suspended particles. These particles are confined by a semi-permeable wall, which only allows solvent to flow, not the solute. Then he thinks about the existing concept of osmotic pressure, which inhibits the solvent from moving to equalise concentrations. He then makes several reasonable assumptions, such as:\n\nSuspended particles have slow and irregular motions due to the solvent’s molecules.\nThe motions of those individual particles are independent of each other.\n\nHe then links the diffusion coefficient to two different contexts. The first is through the theory of diffusion, involving concepts of entropy and free energy. The second is through the theory of thermal molecular motion, where he considers the rate of change of density. By uniting these two theories, he arrives at the root-mean-square displacement of the suspended particle. Wow!\nI’m so happy to have chosen a theoretical physics PhD. Thinking about how theories interconnect reveals a universal understanding. I’m looking forward to reading more of his articles.",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "notes.html#week-6",
    "href": "notes.html#week-6",
    "title": "Weekly Notes",
    "section": "Week 6",
    "text": "Week 6\n\n2024/10/23 Molsim-2025 School Application\nMolSim-2025 is 2-week school that offers a program focusing on basic and advanced molecular simulation methods. It targets PhD candidates and postdoctoral researchers who want to understand and apply these methods to study topics in physics, chemistry or biology. The program has an integrated and balanced structure of lectures and hands-on exercises. It offers a recap of the basic theory relevant for molecular simulation, followed by a thorough covering of basic and advanced simulation techniques. All techniques will be accompanied by illustrative examples of present day research.\n\nMy application (submitted on 241023)\nI am a PhD student in theoretical and computational physics at the University of Bristol, specialising in the simulation of surface phase transitions with a focus on active matter using high-performance computing. My supervisors are Nigel Wilding, who has strongly recommended this winter school and has done substantial work on developing efficient algorithms for MC simulations [1-4], and Francesco Turci, who specialises in disordered systems. My initial project involves investigating drying (surface) phase transitions using Monte Carlo and molecular dynamics techniques, introducing an additional parameter to how they approached the problem in PRL 2021 [5].\nI am highly motivated to join this winter school since it is my first year of PhD studies and also my first time learning how to conduct molecular simulations. I am currently reading the book Understanding Molecular Simulation to grasp the methodologies, and I was very excited by the fact that the authors of this book will be present for the lectures. Even though this book is enjoyable to read, many concepts within it are quite new to me, so it will be a great opportunity to deepen my knowledge in this area and meet colleagues with similar interests. The latter reason is also very important since I am the only PhD student learning models of active particles for surface phase transitions in my department.\nPlease let me know if you would like me to send my CV. For now, I have attached my personal statement, which I submitted for my PhD application, showing my dynamic and multifaceted experience. I hope this wonderful opportunity will materialise.\n\n[1] N.B. Wilding, A.D. Bruce, Density fluctuations and field mixing in the critical fluid, J. Phys. Condens. Matter 4 (12) (1992) 3087–3108\n[2] N.B. Wilding, Critical point and coexistence curve properties of the Lennard-Jones fluid: a finite-size scaling study, Phys. Rev. E 52 (1) (1995) 602–611\n[3] A.D. Bruce, N.B. Wilding, G.J. Ackland, Free energy of crystalline solids: a lattice-switch Monte Carlo method, Phys. Rev. Lett. 79 (16) (1997) 3002–3005\n[4] S. Consta, N.B. Wilding, D. Frenkel, Z. Alexandrowicz, Recoil growth: an efficient simulation method for multi-polymer systems, J. Chem. Phys. 110 (6) (1999) 3220–3228\n[5] F. Turci, N.B. Wilding, Phase separation and multibody effects in three-dimensional active Brownian particles, Phys. Rev. Lett. 126.3 (2021) 038002.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "reading.html#understanding-molecular-simulation",
    "href": "reading.html#understanding-molecular-simulation",
    "title": "List of My Reading",
    "section": "2024/10/23 - Understanding Molecular Simulation",
    "text": "2024/10/23 - Understanding Molecular Simulation\nBy Dann Frenkel and Berend Smit\n\nInteresting discussion of what it means by a ‘model’ in science\n\n\n\nOn page 6, Introduction",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#understanding-molecular-simulation-3rd-ed",
    "href": "reading.html#understanding-molecular-simulation-3rd-ed",
    "title": "Reading Archive",
    "section": "2024/10/23 - Understanding Molecular Simulation, 3rd Ed",
    "text": "2024/10/23 - Understanding Molecular Simulation, 3rd Ed\nBy Daan Frenkel and Berend Smit\n\nChapter 1. Introduction\nBefore starting our project, I was a little concerned about whether computational simulation is a valid way to understand the fundamental order of nature. I thought that what we do as physicists is observe systems through experiments, theorise with idealised objects to gain predictive power, and then test the theory by observing again. This thought process was probably inspired by a Kantian perspective; I read his Critique of Pure Reason in high school, where he posits that causality is a presupposition of reasoning. For those purposes, idealised objects had to be mathematical (forms or images from Plato) and needed to represent what I directly observe in empirical reality.\n\n\n\nOn page 2, Introduction\n\n\nI’m still not completely certain if computer simulation is truly the way to go, but as I work through it, I hope it will make more sense to me.\n\n\n\n\nOn page 6, Introduction\n\n\nQuite an interesting discussion on what ‘model’ means in science.\n\n\n\nChapter 2. Thermodynamics and Statistical Mechanics\n\n\n\nOn page 22, 2.1.2 Chemical Potential and Equilibrium\n\n\nImportant equilibrium conditions!\n\n\n\n\nOn page 22, 2.1.2 Chemical Potential and Equilibrium\n\n\nI’m not entirely sure why the extremum condition applies specifically to variations in \\(E_1\\), \\(N_1\\), and \\(V_1\\). So, I asked ChatGPT:\n\n\nClick to reveal the answer!\n\nYou’re right to question this subtle point.\nThe key insight lies in understanding that when we talk about maximising the total entropy \\(S_{\\text{tot}} = S_1 + S_2\\) of a closed system with fixed total values of energy, volume, and particle number, the only degrees of freedom available for changes are the distributions of \\(E\\), \\(V\\), and \\(N\\) between the subsystems.\nHere’s the reasoning in detail:\n\nFixed Total Quantities Impose Constraints: Because the total energy \\(E_{\\text{tot}} = E_1 + E_2\\), volume \\(V_{\\text{tot}} = V_1 + V_2\\), and particle number \\(N_{\\text{tot}} = N_1 + N_2\\) are fixed, any changes in \\(E_1\\), \\(V_1\\), or \\(N_1\\) must be offset by corresponding changes in \\(E_2\\), \\(V_2\\), and \\(N_2\\) to keep these sums constant.\nEntropy Extremum Condition: In equilibrium thermodynamics, the Second Law requires that the total entropy of an isolated (or closed) system reaches a maximum (or an extremum) at equilibrium. However, since the system is closed and these total quantities are fixed, the system cannot simply increase or decrease its overall \\(E_{\\text{tot}}\\), \\(V_{\\text{tot}}\\), or \\(N_{\\text{tot}}\\). Instead, any adjustments to entropy must occur through redistributions of these quantities between subsystems.\nRedistribution as the Only Available Variation: Thus, the extremisation of \\(S_{\\text{tot}}\\) must occur specifically with respect to the variables that can change within the subsystems while satisfying the overall conservation constraints. Since \\(E_{\\text{tot}}\\), \\(V_{\\text{tot}}\\), and \\(N_{\\text{tot}}\\) are fixed, the only available independent variations in \\(S_{\\text{tot}}\\) come from redistributing \\(E_1\\), \\(V_1\\), and \\(N_1\\) (and equivalently \\(E_2\\), \\(V_2\\), and \\(N_2\\)).\nDerivative Vanishing Condition: For \\(S_{\\text{tot}} = S_1 + S_2\\) to be maximised (or extremised) under these constraints, the derivatives of \\(S_{\\text{tot}}\\) with respect to \\(E_1\\), \\(V_1\\), and \\(N_1\\) must vanish. This is because any non-zero derivative would indicate that entropy could be further increased by adjusting these redistributive variables, contradicting the requirement of equilibrium.\n\nIn summary, we require the extremum condition with respect to \\(E_1\\), \\(V_1\\), and \\(N_1\\) specifically because these are the variables that can be redistributed between the subsystems within the constraint of fixed total quantities. This is why the extremum condition applies to these specific derivatives, and not to other parameters.\n\n\n\n\n\nOn page 30, 2.2.3 Towards Classical Statistical Mechanics\n\n\nI’m not sure how to derive the transition from 2.2.17 to 2.2.18.",
    "crumbs": [
      "Project Notes",
      "Reading Archive"
    ]
  },
  {
    "objectID": "conferences.html",
    "href": "conferences.html",
    "title": "Conferences",
    "section": "",
    "text": "By Dan Lucas from St Andrews\n\n\nAn attractive approach to tackling the complexity of a turbulent fluid flow is to view the behaviour from a dynamical systems perspective. That is, we might imagine a trajectory navigating a high dimensional phase space directed by the stable and unstable manifolds of simple invariant states. In a fluid system such invariant states might take the form of steady equilibria, travelling waves or time periodic orbits. In many cases isolating such states is challenging due to their high instability. In this talk we will introduce the method of “time-delayed feedback control” as a method to passively stabilise travelling wave solutions to the Navier-Stokes equations. We will survey recent results in this project where we successfully stabilise states from two-dimensional turbulence and turbulence in a rectilinear periodic pipe. In both cases travelling waves can be stabilised at relatively large Reynolds numbers, and in each situation we outline some novel approaches to improve the performance of the control. Along the way we perform linear stability analyses and use methods from control theory to validate our results and help us gain additional insight into the mechanisms underpinning successful control. We also demonstrate gradient descent methods to help optimise control parameters to avoid laborious searching and enable states to be obtained from speculative guesses.\n\n\n\nBefore going to the seminar, there were concepts I couldn’t understand from the abstract, which were:\n\nStable and unstable manifolds of simple invariant states:\n\nIn dynamical systems, an invariant state refers to a state of the system that doesn’t change over time (e.g., a fixed point or periodic orbit). Manifolds are like paths or surfaces that represent how nearby points behave relative to this state.\n\nA stable manifold means nearby points move towards the invariant state (like water flowing towards a drain).\nAn unstable manifold means nearby points move away from the state (like a ball rolling off the top of a hill).\n\n\nSteady equilibria, travelling waves, or time-periodic orbits:\n\nSteady equilibria are solutions where the system remains constant over time.\nTravelling waves are wave-like solutions that maintain their shape while moving through space.\nTime-periodic orbits are states where the system repeats its behaviour in a regular time cycle, like a pendulum swinging back and forth.\n\nTime-delayed feedback control:\n\nThis is a control method where the system’s state is monitored and the control signal applied is based on the system’s past states, not its current state. The delay refers to how far back in time you look to adjust the system’s behaviour. It’s often used to stabilise unstable systems by correcting them with delayed feedback.\n\nRectilinear periodic pipe:\n\nThis describes a straight (rectilinear) pipe where the fluid flow repeats itself periodically along the length of the pipe, meaning the pipe’s conditions are the same at regular intervals.\n\nReynolds numbers:\n\nThe Reynolds number is a dimensionless quantity used to predict the flow behaviour of fluids. It compares inertial forces to viscous forces and helps determine whether a flow will be laminar (smooth) or turbulent (chaotic). Larger Reynolds numbers typically indicate turbulent flow.\n\nControl theory:\n\nThis is a field of study focused on how to control systems to achieve desired behaviours. It involves using mathematical models to design strategies (called controllers) to manage dynamic systems (like fluid flow) so they behave in a certain way.\n\nSpeculative guesses:\n\nThis refers to making educated guesses about the system’s parameters or initial conditions to find solutions or states of interest without fully knowing the correct values in advance. It suggests an exploratory approach.\n\n\n\n\n\nI could not understand most of what he talked about, so my mind wandered. I began thinking about how I could approach solving an important problem in the vaping industry: the ideal position (such as height) of the coil in the atomiser. The object of interest can be described as follows:\n\nThere are posts (positive/negative), and the coil is usually installed between them. The coil is typically made from Kanthal A1, NiChrome80, or SS316L, listed in order of common usage.\nSince the coil is wrapped in a helical form, cotton is inserted inside the coil to hold the e-liquid (it’s easier to see than explain; check my business Instagram).\nThe e-liquid consists of four components: PG (propylene glycol), which has low viscosity, VG (vegetable glycerin), which has high viscosity, flavourings (dissolved in PG), and nicotine (also dissolved in PG). We can approximate the e-liquid as a mix of PG and VG.\nAir typically enters from the side, while the vaporised liquid and air leave through the top of the atomiser by suction.\nThe temperature of the coil continuously changes, affecting the vaporisation process. This temperature is influenced by how incoming air interacts with the droplets formed on the coil.\n\nThe vaping industry mainly focuses on finding the optimal coil height by using computational aerodynamics software to maximise airflow around the coil, prolonging its life. However, not all of these simulations reflect reality very well because:\n\nThe power, which dictates the temperature gradient of the coil, is determined by the user’s settings on their vape mod.\nEveryone’s suction strength varies.\nCoil diameters differ.\nThe ratio of PG to VG depends on the user, typically 50/50 for mouth-to-lung vaping and 30/70 for direct-lung vaping.\nAmbient temperature, which affects the incoming air, differs from user to user.\nDepending on how the cotton is placed inside the atomiser, the available volume for airflow can change.\nThere is a continuous influx of liquid through the cotton during vaporisation.\n\nSo, many factors are involved. I was thinking that I could approach this problem from a different angle: how can I make all the droplets evaporate effectively? I’m not sure if I can tackle this in the context of active drying, but it’s a possibility.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Conferences"
    ]
  },
  {
    "objectID": "conferences.html#stabilising-travelling-waves-from-fluid-turbulence.",
    "href": "conferences.html#stabilising-travelling-waves-from-fluid-turbulence.",
    "title": "Conferences",
    "section": "",
    "text": "By Dan Lucas from St Andrews\n\n\nAn attractive approach to tackling the complexity of a turbulent fluid flow is to view the behaviour from a dynamical systems perspective. That is, we might imagine a trajectory navigating a high dimensional phase space directed by the stable and unstable manifolds of simple invariant states. In a fluid system such invariant states might take the form of steady equilibria, travelling waves or time periodic orbits. In many cases isolating such states is challenging due to their high instability. In this talk we will introduce the method of “time-delayed feedback control” as a method to passively stabilise travelling wave solutions to the Navier-Stokes equations. We will survey recent results in this project where we successfully stabilise states from two-dimensional turbulence and turbulence in a rectilinear periodic pipe. In both cases travelling waves can be stabilised at relatively large Reynolds numbers, and in each situation we outline some novel approaches to improve the performance of the control. Along the way we perform linear stability analyses and use methods from control theory to validate our results and help us gain additional insight into the mechanisms underpinning successful control. We also demonstrate gradient descent methods to help optimise control parameters to avoid laborious searching and enable states to be obtained from speculative guesses.\n\n\n\nBefore going to the seminar, there were concepts I couldn’t understand from the abstract, which were:\n\nStable and unstable manifolds of simple invariant states:\n\nIn dynamical systems, an invariant state refers to a state of the system that doesn’t change over time (e.g., a fixed point or periodic orbit). Manifolds are like paths or surfaces that represent how nearby points behave relative to this state.\n\nA stable manifold means nearby points move towards the invariant state (like water flowing towards a drain).\nAn unstable manifold means nearby points move away from the state (like a ball rolling off the top of a hill).\n\n\nSteady equilibria, travelling waves, or time-periodic orbits:\n\nSteady equilibria are solutions where the system remains constant over time.\nTravelling waves are wave-like solutions that maintain their shape while moving through space.\nTime-periodic orbits are states where the system repeats its behaviour in a regular time cycle, like a pendulum swinging back and forth.\n\nTime-delayed feedback control:\n\nThis is a control method where the system’s state is monitored and the control signal applied is based on the system’s past states, not its current state. The delay refers to how far back in time you look to adjust the system’s behaviour. It’s often used to stabilise unstable systems by correcting them with delayed feedback.\n\nRectilinear periodic pipe:\n\nThis describes a straight (rectilinear) pipe where the fluid flow repeats itself periodically along the length of the pipe, meaning the pipe’s conditions are the same at regular intervals.\n\nReynolds numbers:\n\nThe Reynolds number is a dimensionless quantity used to predict the flow behaviour of fluids. It compares inertial forces to viscous forces and helps determine whether a flow will be laminar (smooth) or turbulent (chaotic). Larger Reynolds numbers typically indicate turbulent flow.\n\nControl theory:\n\nThis is a field of study focused on how to control systems to achieve desired behaviours. It involves using mathematical models to design strategies (called controllers) to manage dynamic systems (like fluid flow) so they behave in a certain way.\n\nSpeculative guesses:\n\nThis refers to making educated guesses about the system’s parameters or initial conditions to find solutions or states of interest without fully knowing the correct values in advance. It suggests an exploratory approach.\n\n\n\n\n\nI could not understand most of what he talked about, so my mind wandered. I began thinking about how I could approach solving an important problem in the vaping industry: the ideal position (such as height) of the coil in the atomiser. The object of interest can be described as follows:\n\nThere are posts (positive/negative), and the coil is usually installed between them. The coil is typically made from Kanthal A1, NiChrome80, or SS316L, listed in order of common usage.\nSince the coil is wrapped in a helical form, cotton is inserted inside the coil to hold the e-liquid (it’s easier to see than explain; check my business Instagram).\nThe e-liquid consists of four components: PG (propylene glycol), which has low viscosity, VG (vegetable glycerin), which has high viscosity, flavourings (dissolved in PG), and nicotine (also dissolved in PG). We can approximate the e-liquid as a mix of PG and VG.\nAir typically enters from the side, while the vaporised liquid and air leave through the top of the atomiser by suction.\nThe temperature of the coil continuously changes, affecting the vaporisation process. This temperature is influenced by how incoming air interacts with the droplets formed on the coil.\n\nThe vaping industry mainly focuses on finding the optimal coil height by using computational aerodynamics software to maximise airflow around the coil, prolonging its life. However, not all of these simulations reflect reality very well because:\n\nThe power, which dictates the temperature gradient of the coil, is determined by the user’s settings on their vape mod.\nEveryone’s suction strength varies.\nCoil diameters differ.\nThe ratio of PG to VG depends on the user, typically 50/50 for mouth-to-lung vaping and 30/70 for direct-lung vaping.\nAmbient temperature, which affects the incoming air, differs from user to user.\nDepending on how the cotton is placed inside the atomiser, the available volume for airflow can change.\nThere is a continuous influx of liquid through the cotton during vaporisation.\n\nSo, many factors are involved. I was thinking that I could approach this problem from a different angle: how can I make all the droplets evaporate effectively? I’m not sure if I can tackle this in the context of active drying, but it’s a possibility.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Conferences"
    ]
  },
  {
    "objectID": "index.html#groups",
    "href": "index.html#groups",
    "title": "Project Description",
    "section": "Groups",
    "text": "Groups\nSoft matter community\nUpcoming events by Nonlinear and Complex Physics Group",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "notes.html#week-7",
    "href": "notes.html#week-7",
    "title": "Weekly Notes",
    "section": "Week 7",
    "text": "Week 7\n\n2024/10/28 Weekly project meeting\n\nThings to discuss\n\nAsk about page 51 on Molecular Dynamics Simulation showing notes written on Zotero.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#week-8",
    "href": "notes.html#week-8",
    "title": "Weekly Notes",
    "section": "Week 8",
    "text": "Week 8\n\n2024/11/8 Active Brownian Particles (ABPs)\nI now understand why ABPs drive the system out of equilibrium. I love deriving everything mathematically from first principles.\nThings I have understood:\n\nThe equations of motion for ABPs are described by overdamped Langevin equations.\nPersistent fluxes of particles prevent the detailed balance condition; therefore, there is no Boltzmann distribution.\n\nI’m still uncertain about the concept of entropy production. When I finish reading Physics and Beyond, I’ll start reading Understanding Molecular Simulation again, as it has a chapter that discusses this concept.\nThese are the PDF notes that I wrote: My handwritten notes",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "reading.html#physics-and-beyond",
    "href": "reading.html#physics-and-beyond",
    "title": "List of My Reading",
    "section": "2024/11/2 - Physics and Beyond",
    "text": "2024/11/2 - Physics and Beyond\nBy Werner Heisenberg\nIt’s the first time I’m reading this in English; the title of the book in Korean is 부분과 전체, which might translate to Parts and the Whole. I’ve read it many times, and it has been highly influential to me as a physicist. To capture some of the things I want to revisit later:\n\n\n\nOn page 72, Fresh Fields (1926-1927)\n\n\n\n\n\nOn page 80, Fresh Fields (1926-1927)\n\n\nSo far, having read up to page 89, it has all been interesting, except for Chapter 4 (Lessons in Politics and History).",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#sec-physics-and-beyond",
    "href": "reading.html#sec-physics-and-beyond",
    "title": "Reading Archive",
    "section": "2024/11/2 - 11/8 Physics and Beyond (Heisenberg et al. 1971)",
    "text": "2024/11/2 - 11/8 Physics and Beyond (Heisenberg et al. 1971)\n\nHeisenberg, Werner et al. 1971. Physics and Beyond. Allen & Unwin London.\nCited by 1832\nIt’s the first time I’m reading this in English; the title of the book in Korean is 부분과 전체, which might translate to Parts and the Whole. I’ve read it many times since I was in high school, and it has been highly influential to me as a physicist throughout my life. To capture some of the things I want to revisit later:\n\n\n\nOn page 72, Fresh Fields (1926-1927)\n\n\n\n\n\nOn page 80, Fresh Fields (1926-1927)\n\n\nSo far, having read up to page 89, it has all been interesting, except for Chapter 4 (Lessons in Politics and History). When the development of quantum mechanics was presented in Chapters 5 and 6, I felt my heart pounding as I read through, just as it did when I first read this book.\n\n\n\n\nOn page 97, Atomic Physics and Pragmatism (1929)\n\n\nAll these realms were so enjoyable to learn, but now, as a researcher, I wonder what realms are still open. I thought one of them was non-equilibrium statistical thermodynamics, but it appears to me that this theory can’t be axiomatic, implying that all systems out of equilibrium must be described differently.\n\n\n\n\nOn page 109, The Relationship between Biology, Physics and Chemistry (1930-1932)\n\n\n‘Forms through which matter streams,’ as Niels Bohr described, was the most profound characterisation of organisms I have encountered. I used to wonder, what about this structure remains? Does it actually persist, given that a person changes continuously as a child becomes an adult? Is it simply the name (person) we assign that represents this form of life? With this thought, is there really a distinction between animate and inanimate objects?\nWhen I read Timaeus by Plato in high school, he described geometrical forms as the basis of earth, fire, water, and air, even though I found his idea peculiar (like everything is made of right triangles). At the time, I thought the properties that define those mathematical forms were responsible for things maintaining their structure in the way we perceive over time (since all forms change shape as time passes). My master’s research was also focused on investigating this homeostasis in an ideal structure, not physical but something we perceive, in the context of foreign exchange markets. This line of thought was also captured well by Bohr’s question: “Can quantum mechanics explain nature’s tendency to form structures through which matter with fixed chemical properties can stream for a limited time?”\n\n\n\n\nOn page 128, Discussions about Language (1933)\n\n\nThis passage about the discovery of antimatter was one of the reasons I chose a physics degree, along with my ambition to formally study general relativity. Although I didn’t score well in my particle physics exam in third year due to a part-time job over winter break, it remains one of the most exciting units I’ve taken. Here are the scores and ratings I gave to my third and fourth-year units with scores of at least 4:\n5: Physics Research Project (83), Quantum Physics (88)\n4.5: Physics of Phase Transitions (85), Analytical Mechanics (66), Particle Physics (58)\n4: Quantum Information Theory (68), Foundations of Modern Physics (68), Methods of Theoretical Physics (63)\nIt’s surprising that general relativity only scored 3.5, but it seems I didn’t enjoy the lecture style despite being fascinated by the content.\n\n\n\n\nOn page 134, Discussions about Language (1933)\n\n\nThis passage captures the reason I didn’t pursue a philosophy degree, despite having written about philosophy of science. What I realised was the fluidity of language, and at some point, reading philosophy felt like participating in a language game. Even when I wrote The Self and the World, I included definitions for the terms I used in the document. In contrast, I conceived mathematical objects as eternal, grounded solidly in axioms. I couldn’t imagine any language other than this to describe the hidden secrets of the universe as eternal representations, unchanging, unmoved, and concrete.\n\n\n\n\nOn page 136, Discussions about Language (1933)\n\n\nAnother book I feel closely connected to is the Tao Te Ching by Lao Tzu. It’s probably not an exaggeration to say that my whole life has been devoted to understanding the meaning of Tao, even though Lao Tzu paradoxically said, “The Tao that can be described is not the eternal Tao.” One day, I realised it is synonymous with the Truth or, in more Platonic terms, the formless. Ineffable. That’s when I wrote this diary: Is “It” a Joke?\n\n\n\n\nOn page 191, Toward a New Beginning (1941-1945)\n\n\nThese chapters were not enjoyable to read: Revolution and University Life (1933), Individual Behavior in the Face of Political Disaster (1937-1941), Toward a New Beginning (1941-1945). I’m certainly not interested in politics or wars. However, the ending of this third chapter is beautifully written; beauty transcends ideology, opinions, and dualistic views of the world.\n\n\n\n\nOn page 195, The Responsibility of the Scientist (1945-1950)\n\n\nThis reveals the reason why I chose the theme of active matter. I was curious about how this model suddenly emerged in the last 25 years. Why is there such a sudden interest in this concept? What possibilities does it offer for understanding nature? What contributions can I make to the circle of human knowledge?\n\nWhile reading through the Scientific and Political Disputes (1956-1957) chapter, I realised I can only concentrate when scientific matters are being discussed, such as the conversations between Heisenberg and Wolfgang about the mathematical theory for elementary particles.\n\n\n\nOn page 230, The Unified Field Theory (1957-1958)\n\n\nHowever, everything that followed from the passage in the image was fascinating, especially when they started discussing symmetries (for example, the universe as a whole does not necessarily have to be symmetrical with respect to the operations under which natural laws remain invariant), relativistic quantum field theories, and more, which captivated me when I studied particle physics in my third year.\n\n\n\n\nOn page 240, Elementary Particles and Platonic Philosophy (1961-1965)\n\n\nI have finally finished the book. Although the above image is not the last page, I love this book because it begins with Plato and ends with him. Timaeus was the book that shaped my worldview when I was in high school, and when I first encountered Physics and Beyond, I was thrilled to find someone in history who asked the same questions I had while reading Timaeus. Since then, my understanding has deepened, and I’ve come to see that all philosophy traces back to Plato. Last year, a decade later, I finally had a direct understanding of what Plato described through some interesting experiences.\nEven beyond that passage in the screenshot, it’s truly worth rereading. People at that time were already considering how natural laws conform to different scales, touching on the concept of emergence, which is the field I’m now working in.\nWhile reading this book, I rewatched the documentary series Atom, hosted by Jim Al-Khalili. I remember watching it for the first time in high school, loving it immensely, and being struck by statements from scholars like Paul Dirac, who said, “A physical law must possess mathematical beauty.” I was curious about what QED implied once I start learning about it at university, such as how all the matter we see is just reflections of virtual particles. That was a long time ago, and that naïveté and curiosity are what led me to study physics. I’d like to close with what Jim Al-Khalili said (even though I largely disagree with his interpretation of quantum mechanics in that chapter) at the end of The Illusion of Reality (the third episode):\nIn the last 100 years, we have peered deep inside the atom, the basic building block of the universe. And inside this tiny object, we have found a strange new world governed by exotic laws that at times seem to defy reason. Atoms present us with dizzying contradictions. They can behave both as particles or waves. They appear to be in more than one place at the same time. They force us to rethink what we mean by past and future, by cause and effect. And they tell us strange things about where the universe came from and where it’s going. Pretty amazing stuff for something that’s just a millionth of a millimetre across. That’s why Niels Bohr, the father of atomic physics, once said that, when it comes to atoms, language can only be used as poetry. What’s fascinating to me is that although we’ve learnt an incredible amount about atoms and their behaviour, our scientific journey has only just begun. Because although we know how a single atom or just a few atoms behave, the way trillions of them come together in concert to create the world around us is still largely a mystery. To give you one dramatic example, the atoms that make up my body are identical to the atoms in the rocks, the trees, the air, even the stars. And yet, they come together to create a conscious being who can ask the question, “What is an atom?” Explaining all that is surely the next great challenge in science.\nI realised that the “next great challenge” he mentioned is the same one I’ve been drawn to since studying physics: the emergence of consciousness. The most intriguing question, perhaps prompted by an interesting dream I had last night, is how our mind creates the world and perceives it simultaneously when we dream. When I’m awake, I can do this partially; for instance, when I think about walking down the corridor where my office is located, I can imagine it while experiencing it at the same time. It seems this ability expands to full capacity in dreams. Once I understand that mechanism, I might be able to discern, even when awake, whether I am still dreaming and creating the world while simultaneously perceiving it.",
    "crumbs": [
      "Project Notes",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#sec-physicsandbeyond",
    "href": "reading.html#sec-physicsandbeyond",
    "title": "List of My Reading",
    "section": "2024/11/2 - Physics and Beyond",
    "text": "2024/11/2 - Physics and Beyond\nBy Werner Heisenberg\nIt’s the first time I’m reading this in English; the title of the book in Korean is 부분과 전체, which might translate to Parts and the Whole. I’ve read it many times, and it has been highly influential to me as a physicist. To capture some of the things I want to revisit later:\n\n\n\nOn page 72, Fresh Fields (1926-1927)\n\n\n\n\n\nOn page 80, Fresh Fields (1926-1927)\n\n\nSo far, having read up to page 89, it has all been interesting, except for Chapter 4 (Lessons in Politics and History).",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#the-science-of-interstellar",
    "href": "reading.html#the-science-of-interstellar",
    "title": "Reading Archive",
    "section": "2024/11/9 - The Science of Interstellar",
    "text": "2024/11/9 - The Science of Interstellar\nToday, I rewatched the film Interstellar, perhaps for the fourth time. I was deeply impressed by Nolan’s previous film Inception, which I also probably watched five times already. Yesterday, I had to give Inception a 10-star rating for the first time in my life, as it just gets more interesting with every viewing. This 10-star rating is very special to me, as I have never rated any of the over 3,000 films I’ve watched so highly.\nAfter this purely fantastical journey, I became curious about the science behind it. Then I realised that the scientific adviser for the film, Kip Thorne, actually wrote a book about it! I knew I had planned to read Understanding Molecular Simulation today, but since it’s the weekend, I decided to indulge in this investigation instead.\n\n\n\nOn page 45, 4. Warped Time and Space, and Tidal Gravity\n\n\nWhat a beautiful way of interpreting general relativity!\nSo far, having read up to Chapter 6, it has all been very interesting! But since Monday has arrived, it’s time to focus on my project again…",
    "crumbs": [
      "Project Notes",
      "Reading Archive"
    ]
  },
  {
    "objectID": "notes.html#week-9",
    "href": "notes.html#week-9",
    "title": "Weekly Notes",
    "section": "Week 9",
    "text": "Week 9\n\n2024/11/13 Mathpix and Stochastic Processes\nFrancesco introduced a tool called Mathpix, which looks incredibly useful for converting handwritten notes from Goodnotes into formal documents!\nHe also shared his draft notes on random walks and stochastic processes: Handbook of Particle-Based Simulation of Fluids, which I can download as .ipynb files to experiment with the code.\nI also received a very warm, thoughtful email from Nigel, my supervisor. Since I’d like to reread it often, I want to preserve it here with password protection:\n\n  \nHi Sohyun,\n\nThanks for your messages. (I thought I’d move things to email as it is easier for longer conversations).\n\nHappy to talk about your worries at the next meeting. I would just say at the start that I am not currently concerned about your progress. It is normal at the start of a PhD to spend quite a lot of time “getting the lay of the land”. We appreciate that with such a lot of new ideas and concepts that things can sometimes feel overwhelming, and it can be difficult to separate the wood from the trees. Please be reassured that this is normal.\n\nI would also say that it is very positive that you are engaged with a good number of complex concepts and trying to understand them in your own terms. The students who don’t make progress are usually the ones who are not engaged, so again I think you can be reassured.\n\nWhen it comes to reading papers/books that we have suggested, I just wanted to comment that the way most scientists absorb information is usually not by sitting down, reading a paper from cover to cover and not putting it down until they understand every detail. If we did that, we wouldn’t get anything done. Rather we try to first get a feel for roughly what the message of the paper is talking about, the main ideas if you like, and very often that is as far as it goes. If there is something that we find particularly interesting or relevant we might go into more detail, but I would say that that is the exception. So, if we put papers on Zotero and suggest you look at them, we don’t mean that you need to read and understand everything in great detail. In most cases you might just want to get a rough idea of what a paper is about (AI can help here) and build up some familiarity with the types of approaches and language that are used in the field.\n\nAnother comment I would make is that it is not always necessary as a PhD student to be able to derive from first principles the methods and results that underpin your approach. Of course, we need to feel reasonably confident that we are using tried and tested techniques for which the strengths and weakness are known. But often the methods themselves might be based on decades of work drawn from vast fields of literature. If one were not to try to make progress until all the foundations had been thoroughly understood, then there would be little time left to measure things. I think it is quite right and proper that you want to understand where the Langevin or ABP equations of motion comes from and how this translates into a time stepping algorithm for evolving the system. But I don’t think one necessarily needs to go all the way back to Einstein’s original papers to do this.  You told me (I think in the context of your project last year) that you felt the need to understand all the foundations before making progress on the project. I would just comment that often we learn ‘on the job’, so to say, ie we might start calculating or measuring without understanding completely what we are doing or why, but the process of ‘doing’ builds that understanding.\n\nAnyway, I hope these comments help and we can certainly discuss further next week.\n\nBest wishes,\n\nNigel\n  \n\n\n\n  Type password to reveal the email:\n  \n  Submit\n\n\n\n\n\n2024/11/14 Reading Francesco’s notes\n\n\n\nOn One dimensional motion and its statistics, Random Walks\n\n\nDerivations: My handwritten notes\nStill not sure how \\(l^2\\) came in the equations…\n\n\n2024/11/16 Watching Biophysics Lectures\n \nI decided to watch lectures from weeks 1, 2, 4, and 5.\n\n\n\n\nLecture, Monday October 3rd\n\n\nThis was quite interesting, as it implies that the duality of the self and the world subsists in the possibility of having the same copy of DNA (which is also unique to myself compared to others, even though the similarity in DNA is striking across humans: approximately 99.9% of the DNA sequence is the same between any two individuals). For example, the clothes I am wearing now do not share the same DNA.\nHowever, after finishing week 1, it wasn’t very exciting. I would like to work with (idealised) mathematical objects that have relevance to empirical reality, not specific details about how DNA is formed, which chemicals and bonds are involved, or what functions it performs. When I was learning astrophysics, I remember only liking cosmology out of all the astrophysics fields because the other fields felt like the biology of stars, planets, or galaxies. It seems I’m not very interested in these phenomenological descriptions.\n\n\n\n\nLecture, Monday October 10th\n\n\nThis is quite interesting: the protein coat (capsid) enclosing the nucleic acid of a virus is always a multiple of 60, such as 60, 120, or 180. Why this number? Why does it exhibit icosahedral symmetry?\n\n\n\nLecture, Monday October 10th\n\n\nAlso, this is fascinating. Nature can achieve self-assembly, but humans cannot, no matter how much we know about the individual ingredients that make up these structures (even though the lecturer mentioned that simple structures like helices, such as the tobacco mosaic virus, can be made in the lab). Most of the lecture content here was quite engaging as it covered protein folding. I remembered writing an essay on AlphaFold for coursework while attending these lectures two years ago.\nBut no, as soon as the next lecture started covering the chemistry of protein folding and the formation of primary and secondary structures, it completely lost me. It took a few hours to complete one lecture because it was just not interesting.\n\n\n\n\nLecture, October 19th\n\n\nI guess that’s why I’m more interested in fungal networks than other life forms, which I find mundane…? After this quiz, there were further explanations about hydrogen bonding, van der Waals attractions, hydrophobic effects, and so on, but they were all nightmares and torturous. There were mentions of entropic costs, enthalpically favourable states, and other concepts, but without equations, it all felt hollow and uninteresting. I’m not sure if this was the lecturer’s fault or the content itself, but I hated learning about all this. No wonder I gave a score of just 2 for this unit. I wanted to stop, but I know the upcoming topics will be about self-assembly or molecular motors, so I decided to persevere… What torture!\n\nIt really makes me reflect on what I’ve been genuinely interested in. From my third year, I started rating how much I enjoyed each unit after finishing it, based on this scale:\n\n5: I found it very interesting\n\n4: Interesting\n\n3: Okay\n\n2: Not much fun\n\n1: I hated it\n\nHere are the scores for my third-year and fourth-year units:\n\n5: Quantum Physics / Physics Research Project\n\n4.5: Particle Physics, Analytical Mechanics / The Physics of Phase Transitions\n\n4: Methods of Theoretical Physics / Foundations of Modern Physics, General Relativity and Cosmology, Quantum Information Theory\n\n3.5: Materials Physics\n3: Environmental Physics\n\n2.5: Solid State Physics / Applied Materials Physics\n\n2: Biophysics\n\nBased on this, how did I end up choosing my PhD project in active matter? There were complex reasons for choosing it, as I outlined in 2024/11/15 - Proliferating Active Matter, but honestly, I should have thought it through more carefully (even though, at the time, I believed I was being very thorough).\nSo, what am I really interested in? It would be the foundations of modern physics: fairly mathematical work, possibly with computational approaches. However, I’m also deeply interested in neuroscience. I thought I would find a connection by pursuing active matter projects, as studying the brain is a subset of biology. Now, I’m not so sure…\nSo, I looked at the programme for the conference Statistical Physics of Cognition (happening in 10 days) to see if there is any research linking active matter and neuroscience. Although I couldn’t find one specifically about active matter, I found one that connects with non-equilibrium statistical physics:\n\n\n\nStatistical Physics of Cognition - Programme\n\n\nIt appears that the researcher has written several papers on this topic with William Bialek, who authored a seminal paper on applying the maximum entropy principle to elucidate collective behaviour in retinal neuronal networks (see Schneidman et al. (2006)), which inspired my MSci research project.\n\nSchneidman, Elad, Michael J Berry, Ronen Segev, and William Bialek. 2006. “Weak Pairwise Correlations Imply Strongly Correlated Network States in a Neural Population.” Nature 440 (7087): 1007–12.\n\n———. 2022b. “Emergence of Local Irreversibility in Complex Interacting Systems.” Physical Review E 106 (3): 034102.\nThe abstract of the first paper (Lynn et al. (2022b)):\n\nLiving systems are fundamentally irreversible, breaking detailed balance and establishing an arrow of time. But how does the evident arrow of time for a whole system arise from the interactions among its multiple elements? We show that the local evidence for the arrow of time, which is the entropy production for thermodynamic systems, can be decomposed. First, it can be split into two components: an independent term reflecting the dynamics of individual elements and an interaction term driven by the dependencies among elements. Adapting tools from nonequilibrium physics, we further decompose the interaction term into contributions from pairs of elements, triplets, and higher-order terms. We illustrate our methods on models of cellular sensing and logical computations, as well as on patterns of neural activity in the retina as it responds to visual inputs. We find that neural activity can define the arrow of time even when the visual inputs do not, and that the dominant contribution to this breaking of detailed balance comes from interactions among pairs of neurons.\n\nThe abstract of the second paper (Lynn et al. (2022a)):\n\nLynn, Christopher W, Caroline M Holmes, William Bialek, and David J Schwab. 2022a. “Decomposing the Local Arrow of Time in Interacting Systems.” Physical Review Letters 129 (11): 118101.\n\nWe show that the evidence for a local arrow of time, which is equivalent to the entropy production in thermodynamic systems, can be decomposed. In a system with many degrees of freedom, there is a term that arises from the irreversible dynamics of the individual variables, and then a series of non-negative terms contributed by correlations among pairs, triplets, and higher-order combinations of variables. We illustrate this decomposition on simple models of noisy logical computations, and then apply it to the analysis of patterns of neural activity in the retina as it responds to complex dynamic visual scenes. We find that neural activity breaks detailed balance even when the visual inputs do not, and that this irreversibility arises primarily from interactions between pairs of neurons.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "reading.html#section",
    "href": "reading.html#section",
    "title": "List of My Reading",
    "section": "2024/11/14 -",
    "text": "2024/11/14 -\nSkimming through many papers since I forgot to charge my iPad in my office… I think this is productive ahead of my Monday project meeting next week.\nWetting Transition of Active Brownian Particles on a Thin Membrane (Turci and Wilding 2021)\nTurci, Francesco, and Nigel B Wilding. 2021. “Wetting Transition of Active Brownian Particles on a Thin Membrane.” Physical Review Letters 127 (23): 238002.\n\nCited by 20\nUnfortunately, not very interesting. The authors (my supervisors) investigated how ABPs interact with a planar surface with barrier strength \\(\\epsilon_w\\); decreasing this makes the surface resemble a thin penetrable (or porous) membrane. The research implications would relate to artificial colloids or elementary swarm robots, but I’m not particularly interested in those systems.\n\n\n\nOn page 2, Partial and complete wetting of droplets of active Brownian particles\n\n\nThe above image is a good summary of what the research is about, which coincidentally is from what I’m currently reading:\nPartial and Complete Wetting of Droplets of Active Brownian Particles (Turci, Jack, and Wilding 2024)\nTurci, Francesco, Robert L Jack, and Nigel B Wilding. 2024. “Partial and Complete Wetting of Droplets of Active Brownian Particles.” Soft Matter 20 (9): 2060–74.\n\nCited by 5\nIt became quite technical from Chapter 2 onward, so I only read the introduction and the discussion & conclusions sections. I think I’m becoming increasingly uncertain about wanting to pursue my project. It doesn’t seem particularly mysterious or intriguing. I guess the highlight message of this article was that despite the inherent non-equilibrium mechanisms that engender phase separation and non-trivial flow patterns, the large-scale properties of the active model can be mapped onto an equilibrium one, which mean that we can use the techniques from equilibrium stats. mechanics such as renormalisation group which I was hoping to learn deeply in my PhD. If there were a connection between surface phase transitions of vapour inside the cap of my RDA (rebuildable dripping atomiser), it might be more interesting, but I think this is likely an equilibrium condition rather than something relevant to active matter. I must ask next week.\nMotility-Induced Phase Separation (Cates and Tailleur 2015)\nCates, Michael E, and Julien Tailleur. 2015. “Motility-Induced Phase Separation.” Annu. Rev. Condens. Matter Phys. 6 (1): 219–44.\n\nCited by 1579 (Really surprising of the attention of this topics!)\nThis one also, I only read the introduction and conclusion. I wanted to read this because MIPS keeps coming back in all papers. Essentialy, that phenomenon happens because active particles generically accumulate where they move more slowly. What’s really worth noting is that run and tumple model is inspired by e-coli and active brownian particles are inspired by synthetic colloids. Am I interested in both systems? No… I think I should have done this activity of skimming a lot of papers to see what I’m really interested in.\nProliferating active matter (Hallatschek et al. 2023)\nHallatschek, Oskar, Sujit S Datta, Knut Drescher, Jörn Dunkel, Jens Elgeti, Bartek Waclaw, and Ned S Wingreen. 2023. “Proliferating Active Matter.” Nature Reviews Physics 5 (7): 407–19.\n\nCited by 48\nI thought I should probably read papers which inspired me to investigate active matter in PhD almost about a year ago once more. One particular article, even though it didn’t seem popular to gain attractions, was written by Keller: ‘Active matter, then and now’ (Keller 2016). I loved reading it so much so I probably read like three times. Skipping that one this time, I now started to read the one with the title above: ‘Proliferating active matter’ which I also really enjoyed reading. I remember the start of the article was quite strong, mentioning the book that I often reread, ‘What is life?’ by Erwin Schrodinger, and also mentioning about the reshaping the chess board by active matter paradigm (which was probably something to do with breaking the mass reversal symmetry?) as if I play the physics game like a chess.\n\n\n\nKeller, Evelyn Fox. 2016. “Active Matter, Then and Now.” History and Philosophy of the Life Sciences 38: 1–11.",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#skimming-through-papers",
    "href": "reading.html#skimming-through-papers",
    "title": "List of My Reading",
    "section": "2024/11/14 - Skimming through papers",
    "text": "2024/11/14 - Skimming through papers\nSkimming through many papers since I forgot to charge my iPad in my office… I think this is productive ahead of my Monday project meeting next week.\nWetting Transition of Active Brownian Particles on a Thin Membrane (Turci and Wilding 2021)\nTurci, Francesco, and Nigel B Wilding. 2021. “Wetting Transition of Active Brownian Particles on a Thin Membrane.” Physical Review Letters 127 (23): 238002.\n\nCited by 20\nUnfortunately, not very interesting. The authors (my supervisors) investigated how ABPs interact with a planar surface with barrier strength \\(\\epsilon_w\\); decreasing this makes the surface resemble a thin penetrable (or porous) membrane. The research implications relate to artificial colloids or elementary swarm robots, but I’m not particularly interested in those systems.\n\n\n\nOn page 2, Partial and complete wetting of droplets of active Brownian particles\n\n\nThe above image is a good summary of what the research is about, which coincidentally is from what I’m currently reading:\n\nPartial and Complete Wetting of Droplets of Active Brownian Particles (Turci, Jack, and Wilding 2024)\nTurci, Francesco, Robert L Jack, and Nigel B Wilding. 2024. “Partial and Complete Wetting of Droplets of Active Brownian Particles.” Soft Matter 20 (9): 2060–74.\n\nCited by 5\nIt became quite technical from Chapter 2 onward, so I only read the introduction and the discussion & conclusions sections. I think I’m becoming increasingly uncertain about wanting to pursue my project. It doesn’t seem particularly mysterious or evoking my curiosity. I guess the highlight of this article was that, despite the inherent non-equilibrium mechanisms that engender phase separation and non-trivial flow patterns, the large-scale properties of the active model can be mapped onto an equilibrium one. This means that we can use techniques from equilibrium statistical mechanics, such as the renormalisation group, which I was hoping to learn deeply in my PhD.\nIf there were a connection between surface phase transitions of vapour inside the cap of my RDA (rebuildable dripping atomiser), it might be more interesting and relating to my interests, but I think this is likely an equilibrium condition rather than something relevant to active matter. I must ask next week.\n\nMotility-Induced Phase Separation (Cates and Tailleur 2015)\nCates, Michael E, and Julien Tailleur. 2015. “Motility-Induced Phase Separation.” Annu. Rev. Condens. Matter Phys. 6 (1): 219–44.\n\nCited by 1579 (Really surprising how much attention this topic has received!)\nThis one, too, I only read the introduction and conclusion. I wanted to read this because MIPS keeps appearing in many papers. Essentially, this phenomenon occurs because active particles generically accumulate where they move more slowly. What’s really worth noting is that the run-and-tumble model is inspired by E. coli, while active Brownian particles are inspired by synthetic colloids. Am I interested in either system? No… I think I should have done this activity of skimming through many papers earlier to clarify what I’m truly interested in.\n\nProliferating Active Matter (Hallatschek et al. 2023)\nHallatschek, Oskar, Sujit S Datta, Knut Drescher, Jörn Dunkel, Jens Elgeti, Bartek Waclaw, and Ned S Wingreen. 2023. “Proliferating Active Matter.” Nature Reviews Physics 5 (7): 407–19.\n\nCited by 48\nI thought I should probably reread papers that inspired me to investigate active matter in my PhD almost a year ago. One particular article, even though it didn’t seem to attract much attention, was written by Keller: ‘Active Matter, Then and Now’ (Keller 2016). I loved reading it so much that I probably read it three times. Skipping that one this time, I started reading Proliferating Active Matter, which I also really enjoyed.\n\nKeller, Evelyn Fox. 2016. “Active Matter, Then and Now.” History and Philosophy of the Life Sciences 38: 1–11.\nI remember the start of the article being quite strong, mentioning the book that I often reread, What Is Life? by Erwin Schrödinger, and also discussing the reshaping of the chessboard by the active matter paradigm (which was probably something to do with breaking mass-reversal symmetry?)—as if I were playing the physics game like chess.\nWhile reading (just before the chapter Motile Proliferating Matter), I got sidetracked because it wasn’t really interesting anymore. It seems my interests have shifted over the summer or possibly during the final stages of my MSci research project. It sort of makes sense when I think about it in terms of the timeline.\n\nIn January 2024, when I was applying for my PhD {#sec-applying-phd}:\n\nI wanted to pursue new physics. It appeared to me that two of my favourite fields (general relativity and quantum field theory) were already well-explored and largely complete.\nI also wanted to gain more employability skills, as I hoped to work at Google DeepMind after my PhD. I thought a computationally driven project was essential for this.\nEager to formally learn about the renormalisation group, I looked into areas of new physics related to it. That’s when I discovered the emerging field of active matter. After reading Keller’s account of its history and emergence, as well as McGivern’s account of how it relates to cognition (which I should probably revisit tomorrow), I thought, this is it! This was the field I wanted to pursue! I met Nigel, who was such a brilliant and thoughtful person to talk with, and Francesco, who had already been amazing. I applied directly (and, in fact, only applied for this PhD, while my peers were applying for multiple positions).\nIn my second term, I was also in the process of interviewing with Samsung Electronics, as they invited me to take on a data scientist role (this happened in early January, I think?). The role and salary were very attractive. However, once I received the final offer, I had to think deeply about what I truly wanted to do. There were still unsolved mysteries I hoped to explore during my PhD. I was curious about fundamental questions like: What is time? What is space? I thought about relativity theory and how Einstein built his ideas around the concept of a universal clock, which doesn’t depend on the mechanisms of the clock itself. But these clocks are also within a gravitational field. Can we truly justify that reading a clock on an observer’s wrist is the correct way to measure time, given that all clocks are fundamentally based on electromagnetism?\nSo, I declined the job offer and decided to stay at university for another four years. Over the summer holidays, I continued reading neuroscience books (particularly on dreams and altered states of consciousness) and considered which topics would be interesting to investigate throughout my PhD.\n\nBefore sleeping, I started reading Time and Quantum Clocks: A Review of Recent Developments (Altaie, Hodgson, and Beige 2022), which I found very interesting.\n\nAltaie, M Basil, Daniel Hodgson, and Almut Beige. 2022. “Time and Quantum Clocks: A Review of Recent Developments.” Frontiers in Physics 10: 897305.\n\nActive Materials: Minimal Models of Cognition? (McGivern 2020)\nMcGivern, Patrick. 2020. “Active Materials: Minimal Models of Cognition?” Adaptive Behavior 28 (6): 441–51.\n\nCited by 20\nThe next morning, I felt compelled to reread this paper, as it was one of the key works that truly ignited my interest in the field of active matter.\n\n\n\nOn page 8, 3. Minimal models\n\n\nYes! This was it! I was curious whether a simple model of active matter that I learn could be applied to biological systems by examining if they fall into the same universality class as a realistic model through the application of renormalisation group techniques.\nVery interesting. I’m glad I read it once again. I wonder what my supervisors think about this article. I thought it would be useful to clarify whether I truly want to pursue the field of biophysics (as I’m not particularly interested in synthetic colloids), so I decided to revisit the biophysics lectures (see 2024/11/16 Watching Biophysics Lectures).",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#sec-skimming-papers",
    "href": "reading.html#sec-skimming-papers",
    "title": "List of My Reading",
    "section": "2024/11/14 - Skimming through papers",
    "text": "2024/11/14 - Skimming through papers\nSkimming through many papers since I forgot to charge my iPad in my office… I think this is productive ahead of my Monday project meeting next week.",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "notes.html#week-10",
    "href": "notes.html#week-10",
    "title": "Weekly Notes",
    "section": "Week 10",
    "text": "Week 10\n\n2024/11/19 Continuing to Watch Biophysics Lectures\n\n\n\nLecture, Monday October 24th\n\n\nInteresting!\n\n\n\n\nLecture, Wednesday October 26th\n\n\nThere is a whole branch of physics called soft matter, which investigates viscoelastic types of materials. At Harvard, there is a seminar series called Squishy Physics, which describes it quite well. And, of course, biological materials form the heart of soft matter.\n\n\n\n\nLecture, Wednesday October 26th\n\n\nThe image source: Microtubules: the basics\n\n\n\n\nLecture, Wednesday October 26th\n\n\n\n\n\nImmune System Science GIF\n\n\nThis lecture (Wednesday October 26th) has been particularly interesting, as it delved into the dynamics of cells. Topics included microtubules growing and collapsing to induce cell movement, how blood cells squeeze through capillaries (this was adorable! Although I think it was mentioned in the previous lecture), and connections to soft matter physics, where I feel most aligned. There were also discussions about self-assembly, which were very interesting.\nSo, the topics that interest me in biophysics are cell dynamics, self-assembly (and disassembly).\n\n\n2024/11/21 A liquid droplet\nSuddenly, a strange thought occurred, which I was trying to phrase to ask my supervisor:\n\nI’ve been thinking about the shape of a liquid droplet on a surface, particularly how it changes with wetting states. On a superhydrophobic surface, the droplet appears almost perfectly spherical because it minimises contact with the surface. As the surface becomes less hydrophobic, transitioning to a partially wetting state, the droplet flattens into a spherical cap shape. I was wondering if this change in shape could be thought of as a conceptual process where the spherical droplet ‘expands,’ exposing less of its ‘head’ above the surface as it flattens. In the extreme limit of complete wetting, it could correspond to a large sphere overlaying the surface, with only a tiny portion visible above it. Has anyone investigated this kind of analogy or thought about the wetting transition in a similar way?\n\nI have derived some expressions in these handwritten notes, but I’m not sure where to go with this.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "direction.html",
    "href": "direction.html",
    "title": "Redirection of PhD",
    "section": "",
    "text": "Also, for the next project meeting, I think it’s probably worthwhile to discuss several concerns I have at this stage.\n\nRight now, I’m focusing on reading about molecular dynamics simulation. However, I’ve been told many times that a lot of the techniques discussed in this book are not related to active matter projects. Do you think it would be better to start reading the references on Zotero instead? There is a lot of material (one book, 21 papers, online resources, as well as code) being presented to me, but it’s not really clear to me what the priority is.\nThere were things that I wanted to discuss last week (see 2024/11/2 Things to discuss and 2024/11/4 Diary), but since not everyone could be present, it was postponed. The notes I wrote on 4 November reflect my feelings about our project and my progress in the PhD. I wonder if these points would be better discussed in the next project meeting before starting the book club meeting.\n\n\n\n\nHi Sohyun,\nThanks for your messages. (I thought I’d move things to email as it is easier for longer conversations).\nHappy to talk about your worries at the next meeting. I would just say at the start that I am not currently concerned about your progress. It is normal at the start of a PhD to spend quite a lot of time “getting the lay of the land”. We appreciate that with such a lot of new ideas and concepts that things can sometimes feel overwhelming, and it can be difficult to separate the wood from the trees. Please be reassured that this is normal.\nI would also say that it is very positive that you are engaged with a good number of complex concepts and trying to understand them in your own terms. The students who don’t make progress are usually the ones who are not engaged, so again I think you can be reassured.\nWhen it comes to reading papers/books that we have suggested, I just wanted to comment that the way most scientists absorb information is usually not by sitting down, reading a paper from cover to cover and not putting it down until they understand every detail. If we did that, we wouldn’t get anything done. Rather we try to first get a feel for roughly what the message of the paper is talking about, the main ideas if you like, and very often that is as far as it goes. If there is something that we find particularly interesting or relevant we might go into more detail, but I would say that that is the exception. So, if we put papers on Zotero and suggest you look at them, we don’t mean that you need to read and understand everything in great detail. In most cases you might just want to get a rough idea of what a paper is about (AI can help here) and build up some familiarity with the types of approaches and language that are used in the field.\nAnother comment I would make is that it is not always necessary as a PhD student to be able to derive from first principles the methods and results that underpin your approach. Of course, we need to feel reasonably confident that we are using tried and tested techniques for which the strengths and weakness are known. But often the methods themselves might be based on decades of work drawn from vast fields of literature. If one were not to try to make progress until all the foundations had been thoroughly understood, then there would be little time left to measure things. I think it is quite right and proper that you want to understand where the Langevin or ABP equations of motion comes from and how this translates into a time stepping algorithm for evolving the system. But I don’t think one necessarily needs to go all the way back to Einstein’s original papers to do this. You told me (I think in the context of your project last year) that you felt the need to understand all the foundations before making progress on the project. I would just comment that often we learn ‘on the job’, so to say, ie we might start calculating or measuring without understanding completely what we are doing or why, but the process of ‘doing’ builds that understanding.\nAnyway, I hope these comments help and we can certainly discuss further next week.\nBest wishes,\nNigel\n\n\n\nIt seems my interests have shifted over the summer or possibly during the final stages of my MSci research project. It sort of makes sense when I think about it in terms of the timeline.\nIn January 2024, when I was applying for my PhD:\n\nI wanted to pursue new physics. It appeared to me that two of my favourite fields (general relativity and quantum field theory) were already well-explored and largely complete.\nI also wanted to gain more employability skills, as I hoped to work at Google DeepMind after my PhD. I thought a computationally driven project was essential for this.\nEager to formally learn about the renormalisation group, I looked into areas of new physics related to it. That’s when I discovered the emerging field of active matter. After reading Keller’s account of its history and emergence, as well as McGivern’s account of how it relates to cognition (which I should probably revisit tomorrow), I thought, this is it! This was the field I wanted to pursue! I met Nigel, who was such a brilliant and thoughtful person to talk with, and Francesco, who had already been amazing. I applied directly (and, in fact, only applied for this PhD, while my peers were applying for multiple positions).\nIn my second term, I was also in the process of interviewing with Samsung Electronics, as they invited me to take on a data scientist role (this happened in early January, I think?). The role and salary were very attractive. However, I had to think deeply about what I truly wanted to do. There were still unsolved mysteries I hoped to explore during my PhD. I was curious about fundamental questions like: What is time? What is space? I thought about relativity theory and how Einstein built his ideas around the concept of a universal clock, which doesn’t depend on the mechanisms of the clock itself. But these clocks are also within a gravitational field. Can we truly justify that reading a clock on an observer’s wrist is the correct way to measure time, given that all clocks are fundamentally based on electromagnetism?\nSo, I decided to stay at university for another four years. Over the summer holidays, I continued reading neuroscience books (particularly on dreams and altered states of consciousness) and considered which topics would be interesting to investigate throughout my PhD.\n\n\n\n\nSee 2024/11/16 Watching Biophysics Lectures\n\nIt really makes me reflect on what I’ve been genuinely interested in. From my third year, I started rating how much I enjoyed each unit after finishing it, based on this scale:\n\n5: I found it very interesting\n\n4: Interesting\n\n3: Okay\n\n2: Not much fun\n\n1: I hated it\n\nHere are the scores for my third-year and fourth-year units:\n\n5: Quantum Physics / Physics Research Project\n\n4.5: Particle Physics, Analytical Mechanics / The Physics of Phase Transitions\n\n4: Methods of Theoretical Physics / Foundations of Modern Physics, General Relativity and Cosmology, Quantum Information Theory\n\n3.5: Materials Physics\n3: Environmental Physics\n\n2.5: Solid State Physics / Applied Materials Physics\n\n2: Biophysics\n\nBased on this, how did I end up choosing my PhD project in active matter? There were complex reasons for choosing it, as I outlined in 2024/11/14 - Skimming through papers, but honestly, I should have thought it through more carefully (even though, at the time, I believed I was being very thorough).\nSo, what am I really interested in? It would be the foundations of modern physics—fairly mathematical work, possibly with computational approaches. However, I’m also deeply interested in neuroscience. I thought I would find a connection by pursuing active matter projects, as studying the brain is a subset of biology. Now, I’m not so sure…\n\n\n\n\n\nContinuous time or discrete time are names. Just the named.\n\n\n\nWetting and drying, it’s not beautiful. It’s such a domain of such an abstract domain.\nTime and space, I’m always experiencing. I want to study something that I’m always experiencing.\n\n\n\nThe reason Einstein’s theory is beautiful is because it’s the ULTIMATE PATTERN!\nSpace and time are interlinked! Energy and mass are the same! Mass is equal to frequency!1 The beauty of mathematics was that ‘equality’ sign!\nJust a very simple relationship revealed by mathematics!\nThat was the whole purpose of physics!\nNo matter what complicated language we use to describe concepts,\nThere comes the language of physics: “They are the same!”\nI cannot stop laughing.\n“Stop arguing! They are the same!”\nThe reason the renormalisation group naively appeared as beautiful was because, as we went to higher levels of description, we somehow discovered: ‘Oh! They are the same!’\nNow it all makes sense.\nThe reason the proof of Fermat’s Last Theorem was beautiful was because it linked modular forms to elliptic curves! They are the same!\nThe reason Euler’s relation is beautiful is because it links \\(e\\), \\(\\pi\\), \\(i\\), and \\(-1\\)!\nThe reason criticality is beautiful is because the Ising model and liquid-gas model, ‘only’ at the critical point, are the same! Hence the name ‘Universality’!\nThe reason Maxwell’s equations are beautiful is because they show that electric fields and magnetic fields are the same! The whole phenomenon you’ve been looking at, which you thought was different, is just the same!\nThe reason nature is beautiful is because it is the same thing! Not different things! The breath of perceiving their sameness!\nThe driving motivation for me in my MSci was to say: ‘Hey! The market and the brain are THE SAME!’\nI’ve been just chasing this beauty for my entire lifetime!\n1 By combining \\(E = mc^2\\) and \\(E = hf\\), \\[\nE = mc^2 = hf \\implies f = \\frac{mc^2}{h}\n\\]\n\n\n\n\nTo get this sense of beauty, the things that are left and right of the equality sign have to be the systems that I’m truly interested in. The reason that the investigation of drying or wetting in non-equilibrium contexts using a very specific model (active Brownian particles) is not beautiful is because none of the systems that I’m considering (which is biology) are my interests!\nI don’t care about biology! I’m afraid of insects!\n\n\n\nWe see the same beauty, But the beauty is not the same.\nWe see everyone’s face, but not ours. We find the sameness between different things, but I’m not a thing that relates to those things. When seeking the sameness between me and the others, it falls into trouble. That’s why we can’t see our face. That’s why I can’t see my face. So that I do not self-reference.\n\n\n\nI have a PhD project I want to do: ‘Equality’ sign in physics. Starting from \\(F = ma\\), all the way to \\(E = mc^2\\) and \\(E = hf\\) Searching for what are the left equalities.\nStart the proposal: ‘Considering a PhD project on the theme of the ‘Equality’ sign in physics, exploring its role from foundational equations like \\(F = ma\\) to \\(E = mc^2\\) and \\(E = hf\\), and identifying other significant equalities.’\n\n\n\nIf I think about my current project as spontaneous symmetry breaking, it is kind of interesting.\n\n\n\n\nAfter having a project meeting discussing these points: 2024/11/18 Weekly Project Meeting\n\nDear Sohyun,\nI am writing to follow up on our conversation yesterday when you told me that you are no longer interested in pursuing your PhD project on surface phase transitions in active matter. I have to say that personally, I think that this is a pity because Francesco Turci and I are really excited by the idea of making progress on this topic which represents an unexplored frontier of non-equilibrium statistical physics (as are other people like Rob Jack and Mike Cates in Cambridge University). I would also note that I rather struggle to understand how this can be a fully informed decision when you have not yet engaged with the project in a meaningful way beyond reading a few background papers. However, if you really can muster no enthusiasm for the topic then I must accept that.\nActive Matter is one of the main areas in which I see my research focussing for the foreseeable future. Are you ruling out just the particular project, or do you no longer wish to work in the field of Active Matter at all? If the latter, then the areas of potential overlap for projects that I am qualified and willing to supervise is limited. Furthermore, if the topic were to change significantly, we would need to seek approval from the Faculty who awarded you UoB funding to do a PhD and who may insist that to retain the funding you don’t stray far from the topic for which your funding was agreed as constituting a strategic priority for the school.\nNevertheless, and with this caveat, there may be some options to consider. I have made a tentative list (see attached pdf), which naturally reflects my interest and background in simulation of phase transitions and critical phenomena in both equilibrium and non-equilibrium statistical physics and soft matter. Please look at the list of topics in the middle column of the document. I am happy to discuss what each project might entail at our meeting on Monday.\nI am also happy for you to suggest a PhD project topic. But if you do this, I think that you need to go away and read about the topic in detail and prepare a written proposal that is both convincing in terms of potential for original research (as defined in the UoB PhD regulations) and likely to overlap with my research interests and expertise. Again, the topic would need to be acceptable to your funders in the faculty. To avoid wasting any time, I’ve also prepared a non-exhaustive list (third column) of projects that I happen to know from our conversations that you are interested in, but which I do not feel sufficiently well qualified or motivated to supervise.\nI think that in this situation it would be useful for you to seek some independent advice on possible next steps. Dr Ian Lindsay is the PGR director for the School of Physics and has indicated to me that he would be happy to meet with you to discuss the situation and explain any formal processes that apply. I would strongly suggest that you take him up on this offer and write to him to arrange a meeting. His email is i.d.lindsay@bristol.ac.uk\nBest regards\nNigel\n\n\n\nHi Nigel,\nThank you very much for your email. I completely agree that it was not a fully informed decision, as I have not yet engaged much with the simulation side of things. That is something I have been trying to address since yesterday. When I went back home, I came across the paper ‘Critical Motility-Induced Phase Separation Belongs to the Ising Universality Class’, which seemed so interesting that I thought it might be worthwhile to attempt simulations of active Brownian particles at the critical MIPS in 2D. Although computational resources would be demanding, it would be very interesting to perform renormalisation to rescale the system and demonstrate its scale-invariant features like the critical Ising model.\nI remain very interested in active matter because it represents a compelling and novel paradigm in physics that resonates with my ideas deeply. I am also not ruling out our current project. I shared my personal concerns in the hope of gaining further inspiration for the current project, and I apologise if I inadvertently gave the impression that I have no interest in either this project or the overarching theme I have chosen.\nI will not be in Bristol next Monday or Tuesday, so should we reschedule the meeting to later this week or next Wednesday? Thank you also for the separate document. I will read through the topics, as I am still quite naïve with many of the fields mentioned.\nThank you for introducing Ian, but at this stage, I would like to refine my thoughts further by exploring your suggestions first. It seems that I was too hasty in yesterday’s meeting, and, in hindsight, I probably should not have brought up my concerns in the way that I did.\nThank you, as always, for your support.\nSohyun\n\n\n\n다시 다 읽어봤어.\n엄마가 보기에 학문적 접근이 4학년이 되면서 본격적으로 이루어졌고, 물리학에 관해서 이해하면서 앎의 지평이 크게 늘었다고 생각해.\n물론, 너의 호기심을 만족시켜줄수 있는 부분은 다분히 철학적인면, Fundamental 한것이고, 석사하면서 너가 실험적으로 해본것은, Active matter를 연구하게 되는것까지 된것이 아닌가 싶어. 그래서 그 분야에서 펀딩을 받으며 지금의 너가 있는데, 음…한번 너가 이야기했던것이 기억나. 물리학의 발견은 이미 거의 다 이루어져서 새로이 먼가를 발견하는것은 힘들다 했던것같아. 석사과정 그리고 박사과정 몇달동안 심층적으로 공부가 된것같고, 엄마는 잘 모르지만, 아직 Supervisor 와의 프로젝트에 적극적으로 하지못한 부분이 있으니, 심화된 이해를 갖춘 바탕으로 연구를 차근 해보는것은 어떨까 생각해.\n물리학을 전혀 모르는 엄마로서는 이번에는 머라 딱히 해줄 수 없는데, 너의 여정을 지켜본 엄마로서 봤을때에는 지금은 흥미롭지는 않더라도, 새로운 선구적인 연구를 하게될때에 또 다른 즐거움이 나타나지 않을지,.\n참,.. 고민 많았지. 컴퓨터 공학 ㅡ 천체물리학 ㅡ 물리학 ㅡ 관심이 어디에 쏠려있느냐에 따라 전과도 하고, 배움의 길을 걸어왔는데, 앞으로의 행보에 대해 고민이 더더욱 되는건 당연할꺼야. 관련된 교수진들을 만나보면서, 너가 어떤 연구방향으로 가게될지 자연스럽게 알게될것같아.\n\n\n\nDear Nigel and Francesco,\nI feel that it’s quite unfortunate that our project meeting ended abruptly today. After having a conversation with Ian, it became quite clear to me that there were misunderstandings in our previous meeting last week, so I hoped to clarify those today as I realised that was an important step.\nI deeply appreciate that you set two agendas to talk about today, and both of them were really helpful! Also, you allowed me to mention what I hoped to talk about after we went through those agendas. However, I felt that when I started to bring up a conversation for clarifying my points, it appeared that both of you wanted me to leave before resolving the misunderstandings. I tried to address those concerns, but it just didn’t work, and I started to wonder if my way of communicating was not correct.\nIn our previous meeting, the reason I mentioned the vape products was because I wanted to talk about how wetting and spreading (or drying) could be interesting to me in terms of my own experiences (even though it was not an active fluid), but you misunderstood me as hoping to make a new vape product (which you wrote in the document that you can’t supervise). The whole point of the previous meeting last week was for me to consult with you on why our initial project was interesting from your perspectives. You mentioned that you started to investigate drying at first but didn’t see any drying. Also, the point I raised to Ian and you was that we don’t observe a drying transition in active fluids in real life, so I hoped to understand your motivation for pursuing it.\nI chose my PhD in active matter because I was largely inspired by two philosophical papers:  1. Keller, Evelyn Fox. 2016. “Active Matter, Then and Now.” History and Philosophy of the Life Sciences 38: 1–11.  2. McGivern, Patrick. 2020. “Active Materials: Minimal Models of Cognition?” Adaptive Behavior 28 (6): 441–51.\nThis new field, which has gained significant popularity over the past 20 years, struck me as a paradigm shift. The advertised project was quite general, and in January, you mentioned that it could evolve based on my interests. However, once I started my PhD, I was given an initial project that, if I were to summarise concisely (for Ian), involves investigating how active Brownian particles (ABPs), which evolve through overdamped Langevin equations, interact with surfaces to induce drying surface phase transitions via molecular dynamics simulations. What was very interesting about this model was that, without any attractive interactions, the particles form large-scale structures, described as motility-induced phase separation, simply by turning on activity (motility). Also, it appeared that this model maps to artificial colloids (e.g., Janus particles) or motile bacteria.\nThe problem arose from the fact that I’ve never observed a drying transition in these systems in empirical reality, which kept bringing me back to the map-territory relation. I was also uncertain whether the results I might obtain could be generalisable to a broader class of active matter systems. As I was reading Physics and Beyond by Werner Heisenberg, I came across Einstein’s remark: “It is the theory which decides what we can observe,” made after he considered Mach’s perspective to be naïve. However, it seemed to me that, as I was reading through papers and articles, many statistical physicists simply play with models without carefully examining their assumptions or their relation to empirical evidence. I tried raising this concern last week so that I could gain a different perspective from you, but if it was to be largely dismissed as being “too philosophical” to pursue further discussion, then that’s fine, but it’s just unfortunate.\nSo, in summary, I raised my concern to gain more insights from you, while you understood it as me having completely lost interest in the project, which I found out with Ian was a miscommunication.\nAlso, in terms of progress, yes, I did engage with other materials outside our project (these are for fun and not to be confused with what I do during my working hours). But I have always spent a lot of time reading articles and papers related to our project, as well as understanding the code. In the beginning, you clearly pointed out that, as a PhD student, at first, it’s important to understand the wider context, and it’s a mistake for them to just start working on the problems without this background reading. I’ve been doing so, and you said in the first email (which you sent on the 13th) that you were not worried about my progress. Then, in your second email after our project meeting, I was told that I’m not making meaningful progress.\nI’m quite confused about all this. It takes a long time to read papers from a new field because, during my undergraduate studies, we didn’t cover non-equilibrium statistical physics or colloidal physics. For example, Francesco asked me if I had learned about random walks, but we also didn’t cover this basic concept either! Also, it takes a long time to understand the code written in C++. Yes, there are similarities as I did C and Java in the past, but even a single file such as fix_abp.cpp has a lot of links to other codes such as fix_abp.h, force.h, random_mars.h, etc.\nAs you pointed out in terms of supervision, yes, I won’t raise any philosophical concerns or my interests outside the set project at all. Because if I try to do so, it seems I create misunderstandings. However, I did want to emphasise that my mind is now clear, and maybe I could bring what I wrote on the 25th, which summarises how my motivation and ambition have settled:\n\nWhen I got home, I had a phone call with my mum and shared how much the situation had changed. Reflecting on what I said to her:\nWhile I was at the train station for hours, I found myself thinking deeply about my project, the papers I read last week, and my conversations with Nigel and Ian. I realised that my project presents a perfect opportunity to learn about useful concepts for describing non-equilibrium systems, such as entropy production, the Fokker–Planck equation, and the fluctuation-dissipation theorem. Now, investigating these concepts using the simplest models from the particle perspective of active matter feels really exciting! If a drying transition is observed, it will also be a great chance to master the theoretical understanding and application of renormalisation group techniques.\nReading various papers helped me appreciate how interesting colloids and bacteria can be. Bacteria represent the simplest form of living systems, and through motility-induced phase separation, these systems form large-scale structures without any attractive interactions. Thinking about surface phase transitions became particularly intriguing when I considered how 3D structures form 2D boundaries. Boundaries are key to how we differentiate objects. Even in comics, we draw the boundaries of characters and objects. This perspective made the topic even more interesting.\nI also admire how my supervisors approached the problem, using an order parameter to measure the asymmetry within the capillary system. This method effectively avoids the complexities of defining surface tensions and focuses instead on the geometrical aspects of the problem. Once these ideas crystallised in my mind, I felt certain that I wanted to become an expert in this field. If someone asks about surface phase transitions in non-equilibrium systems, I want to be the person they turn to for advice.\nThese thoughts were swirling in my mind, and strangely, the weather even stopped me from travelling to London to attend the Statistical Physics of Cognition conference, where I had planned to network with people in that field. I don’t believe in mystical things, but the timing was mysterious. This kind of weather disruption, preventing travel between cities, hasn’t happened to me in my five years living in the UK.\nI was also thinking about Nigel and Francesco and how thoughtful they both are. I want to become a light that brightens the path for us.\n\nBut, as you pointed out, I will separate our project notes from my logbook on my project website. Also, thank you very much for introducing the critical Casimir effect in active fluids analogues. I’ll read through the materials on my own over this week. (Initially, as my mind has settled, I was going to work on the simulation side as I wasn’t certain how to construct a wall as you did in your papers with my given code, but I will delay that work until next week.)\nSomehow, your email which followed from our meeting just now has arrived while I was writing this email. I’ll read through your email after I send this.\nThank you, Sohyun\n\n\n\nDear Sohyun (cc Francesco, Ian),\nI wanted to follow up on our meeting today and reiterate and elaborate in writing some of the points covered.\nAs you had previously expressed reservations about continuing with the Active Drying project, we discussed an alternative project in Active Matter centred around the Critical Casimir Effect. You said that on reflection you are happy to continue with the original project, and we agreed that we could keep the Critical Casimir Effect project as a backup or as a topic for future work.\nOn more general matters, we stated that from the point of view of the student-supervisor relationship, there needs to be a clear separation between your work on the project and outside interests. The responsibilities of PhD supervisors do not extend beyond supporting your work on the project and advising/supporting should there be any issues (eg illness/personal situation) that are affecting your ability to progress with the project. Project meetings are therefore not for discussing anything with you except the science of the project or pastoral issues that may be affecting your ability to work.\nSimilarly, if you want to use a blog as a lab book to record progress and notes on papers read etc, this is laudable and desirable for facilitating discussions, but what you have been writing and sharing with us has turned into a sort of personal diary and that’s inappropriate for the student-supervisor relationship. If you want us to read things then they need to be confined to matters directly related to the project.\nBeing a successful PhD student requires a certain level of commitment. While it is early days and we don’t have serious concerns about your progress, we do note that you seem to be spending considerable time writing blogs and thinking about philosophy, vaping, neuroscience, and reading and rereading books, and lecture notes, etc., the relevance of which is not clear. While you can of course do what you want in your own time, we feel that you need to take care not to blur the boundaries between what is in scope for the project work and what is not. From your blog and recent conversations, we are concerned that this might be happening.\nI hope that these comments are helpful. They are not intended to be critical – we just want you to have clear and realistic expectations of the process so that you have a satisfied, enjoyable, and successful PhD journey.\nBest regards\nNigel and Francesco\n\n\n\nDear Nigel,\nThank you for your email. I’ve been reading about the critical Casimir effect, and it’s so interesting! There was research using the run-and-tumble model by Ray et al. in 2014, and since run-and-tumble and ABPs can be mapped onto each other, I thought this paper was quite relevant, so I uploaded it to Zotero (under the category of Active Casimir Effect). Also, there was a concise review on this theme by Bechinger et al. in 2016. Even recently, there has been work on this topic using flocking active matter by Fava et al. in 2024. It’s so interesting, and I deeply appreciate you coming up with this suggestion! By Monday next week, I’ll read more and finalise my choice, though at this stage, I feel it would be more worthwhile to continue with the active drying project first to apply the concepts I’ve learned over the past two months in simulations. If that’s the decision, I can see myself working on the active Casimir effect right after the initial project.\nYes, I won’t share anything unrelated to the project anymore. If I may offer an excuse, there were two occasions I shared something: one was a dialogue related to active matter on 17th of September, and the other was a note on ‘things to discuss’ for the project meeting when I was concerned about the project two weeks ago. I thought both were related, but I apologise and appreciate your pointing out that they were not the right forms to share. I won’t do it again.\nI have honestly felt quite isolated at times this semester as the only PhD student in theoretical physics investigating active matter. So, it was such an enjoyable opportunity for me to have a conversation with you and Francesco, even in broader contexts beyond our project. However, I’ll make sure to confine my conversations strictly to the current project.\nYour comments have been helpful, and I’ll be more realistic from now on. I have also closed the website, as I probably enjoyed designing it a bit too much. While it was intended to document everything I do during my PhD in a self-contained way, it may not have conveyed how much time I dedicate to our project.\nThank you,\nSohyun",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#my-teams-message-to-nigel-and-francesco",
    "href": "direction.html#my-teams-message-to-nigel-and-francesco",
    "title": "Redirection of PhD",
    "section": "",
    "text": "Also, for the next project meeting, I think it’s probably worthwhile to discuss several concerns I have at this stage.\n\nRight now, I’m focusing on reading about molecular dynamics simulation. However, I’ve been told many times that a lot of the techniques discussed in this book are not related to active matter projects. Do you think it would be better to start reading the references on Zotero instead? There is a lot of material (one book, 21 papers, online resources, as well as code) being presented to me, but it’s not really clear to me what the priority is.\nThere were things that I wanted to discuss last week (see 2024/11/2 Things to discuss and 2024/11/4 Diary), but since not everyone could be present, it was postponed. The notes I wrote on 4 November reflect my feelings about our project and my progress in the PhD. I wonder if these points would be better discussed in the next project meeting before starting the book club meeting.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#email-received-from-nigel",
    "href": "direction.html#email-received-from-nigel",
    "title": "Redirection of PhD",
    "section": "",
    "text": "Hi Sohyun,\nThanks for your messages. (I thought I’d move things to email as it is easier for longer conversations).\nHappy to talk about your worries at the next meeting. I would just say at the start that I am not currently concerned about your progress. It is normal at the start of a PhD to spend quite a lot of time “getting the lay of the land”. We appreciate that with such a lot of new ideas and concepts that things can sometimes feel overwhelming, and it can be difficult to separate the wood from the trees. Please be reassured that this is normal.\nI would also say that it is very positive that you are engaged with a good number of complex concepts and trying to understand them in your own terms. The students who don’t make progress are usually the ones who are not engaged, so again I think you can be reassured.\nWhen it comes to reading papers/books that we have suggested, I just wanted to comment that the way most scientists absorb information is usually not by sitting down, reading a paper from cover to cover and not putting it down until they understand every detail. If we did that, we wouldn’t get anything done. Rather we try to first get a feel for roughly what the message of the paper is talking about, the main ideas if you like, and very often that is as far as it goes. If there is something that we find particularly interesting or relevant we might go into more detail, but I would say that that is the exception. So, if we put papers on Zotero and suggest you look at them, we don’t mean that you need to read and understand everything in great detail. In most cases you might just want to get a rough idea of what a paper is about (AI can help here) and build up some familiarity with the types of approaches and language that are used in the field.\nAnother comment I would make is that it is not always necessary as a PhD student to be able to derive from first principles the methods and results that underpin your approach. Of course, we need to feel reasonably confident that we are using tried and tested techniques for which the strengths and weakness are known. But often the methods themselves might be based on decades of work drawn from vast fields of literature. If one were not to try to make progress until all the foundations had been thoroughly understood, then there would be little time left to measure things. I think it is quite right and proper that you want to understand where the Langevin or ABP equations of motion comes from and how this translates into a time stepping algorithm for evolving the system. But I don’t think one necessarily needs to go all the way back to Einstein’s original papers to do this. You told me (I think in the context of your project last year) that you felt the need to understand all the foundations before making progress on the project. I would just comment that often we learn ‘on the job’, so to say, ie we might start calculating or measuring without understanding completely what we are doing or why, but the process of ‘doing’ builds that understanding.\nAnyway, I hope these comments help and we can certainly discuss further next week.\nBest wishes,\nNigel",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#diary",
    "href": "direction.html#diary",
    "title": "Redirection of PhD",
    "section": "",
    "text": "It seems my interests have shifted over the summer or possibly during the final stages of my MSci research project. It sort of makes sense when I think about it in terms of the timeline.\nIn January 2024, when I was applying for my PhD:\n\nI wanted to pursue new physics. It appeared to me that two of my favourite fields (general relativity and quantum field theory) were already well-explored and largely complete.\nI also wanted to gain more employability skills, as I hoped to work at Google DeepMind after my PhD. I thought a computationally driven project was essential for this.\nEager to formally learn about the renormalisation group, I looked into areas of new physics related to it. That’s when I discovered the emerging field of active matter. After reading Keller’s account of its history and emergence, as well as McGivern’s account of how it relates to cognition (which I should probably revisit tomorrow), I thought, this is it! This was the field I wanted to pursue! I met Nigel, who was such a brilliant and thoughtful person to talk with, and Francesco, who had already been amazing. I applied directly (and, in fact, only applied for this PhD, while my peers were applying for multiple positions).\nIn my second term, I was also in the process of interviewing with Samsung Electronics, as they invited me to take on a data scientist role (this happened in early January, I think?). The role and salary were very attractive. However, I had to think deeply about what I truly wanted to do. There were still unsolved mysteries I hoped to explore during my PhD. I was curious about fundamental questions like: What is time? What is space? I thought about relativity theory and how Einstein built his ideas around the concept of a universal clock, which doesn’t depend on the mechanisms of the clock itself. But these clocks are also within a gravitational field. Can we truly justify that reading a clock on an observer’s wrist is the correct way to measure time, given that all clocks are fundamentally based on electromagnetism?\nSo, I decided to stay at university for another four years. Over the summer holidays, I continued reading neuroscience books (particularly on dreams and altered states of consciousness) and considered which topics would be interesting to investigate throughout my PhD.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#diary-1",
    "href": "direction.html#diary-1",
    "title": "Redirection of PhD",
    "section": "",
    "text": "See 2024/11/16 Watching Biophysics Lectures\n\nIt really makes me reflect on what I’ve been genuinely interested in. From my third year, I started rating how much I enjoyed each unit after finishing it, based on this scale:\n\n5: I found it very interesting\n\n4: Interesting\n\n3: Okay\n\n2: Not much fun\n\n1: I hated it\n\nHere are the scores for my third-year and fourth-year units:\n\n5: Quantum Physics / Physics Research Project\n\n4.5: Particle Physics, Analytical Mechanics / The Physics of Phase Transitions\n\n4: Methods of Theoretical Physics / Foundations of Modern Physics, General Relativity and Cosmology, Quantum Information Theory\n\n3.5: Materials Physics\n3: Environmental Physics\n\n2.5: Solid State Physics / Applied Materials Physics\n\n2: Biophysics\n\nBased on this, how did I end up choosing my PhD project in active matter? There were complex reasons for choosing it, as I outlined in 2024/11/14 - Skimming through papers, but honestly, I should have thought it through more carefully (even though, at the time, I believed I was being very thorough).\nSo, what am I really interested in? It would be the foundations of modern physics—fairly mathematical work, possibly with computational approaches. However, I’m also deeply interested in neuroscience. I thought I would find a connection by pursuing active matter projects, as studying the brain is a subset of biology. Now, I’m not so sure…",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#email-received-from-nigel-1",
    "href": "direction.html#email-received-from-nigel-1",
    "title": "Redirection of PhD",
    "section": "",
    "text": "After having a project meeting discussing these points: 2024/11/18 Weekly Project Meeting\n\nDear Sohyun,\nI am writing to follow up on our conversation yesterday when you told me that you are no longer interested in pursuing your PhD project on surface phase transitions in active matter. I have to say that personally, I think that this is a pity because Francesco Turci and I are really excited by the idea of making progress on this topic which represents an unexplored frontier of non-equilibrium statistical physics (as are other people like Rob Jack and Mike Cates in Cambridge University). I would also note that I rather struggle to understand how this can be a fully informed decision when you have not yet engaged with the project in a meaningful way beyond reading a few background papers. However, if you really can muster no enthusiasm for the topic then I must accept that.\nActive Matter is one of the main areas in which I see my research focussing for the foreseeable future. Are you ruling out just the particular project, or do you no longer wish to work in the field of Active Matter at all? If the latter, then the areas of potential overlap for projects that I am qualified and willing to supervise is limited. Furthermore, if the topic were to change significantly, we would need to seek approval from the Faculty who awarded you UoB funding to do a PhD and who may insist that to retain the funding you don’t stray far from the topic for which your funding was agreed as constituting a strategic priority for the school.\nNevertheless, and with this caveat, there may be some options to consider. I have made a tentative list (see attached pdf), which naturally reflects my interest and background in simulation of phase transitions and critical phenomena in both equilibrium and non-equilibrium statistical physics and soft matter. Please look at the list of topics in the middle column of the document. I am happy to discuss what each project might entail at our meeting on Monday.\nI am also happy for you to suggest a PhD project topic. But if you do this, I think that you need to go away and read about the topic in detail and prepare a written proposal that is both convincing in terms of potential for original research (as defined in the UoB PhD regulations) and likely to overlap with my research interests and expertise. Again, the topic would need to be acceptable to your funders in the faculty. To avoid wasting any time, I’ve also prepared a non-exhaustive list (third column) of projects that I happen to know from our conversations that you are interested in, but which I do not feel sufficiently well qualified or motivated to supervise.\nI think that in this situation it would be useful for you to seek some independent advice on possible next steps. Dr Ian Lindsay is the PGR director for the School of Physics and has indicated to me that he would be happy to meet with you to discuss the situation and explain any formal processes that apply. I would strongly suggest that you take him up on this offer and write to him to arrange a meeting. His email is i.d.lindsay@bristol.ac.uk\nBest regards\nNigel",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#some-passages-from-my-diary",
    "href": "direction.html#some-passages-from-my-diary",
    "title": "Redirection of PhD",
    "section": "",
    "text": "Continuous time or discrete time are names. Just the named.\n\n\n\nWetting and drying, it’s not beautiful. It’s such a domain of such an abstract domain.\nTime and space, I’m always experiencing. I want to study something that I’m always experiencing.\n\n\n\nThe reason Einstein’s theory is beautiful is because it’s the ULTIMATE PATTERN!\nSpace and time are interlinked! Energy and mass are the same! Mass is equal to frequency!1 The beauty of mathematics was that ‘equality’ sign!\nJust a very simple relationship revealed by mathematics!\nThat was the whole purpose of physics!\nNo matter what complicated language we use to describe concepts,\nThere comes the language of physics: “They are the same!”\nI cannot stop laughing.\n“Stop arguing! They are the same!”\nThe reason the renormalisation group naively appeared as beautiful was because, as we went to higher levels of description, we somehow discovered: ‘Oh! They are the same!’\nNow it all makes sense.\nThe reason the proof of Fermat’s Last Theorem was beautiful was because it linked modular forms to elliptic curves! They are the same!\nThe reason Euler’s relation is beautiful is because it links \\(e\\), \\(\\pi\\), \\(i\\), and \\(-1\\)!\nThe reason criticality is beautiful is because the Ising model and liquid-gas model, ‘only’ at the critical point, are the same! Hence the name ‘Universality’!\nThe reason Maxwell’s equations are beautiful is because they show that electric fields and magnetic fields are the same! The whole phenomenon you’ve been looking at, which you thought was different, is just the same!\nThe reason nature is beautiful is because it is the same thing! Not different things! The breath of perceiving their sameness!\nThe driving motivation for me in my MSci was to say: ‘Hey! The market and the brain are THE SAME!’\nI’ve been just chasing this beauty for my entire lifetime!\n1 By combining \\(E = mc^2\\) and \\(E = hf\\), \\[\nE = mc^2 = hf \\implies f = \\frac{mc^2}{h}\n\\]\n\n\n\n\nTo get this sense of beauty, the things that are left and right of the equality sign have to be the systems that I’m truly interested in. The reason that the investigation of drying or wetting in non-equilibrium contexts using a very specific model (active Brownian particles) is not beautiful is because none of the systems that I’m considering (which is biology) are my interests!\nI don’t care about biology! I’m afraid of insects!\n\n\n\nWe see the same beauty, But the beauty is not the same.\nWe see everyone’s face, but not ours. We find the sameness between different things, but I’m not a thing that relates to those things. When seeking the sameness between me and the others, it falls into trouble. That’s why we can’t see our face. That’s why I can’t see my face. So that I do not self-reference.\n\n\n\nI have a PhD project I want to do: ‘Equality’ sign in physics. Starting from \\(F = ma\\), all the way to \\(E = mc^2\\) and \\(E = hf\\) Searching for what are the left equalities.\nStart the proposal: ‘Considering a PhD project on the theme of the ‘Equality’ sign in physics, exploring its role from foundational equations like \\(F = ma\\) to \\(E = mc^2\\) and \\(E = hf\\), and identifying other significant equalities.’\n\n\n\nIf I think about my current project as spontaneous symmetry breaking, it is kind of interesting.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#my-reply-to-nigel",
    "href": "direction.html#my-reply-to-nigel",
    "title": "Redirection of PhD",
    "section": "",
    "text": "Hi Nigel,\nThank you very much for your email. I completely agree that it was not a fully informed decision, as I have not yet engaged much with the simulation side of things. That is something I have been trying to address since yesterday. When I went back home, I came across the paper ‘Critical Motility-Induced Phase Separation Belongs to the Ising Universality Class’, which seemed so interesting that I thought it might be worthwhile to attempt simulations of active Brownian particles at the critical MIPS in 2D. Although computational resources would be demanding, it would be very interesting to perform renormalisation to rescale the system and demonstrate its scale-invariant features like the critical Ising model.\nI remain very interested in active matter because it represents a compelling and novel paradigm in physics that resonates with my ideas deeply. I am also not ruling out our current project. I shared my personal concerns in the hope of gaining further inspiration for the current project, and I apologise if I inadvertently gave the impression that I have no interest in either this project or the overarching theme I have chosen.\nI will not be in Bristol next Monday or Tuesday, so should we reschedule the meeting to later this week or next Wednesday? Thank you also for the separate document. I will read through the topics, as I am still quite naïve with many of the fields mentioned.\nThank you for introducing Ian, but at this stage, I would like to refine my thoughts further by exploring your suggestions first. It seems that I was too hasty in yesterday’s meeting, and, in hindsight, I probably should not have brought up my concerns in the way that I did.\nThank you, as always, for your support.\nSohyun",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#diary-see-20241116-watching-biophysics-lectures",
    "href": "direction.html#diary-see-20241116-watching-biophysics-lectures",
    "title": "Direction of My PhD",
    "section": "",
    "text": "It really makes me reflect on what I’ve been genuinely interested in. From my third year, I started rating how much I enjoyed each unit after finishing it, based on this scale:\n\n5: I found it very interesting\n\n4: Interesting\n\n3: Okay\n\n2: Not much fun\n\n1: I hated it\n\nHere are the scores for my third-year and fourth-year units:\n\n5: Quantum Physics / Physics Research Project\n\n4.5: Particle Physics, Analytical Mechanics / The Physics of Phase Transitions\n\n4: Methods of Theoretical Physics / Foundations of Modern Physics, General Relativity and Cosmology, Quantum Information Theory\n\n3.5: Materials Physics\n3: Environmental Physics\n\n2.5: Solid State Physics / Applied Materials Physics\n\n2: Biophysics\n\nBased on this, how did I end up choosing my PhD project in active matter? There were complex reasons for choosing it, as I outlined in 2024/11/14 - Skimming through papers, but honestly, I should have thought it through more carefully (even though, at the time, I believed I was being very thorough).\nSo, what am I really interested in? It would be the foundations of modern physics—fairly mathematical work, possibly with computational approaches. However, I’m also deeply interested in neuroscience. I thought I would find a connection by pursuing active matter projects, as studying the brain is a subset of biology. Now, I’m not so sure…",
    "crumbs": [
      "Project Notes",
      "Direction of My PhD"
    ]
  },
  {
    "objectID": "direction.html#엄마의-메세지",
    "href": "direction.html#엄마의-메세지",
    "title": "Redirection of PhD",
    "section": "",
    "text": "다시 다 읽어봤어.\n엄마가 보기에 학문적 접근이 4학년이 되면서 본격적으로 이루어졌고, 물리학에 관해서 이해하면서 앎의 지평이 크게 늘었다고 생각해.\n물론, 너의 호기심을 만족시켜줄수 있는 부분은 다분히 철학적인면, Fundamental 한것이고, 석사하면서 너가 실험적으로 해본것은, Active matter를 연구하게 되는것까지 된것이 아닌가 싶어. 그래서 그 분야에서 펀딩을 받으며 지금의 너가 있는데, 음…한번 너가 이야기했던것이 기억나. 물리학의 발견은 이미 거의 다 이루어져서 새로이 먼가를 발견하는것은 힘들다 했던것같아. 석사과정 그리고 박사과정 몇달동안 심층적으로 공부가 된것같고, 엄마는 잘 모르지만, 아직 Supervisor 와의 프로젝트에 적극적으로 하지못한 부분이 있으니, 심화된 이해를 갖춘 바탕으로 연구를 차근 해보는것은 어떨까 생각해.\n물리학을 전혀 모르는 엄마로서는 이번에는 머라 딱히 해줄 수 없는데, 너의 여정을 지켜본 엄마로서 봤을때에는 지금은 흥미롭지는 않더라도, 새로운 선구적인 연구를 하게될때에 또 다른 즐거움이 나타나지 않을지,.\n참,.. 고민 많았지. 컴퓨터 공학 ㅡ 천체물리학 ㅡ 물리학 ㅡ 관심이 어디에 쏠려있느냐에 따라 전과도 하고, 배움의 길을 걸어왔는데, 앞으로의 행보에 대해 고민이 더더욱 되는건 당연할꺼야. 관련된 교수진들을 만나보면서, 너가 어떤 연구방향으로 가게될지 자연스럽게 알게될것같아.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "conferences.html#negative-probabilities-paradoxical-properties-and-dangling-coherences-do-we-really-understand-the-quantum-formalism",
    "href": "conferences.html#negative-probabilities-paradoxical-properties-and-dangling-coherences-do-we-really-understand-the-quantum-formalism",
    "title": "Conferences",
    "section": "2024/11/21 Negative probabilities, paradoxical properties, and dangling coherences: Do we really understand the quantum formalism?",
    "text": "2024/11/21 Negative probabilities, paradoxical properties, and dangling coherences: Do we really understand the quantum formalism?\nBy Jonte R Hance\n\nAbstract\nThe quantum formalism, the language of quantum mechanics, is surprisingly simple. Mathematically, it’s just linear algebra, but sticking to the “shut up and calculate” approach possibly delayed the advent of quantum technologies by over half a century. Instead, it was only when people tried to think what the quantum formalism really meant, and noticed that its calculational simplicity belied not just an interpretational difficulty but deep, observable physical weirdness, that we started harnessing quantum effects to power novel and interesting technologies. Despite this, rigorously identifying the source of this weirdness, as is necessary for us to, for instance, design quantum computing algorithms on-demand to give some advantage over non-quantum algorithms, is something most researchers in quantum information still shy away from. However, not everyone stays away from trying to understand and use this weirdness.\nDr Jonte R Hance, a lecturer at Newcastle University, instead focusses their research in this direction – using insights from quantum foundations to design protocols and tools for quantum technologies. Dr Hance will take you through some of their recent work, using quantum paradoxes like the quantum Cheshire cat effect and the Elitzur-Vaidman bomb tester to identify the how the underpinning counterintuitive aspect of quantum mechanics manifest in the formalism through probabilities which seemingly turn negative, allowed correlations between prohibited properties, and supposed “values of observables between measurements” becoming anomalous. They will talk about how they have used these as manifestations as building-blocks to develop more powerful tools for low-light imaging and metrology. Alongside this, they will describe their own career path through the sometime opaque world of academia, considering how their experiences intersected with their queerness and neurodivergence, and discussing their thoughts on how we collectively can make academia a better place for everyone.\n\n\nMy reflection\nI’m glad that I went there. There were a few things that I want to remember:\n\nSo, after he had his PhD, he went to Japan for a postdoc, then after about a year, he directly got the lectureship at Newcastle University. So it’s possible to apply for a lectureship early, like how Tom Machon, my previous supervisor, did (I think he did only three years of postdoc).\nWhen he started to show diagrams and equations for quantum mechanics experiments, everyone seemed really bored, even though the topics can’t be something boring! Because it included things like interaction-free measurement, the quantum Cheshire cat, contextuality, negative probabilities, etc. Also, the speaker wasn’t a boring person! So, it appeared to me that as the formalisms of quantum mechanics became more and more complex, it was evident that the research they do seems very distant even to undergraduate students, which is almost like we can’t know the relevance to reality anymore except that they found something interesting and paradoxical.\nThat brings me to my third point. I’m kind of glad that I didn’t go the quantum mechanics PhD route. I like talking about physics to people. And I don’t think I could even make my talk interesting in the future once I start talking about such high-level quantum mechanics to an audience. My project, active drying, even if the research can sound quite mundane, allows me to talk about a lot of interesting things that seem related to our everyday experiences and curiosities. Such as, how can we think about what life is? What is criticality? Why is this thing important, such as hydrophobicity, which is one of the bases of the structure of living things, and which can also extend to swarms of robots?\nFinally, it seems that after he got the lectureship, he needs to apply for grants for research to hire PhD students and postdocs. So that’s why it seems that all the research papers in quantum mechanics like to make bold headlines, like the smallest refrigerator, \\(1/2\\) spin being measured as 100, bomb experiment, etc. He seemed depressed about the current state of academia. I think if I stay in the soft matter area, I’m sure I can more easily handle the process of applying for grants once I’m at the stage where I have to, since it’s research about our everyday experiences. The length scale is too tiny for quantum mechanics.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Conferences"
    ]
  },
  {
    "objectID": "reading.html#wetting-transition-of-active-brownian-particles-on-a-thin-membrane-turci2021wetting",
    "href": "reading.html#wetting-transition-of-active-brownian-particles-on-a-thin-membrane-turci2021wetting",
    "title": "Reading Archive",
    "section": "2024/11/14 - Wetting Transition of Active Brownian Particles on a Thin Membrane (Turci and Wilding 2021)",
    "text": "2024/11/14 - Wetting Transition of Active Brownian Particles on a Thin Membrane (Turci and Wilding 2021)\n\nTurci, Francesco, and Nigel B Wilding. 2021. “Wetting Transition of Active Brownian Particles on a Thin Membrane.” Physical Review Letters 127 (23): 238002.\nCited by 20\nUnfortunately, not very interesting. The authors (my supervisors) investigated how ABPs interact with a planar surface with barrier strength \\(\\epsilon_w\\); decreasing this makes the surface resemble a thin penetrable (or porous) membrane. The research implications relate to artificial colloids or elementary swarm robots, but I’m not particularly interested in those systems.\n\n\n\nOn page 2, Partial and complete wetting of droplets of active Brownian particles\n\n\nThe above image is a good summary of what the research is about, which coincidentally is from what I’m currently reading:",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#partial-and-complete-wetting-of-droplets-of-active-brownian-particles-turci2024partial",
    "href": "reading.html#partial-and-complete-wetting-of-droplets-of-active-brownian-particles-turci2024partial",
    "title": "Reading Archive",
    "section": "2024/11/14 - Partial and Complete Wetting of Droplets of Active Brownian Particles (Turci, Jack, and Wilding 2024)",
    "text": "2024/11/14 - Partial and Complete Wetting of Droplets of Active Brownian Particles (Turci, Jack, and Wilding 2024)\n\nTurci, Francesco, Robert L Jack, and Nigel B Wilding. 2024. “Partial and Complete Wetting of Droplets of Active Brownian Particles.” Soft Matter 20 (9): 2060–74.\nCited by 5\nIt became quite technical from Chapter 2 onward, so I only read the introduction and the discussion & conclusions sections. I think I’m becoming increasingly uncertain about wanting to pursue my project. It doesn’t seem particularly mysterious or evoking my curiosity. I guess the highlight of this article was that, despite the inherent non-equilibrium mechanisms that engender phase separation and non-trivial flow patterns, the large-scale properties of the active model can be mapped onto an equilibrium one. This means that we can use techniques from equilibrium statistical mechanics, such as the renormalisation group, which I was hoping to learn deeply in my PhD.\nIf there were a connection between surface phase transitions of vapour inside the cap of my RDA (rebuildable dripping atomiser), it might be more interesting and relating to my interests, but I think this is likely an equilibrium condition rather than something relevant to active matter. I must ask next week.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#motility-induced-phase-separation-cates2015motility",
    "href": "reading.html#motility-induced-phase-separation-cates2015motility",
    "title": "Reading Archive",
    "section": "2024/11/15 - Motility-Induced Phase Separation (Cates and Tailleur 2015)",
    "text": "2024/11/15 - Motility-Induced Phase Separation (Cates and Tailleur 2015)\n\nCates, Michael E, and Julien Tailleur. 2015. “Motility-Induced Phase Separation.” Annu. Rev. Condens. Matter Phys. 6 (1): 219–44.\nCited by 1579 (Really surprising how much attention this topic has received!), also written by Michael Cates, who is the Lucasian Professor of Mathematics at the University of Cambridge\nThis one, too, I only read the introduction and conclusion. I wanted to read this because MIPS keeps appearing in many papers. Essentially, this phenomenon occurs because active particles generically accumulate where they move more slowly. What’s really worth noting is that the run-and-tumble model is inspired by E. coli, while active Brownian particles are inspired by synthetic colloids. Am I interested in either system? No… I think I should have done this activity of skimming through many papers earlier to clarify what I’m truly interested in.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#sec-proliferating-active-matter",
    "href": "reading.html#sec-proliferating-active-matter",
    "title": "Reading Archive",
    "section": "2024/11/15 - Proliferating Active Matter (Hallatschek et al. 2023)",
    "text": "2024/11/15 - Proliferating Active Matter (Hallatschek et al. 2023)\n\nHallatschek, Oskar, Sujit S Datta, Knut Drescher, Jörn Dunkel, Jens Elgeti, Bartek Waclaw, and Ned S Wingreen. 2023. “Proliferating Active Matter.” Nature Reviews Physics 5 (7): 407–19.\nCited by 48\nI thought I should probably reread papers that inspired me to investigate active matter in my PhD almost a year ago. One particular article, even though it didn’t seem to attract much attention, was written by Keller: ‘Active Matter, Then and Now’ (Keller 2016). I loved reading it so much that I probably read it three times. Skipping that one this time, I started reading Proliferating Active Matter, which I also really enjoyed.\n\nKeller, Evelyn Fox. 2016. “Active Matter, Then and Now.” History and Philosophy of the Life Sciences 38: 1–11.\nI remember the start of the article being quite strong, mentioning the book that I often reread, What Is Life? by Erwin Schrödinger, and also discussing the reshaping of the chessboard by the active matter paradigm (which was probably something to do with breaking mass-reversal symmetry?); as if I were playing the physics game like chess.\nWhile reading (just before the chapter Motile Proliferating Matter), I got sidetracked because it wasn’t really interesting anymore. It seems my interests have shifted over the summer or possibly during the final stages of my MSci research project. It sort of makes sense when I think about it in terms of the timeline.\nIn January 2024, when I was applying for my PhD:\n\nI wanted to pursue new physics. It appeared to me that two of my favourite fields (general relativity and quantum field theory) were already well-explored and largely complete.\nI also wanted to gain more employability skills, as I hoped to work at Google DeepMind after my PhD. I thought a computationally driven project was essential for this.\nEager to formally learn about the renormalisation group, I looked into areas of new physics related to it. That’s when I discovered the emerging field of active matter. After reading Keller’s account of its history and emergence, as well as McGivern’s account of how it relates to cognition (which I should probably revisit tomorrow), I thought, this is it! This was the field I wanted to pursue! I met Nigel, who was such a brilliant and thoughtful person to talk with, and Francesco, who had already been amazing. I applied directly (and, in fact, only applied for this PhD, while my peers were applying for multiple positions).\nIn my second term, I was also in the process of interviewing with Samsung Electronics, as they invited me to take on a data scientist role (this happened in early January, I think?). The role and salary were very attractive. However, once I received the final offer, I had to think deeply about what I truly wanted to do. There were still unsolved mysteries I hoped to explore during my PhD. I was curious about fundamental questions like: What is time? What is space? I thought about relativity theory and how Einstein built his ideas around the concept of a universal clock, which doesn’t depend on the mechanisms of the clock itself. But these clocks are also within a gravitational field. Can we truly justify that reading a clock on an observer’s wrist is the correct way to measure time, given that all clocks are fundamentally based on electromagnetism?\nSo, I declined the job offer and decided to stay at university for another four years. Over the summer holidays, I continued reading neuroscience books (particularly on dreams and altered states of consciousness) and considered which topics would be interesting to investigate throughout my PhD.\n\nBefore sleeping, I started reading Time and Quantum Clocks: A Review of Recent Developments (Altaie, Hodgson, and Beige 2022), which I found very interesting.\n\nAltaie, M Basil, Daniel Hodgson, and Almut Beige. 2022. “Time and Quantum Clocks: A Review of Recent Developments.” Frontiers in Physics 10: 897305.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#active-materials-minimal-models-of-cognition-mcgivern2020active",
    "href": "reading.html#active-materials-minimal-models-of-cognition-mcgivern2020active",
    "title": "Reading Archive",
    "section": "2024/11/17 - Active Materials: Minimal Models of Cognition? (McGivern 2020)",
    "text": "2024/11/17 - Active Materials: Minimal Models of Cognition? (McGivern 2020)\n\nMcGivern, Patrick. 2020. “Active Materials: Minimal Models of Cognition?” Adaptive Behavior 28 (6): 441–51.\nCited by 20\nThe next morning, I felt compelled to reread this paper, as it was one of the key works that truly ignited my interest in the field of active matter.\n\n\n\nOn page 8, 3. Minimal models (LGA stands for lattice gas automata)\n\n\nYes! This was it! I was curious whether a simple model of active matter that I learn could be applied to biological systems by examining if they fall into the same universality class as a realistic model through the application of renormalisation group techniques.\nVery interesting. I’m glad I read it once again. I wonder what my supervisors think about this article. I thought it would be useful to clarify whether I truly want to pursue the field of biophysics (as I’m not particularly interested in synthetic colloids), so I decided to revisit the biophysics lectures (see 2024/11/16 Watching Biophysics Lectures).\nI thought it would be important to develop a good understanding of why active colloids or motile bacteria are significant. While exploring this, I found a list of nice articles by Philip Ball.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#colloids-get-active-ball2013colloids",
    "href": "reading.html#colloids-get-active-ball2013colloids",
    "title": "Reading Archive",
    "section": "2024/11/20 - Colloids Get Active (Ball 2013)",
    "text": "2024/11/20 - Colloids Get Active (Ball 2013)\n\nBall, Philip. 2013. “Colloids Get Active.” Nature Materials 12 (8): 696–96.\nCited by 5\nPhilip Ball writes:\n\nBacterial swarms—the prototypical form of active matter—model the motile bacteria.\n\nwhich he mentioned is really important as active Brownian particles model the motile bacteria. I loved this very short News & Views article :) The cited paper also seems highly relevant, which begins with the abstract:\n\nAn active colloid is a suspension of particles that transduce free energy from their environment and use the energy to engage in intrinsically non-equilibrium activities such as growth, replication, and self-propelled motility. An obvious example of active colloids is a suspension of bacteria such as Escherichia coli, their physical dimensions being almost invariably in the colloidal range. Synthetic self-propelled particles have also become available recently, such as two-faced, or Janus, particles propelled by differential chemical reactions on their surfaces driving a self-phoretic motion. In these lectures, I give a pedagogical introduction to the physics of single-particle and collective properties of active colloids, focusing on self-propulsion. I will compare and contrast phenomena in suspensions of ‘swimmers’ with the behavior of suspensions of passive particles, where only Brownian motion (discovered by Robert Brown in granules from the pollen of the wild flower Clarkia pulchella) is relevant. I will pay particular attention to issues that pertain to performing experiments using these active particle suspensions, such as how to characterize the suspension’s swimming speed distribution, and include an appendix to guide physicists wanting to start culturing motile bacteria.\n\nThis was probably the first time I realised the significance of the colloidal scale!",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#from-clarkia-to-escherichia-and-janus-the-physics-of-natural-and-synthetic-active-colloids-poon2013clarkia",
    "href": "reading.html#from-clarkia-to-escherichia-and-janus-the-physics-of-natural-and-synthetic-active-colloids-poon2013clarkia",
    "title": "Reading Archive",
    "section": "2024/11/21 - From Clarkia to Escherichia and Janus: The physics of natural and synthetic active colloids (Poon 2013)",
    "text": "2024/11/21 - From Clarkia to Escherichia and Janus: The physics of natural and synthetic active colloids (Poon 2013)\n\nPoon, WCK. 2013. “From Clarkia to Escherichia and Janus: The Physics of Natural and Synthetic Active Colloids.” In Physics of Complex Colloids, 317–86. Ios Press.\nCited by 74\nOne video was introduced in this article about kinematic reversibility, really surprised!\n\n\nEven though the article was very interesting, it didn’t seem closely related to my specific project, so I stopped reading after page 9 and skipped to the conclusion. However, I really liked how it also started with the basics of fluid dynamics.\nIn the conclusion, the author notes:\n\nI have already mentioned one potential source of experimental difficulties for corresponding experiments using active particles: the rapid depletion of “fuel,” so that any putative novel collective effects need to be carefully scrutinized to rule out fuel depletion as a causative factor.\n\nI think this observation also applies to simulations, where particles are often assumed to have an infinite energy supply. And I especially loved the ending of the conclusion. Read it for yourself in the future again :)",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#animate-materials-ball2021animate",
    "href": "reading.html#animate-materials-ball2021animate",
    "title": "Reading Archive",
    "section": "2024/11/21 - Animate Materials (Ball 2021)",
    "text": "2024/11/21 - Animate Materials (Ball 2021)\n\n———. 2021. “Animate Materials.” Springer.\nCited by 12\nPhilip Ball writes:\n\nEver since humans began constructing artifacts from materials—whether a stone bridge or a space rocket—we have regarded design as a fixed objective and have selected materials and structures that we believe will do the job as well as possible. Maintenance, repair, and alteration have then been regarded as additional tasks—necessary in most cases, but enacted post hoc. Typically, the aim has been to use materials that resist change: that will not break or corrode or deform. If these things happen, a whole new train of interventions is required. But for animate materials, responses to such changes are foreseen and accommodated from the outset.\n\nI really like his articles (I should read some of his books!) because they make me imagine a lot of sci-fi scenes that I watched. The most immediate ones that come to mind are Foundation on Apple TV, where both human skin and spaceship exteriors are auto-healed, and the iconic opening scene of Ghost in the Shell where Major Kusanagi body is being constructed.\nAlso, Philip writes:\n\nOne perspective would be to equate “animate” with an autonomous capacity to “act”—which is reflected in the perception that many of the properties considered desirable in animate materials are prefixed with “self-”: assembly, repair, sensing, diagnosing, reporting, protecting.\n\n\nOne of the most obvious molecularscale differences between living and inanimate materials is the nature of the chemical bonding. Rocks and minerals tend to have rigid structures held together by strong (covalent or ionic) chemical bonds. In living systems, the molecules—such as proteins and nucleic acids—are generally dynamic in their conformation and interact with other molecules via weak interactions such as hydrogen bonding and hydrophobic forces. This enables information to be transmitted from place to place, and means that molecular entities can be assembled and disassembled on demand. The “looseness of structure” is surely also an essential feature for systems that are maintained away from equilibrium by a throughput of material and energy, and which can adapt to changes in the environment.\n\nThis is probably also the first time I realised the importance of hydrophobicity in non-equilibrium systems. Even though there was no huge overlap with active matter topics, it was a very interesting read.\nBut his another article, Field work – the physics of sheep, from phase transitions to collective motion, wasn’t very exciting.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#wetting-transition-of-active-brownian-particles-on-a-thin-membrane-completed-turci2021wetting",
    "href": "reading.html#wetting-transition-of-active-brownian-particles-on-a-thin-membrane-completed-turci2021wetting",
    "title": "List of My Reading",
    "section": "2024/11/14 - Wetting Transition of Active Brownian Particles on a Thin Membrane (Completed) (Turci and Wilding 2021)",
    "text": "2024/11/14 - Wetting Transition of Active Brownian Particles on a Thin Membrane (Completed) (Turci and Wilding 2021)\n\nTurci, Francesco, and Nigel B Wilding. 2021. “Wetting Transition of Active Brownian Particles on a Thin Membrane.” Physical Review Letters 127 (23): 238002.\nCited by 20\nUnfortunately, not very interesting. The authors (my supervisors) investigated how ABPs interact with a planar surface with barrier strength \\(\\epsilon_w\\); decreasing this makes the surface resemble a thin penetrable (or porous) membrane. The research implications relate to artificial colloids or elementary swarm robots, but I’m not particularly interested in those systems.\n\n\n\nOn page 2, Partial and complete wetting of droplets of active Brownian particles\n\n\nThe above image is a good summary of what the research is about, which coincidentally is from what I’m currently reading:",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#active-materials-minimal-models-of-cognition-completed-mcgivern2020active",
    "href": "reading.html#active-materials-minimal-models-of-cognition-completed-mcgivern2020active",
    "title": "List of My Reading",
    "section": "2024/11/17 - Active Materials: Minimal Models of Cognition? (Completed) (McGivern 2020)",
    "text": "2024/11/17 - Active Materials: Minimal Models of Cognition? (Completed) (McGivern 2020)\n\nMcGivern, Patrick. 2020. “Active Materials: Minimal Models of Cognition?” Adaptive Behavior 28 (6): 441–51.\nCited by 20\nThe next morning, I felt compelled to reread this paper, as it was one of the key works that truly ignited my interest in the field of active matter.\n\n\n\nOn page 8, 3. Minimal models (LGA stands for lattice gas automata)\n\n\nYes! This was it! I was curious whether a simple model of active matter that I learn could be applied to biological systems by examining if they fall into the same universality class as a realistic model through the application of renormalisation group techniques.\nVery interesting. I’m glad I read it once again. I wonder what my supervisors think about this article. I thought it would be useful to clarify whether I truly want to pursue the field of biophysics (as I’m not particularly interested in synthetic colloids), so I decided to revisit the biophysics lectures (see 2024/11/16 Watching Biophysics Lectures).\nI thought it would be important to develop a good understanding of why active colloids or motile bacteria are significant. While exploring this, I found a list of nice articles by Philip Ball.",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#colloids-get-active-completed-ball2013colloids",
    "href": "reading.html#colloids-get-active-completed-ball2013colloids",
    "title": "List of My Reading",
    "section": "2024/11/20 - Colloids Get Active (Completed) (Ball 2013)",
    "text": "2024/11/20 - Colloids Get Active (Completed) (Ball 2013)\n\nBall, Philip. 2013. “Colloids Get Active.” Nature Materials 12 (8): 696–96.\nCited by 5\nPhilip Ball writes:\n\nBacterial swarms—the prototypical form of active matter—model the motile bacteria.\n\nwhich he mentioned is really important as active Brownian particles model the motile bacteria. I loved this very short News & Views article :) The cited paper also seems highly relevant, which begins with the abstract:\n\nAn active colloid is a suspension of particles that transduce free energy from their environment and use the energy to engage in intrinsically non-equilibrium activities such as growth, replication, and self-propelled motility. An obvious example of active colloids is a suspension of bacteria such as Escherichia coli, their physical dimensions being almost invariably in the colloidal range. Synthetic self-propelled particles have also become available recently, such as two-faced, or Janus, particles propelled by differential chemical reactions on their surfaces driving a self-phoretic motion. In these lectures, I give a pedagogical introduction to the physics of single-particle and collective properties of active colloids, focusing on self-propulsion. I will compare and contrast phenomena in suspensions of ‘swimmers’ with the behavior of suspensions of passive particles, where only Brownian motion (discovered by Robert Brown in granules from the pollen of the wild flower Clarkia pulchella) is relevant. I will pay particular attention to issues that pertain to performing experiments using these active particle suspensions, such as how to characterize the suspension’s swimming speed distribution, and include an appendix to guide physicists wanting to start culturing motile bacteria.\n\nThis was probably the first time I realised the significance of the colloidal scale!",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#animate-materials-completed-ball2021animate",
    "href": "reading.html#animate-materials-completed-ball2021animate",
    "title": "List of My Reading",
    "section": "2024/11/21 - Animate Materials (Completed) (Ball 2021)",
    "text": "2024/11/21 - Animate Materials (Completed) (Ball 2021)\n\n———. 2021. “Animate Materials.” Springer.\nCited by 12\nPhilip Ball writes:\n\nEver since humans began constructing artifacts from materials—whether a stone bridge or a space rocket—we have regarded design as a fixed objective and have selected materials and structures that we believe will do the job as well as possible. Maintenance, repair, and alteration have then been regarded as additional tasks—necessary in most cases, but enacted post hoc. Typically, the aim has been to use materials that resist change: that will not break or corrode or deform. If these things happen, a whole new train of interventions is required. But for animate materials, responses to such changes are foreseen and accommodated from the outset.\n\nI really like his articles (I should read some of his books!) because they make me imagine a lot of sci-fi scenes that I watched. The most immediate ones that come to mind are Foundation on Apple TV, where both human skin and spaceship exteriors are auto-healed, and the iconic opening scene of Ghost in the Shell where Major Kusanagi body is being constructed.\nAlso, Philip writes:\n\nOne perspective would be to equate “animate” with an autonomous capacity to “act”—which is reflected in the perception that many of the properties considered desirable in animate materials are prefixed with “self-”: assembly, repair, sensing, diagnosing, reporting, protecting.\n\n\nOne of the most obvious molecularscale differences between living and inanimate materials is the nature of the chemical bonding. Rocks and minerals tend to have rigid structures held together by strong (covalent or ionic) chemical bonds. In living systems, the molecules—such as proteins and nucleic acids—are generally dynamic in their conformation and interact with other molecules via weak interactions such as hydrogen bonding and hydrophobic forces. This enables information to be transmitted from place to place, and means that molecular entities can be assembled and disassembled on demand. The “looseness of structure” is surely also an essential feature for systems that are maintained away from equilibrium by a throughput of material and energy, and which can adapt to changes in the environment.\n\nThis is probably also the first time I realised the importance of hydrophobicity in non-equilibrium systems. Even though there was no huge overlap with active matter topics, it was a very interesting read.\nBut his another article, Field work – the physics of sheep, from phase transitions to collective motion, wasn’t very exciting.",
    "crumbs": [
      "Project Notes",
      "List of My Reading"
    ]
  },
  {
    "objectID": "reading.html#on-the-motion-of-small-particles-suspended-in-liquids-at-rest-required-by-the-molecular-kinetic-theory-of-heat",
    "href": "reading.html#on-the-motion-of-small-particles-suspended-in-liquids-at-rest-required-by-the-molecular-kinetic-theory-of-heat",
    "title": "Reading List",
    "section": "2024/10/18 - 10/19 On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat",
    "text": "2024/10/18 - 10/19 On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat\nBy Albert Einstein\nSince I am studying a model called active Brownian particles, a thought occurred to me: I should actually read where this understanding of Brownian motion came from! This was done by the very man: Albert Einstein in 1905 (Einstein et al. 1905). I normally leave my iPad in my office so whenever I needed derivations, I used a pen and note, quite a classical way while reading a classical paper:\n\nEinstein, Albert et al. 1905. “On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat.” Annalen Der Physik 17 (549-560): 208.\nMy handwritten notes\nI’m so glad that I read this. It reminded me of how much I loved studying thermodynamics during my undergraduate studies. It was kind of like studying geometry (or topology). I consider a system subject to constraints and investigate how the particle behaves given the state variables. The paper wasn’t straightforward to read, as I had to remind myself of several concepts such as the continuous form of entropy, perturbation theory, and Fourier transforms to find a solution for diffusion equations.\nI really liked the way he displayed his logic. He considers a system: a pure solvent and suspended particles. These particles are confined by a semi-permeable wall, which only allows solvent to flow, not the solute. Then he thinks about the existing concept of osmotic pressure, which inhibits the solvent from moving to equalise concentrations. He then makes several reasonable assumptions, such as:\n\nSuspended particles have slow and irregular motions due to the solvent’s molecules.\nThe motions of those individual particles are independent of each other.\n\nHe then links the diffusion coefficient to two different contexts. The first is through the theory of diffusion, involving concepts of entropy and free energy. The second is through the theory of thermal molecular motion, where he considers the rate of change of density. By uniting these two theories, he arrives at the root-mean-square displacement of the suspended particle. Wow!\nI’m so happy to have chosen a theoretical physics PhD. Thinking about how theories interconnect reveals a universal understanding. I’m looking forward to reading more of his articles.",
    "crumbs": [
      "Project Notes",
      "Reading List"
    ]
  },
  {
    "objectID": "reading.html#on-the-motion-of-small-particles-suspended-in-liquids-at-rest-required-by-the-molecular-kinetic-theory-of-heat-einstein1905motion",
    "href": "reading.html#on-the-motion-of-small-particles-suspended-in-liquids-at-rest-required-by-the-molecular-kinetic-theory-of-heat-einstein1905motion",
    "title": "Reading Archive",
    "section": "2024/10/18 - 10/19 On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat (Einstein et al. 1905)",
    "text": "2024/10/18 - 10/19 On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat (Einstein et al. 1905)\n\nEinstein, Albert et al. 1905. “On the Motion of Small Particles Suspended in Liquids at Rest Required by the Molecular-Kinetic Theory of Heat.” Annalen Der Physik 17 (549-560): 208.\nCited by 5001\nSince I am studying a model called active Brownian particles, a thought occurred to me: I should actually read where this understanding of Brownian motion came from! This was done by the very man: Albert Einstein in 1905. I normally leave my iPad in my office so whenever I needed derivations, I used a pen and note, quite a classical way while reading a classical paper:\nMy handwritten notes\nI’m so glad that I read this. It reminded me of how much I loved studying thermodynamics during my undergraduate studies. It was kind of like studying geometry (or topology). I consider a system subject to constraints and investigate how the particle behaves given the state variables. The paper wasn’t straightforward to read, as I had to remind myself of several concepts such as the continuous form of entropy, perturbation theory, and Fourier transforms to find a solution for diffusion equations.\nI really liked the way he displayed his logic. He considers a system: a pure solvent and suspended particles. These particles are confined by a semi-permeable wall, which only allows solvent to flow, not the solute. Then he thinks about the existing concept of osmotic pressure, which inhibits the solvent from moving to equalise concentrations. He then makes several reasonable assumptions, such as:\n\nSuspended particles have slow and irregular motions due to the solvent’s molecules.\nThe motions of those individual particles are independent of each other.\n\nHe then links the diffusion coefficient to two different contexts. The first is through the theory of diffusion, involving concepts of entropy and free energy. The second is through the theory of thermal molecular motion, where he considers the rate of change of density. By uniting these two theories, he arrives at the root-mean-square displacement of the suspended particle. Wow!\nI’m so happy to have chosen a theoretical physics PhD. Thinking about how theories interconnect reveals a universal understanding. I’m looking forward to reading more of his articles.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#understanding-molecular-simulation-3rd-ed-frenkel2023understanding",
    "href": "reading.html#understanding-molecular-simulation-3rd-ed-frenkel2023understanding",
    "title": "Reading Archive",
    "section": "2024/10/23 - Understanding Molecular Simulation, 3rd Ed (Frenkel and Smit 2023)",
    "text": "2024/10/23 - Understanding Molecular Simulation, 3rd Ed (Frenkel and Smit 2023)\n\nFrenkel, Daan, and Berend Smit. 2023. Understanding Molecular Simulation: From Algorithms to Applications. Elsevier.\nCited by 22954!\n\nChapter 1. Introduction\nBefore starting our project, I was a little concerned about whether computational simulation is a valid way to understand the fundamental order of nature. I thought that what we do as physicists is observe systems through experiments, theorise with idealised objects to gain predictive power, and then test the theory by observing again. This thought process was probably inspired by a Kantian perspective; I read his Critique of Pure Reason in high school, where he posits that causality is a presupposition of reasoning. For those purposes, idealised objects had to be mathematical (forms or images from Plato) and needed to represent what I directly observe in empirical reality.\n\n\n\nOn page 2, Introduction\n\n\nI’m still not completely certain if computer simulation is truly the way to go, but as I work through it, I hope it will make more sense to me.\n\n\n\n\nOn page 6, Introduction\n\n\nQuite an interesting discussion on what ‘model’ means in science.\n\n\n\nChapter 2. Thermodynamics and Statistical Mechanics\n\n\n\nOn page 22, 2.1.2 Chemical Potential and Equilibrium\n\n\nImportant equilibrium conditions!\n\n\n\n\nOn page 22, 2.1.2 Chemical Potential and Equilibrium\n\n\nI’m not entirely sure why the extremum condition applies specifically to variations in \\(E_1\\), \\(N_1\\), and \\(V_1\\). So, I asked ChatGPT:\n\n\nClick to reveal the answer!\n\nYou’re right to question this subtle point.\nThe key insight lies in understanding that when we talk about maximising the total entropy \\(S_{\\text{tot}} = S_1 + S_2\\) of a closed system with fixed total values of energy, volume, and particle number, the only degrees of freedom available for changes are the distributions of \\(E\\), \\(V\\), and \\(N\\) between the subsystems.\nHere’s the reasoning in detail:\n\nFixed Total Quantities Impose Constraints: Because the total energy \\(E_{\\text{tot}} = E_1 + E_2\\), volume \\(V_{\\text{tot}} = V_1 + V_2\\), and particle number \\(N_{\\text{tot}} = N_1 + N_2\\) are fixed, any changes in \\(E_1\\), \\(V_1\\), or \\(N_1\\) must be offset by corresponding changes in \\(E_2\\), \\(V_2\\), and \\(N_2\\) to keep these sums constant.\nEntropy Extremum Condition: In equilibrium thermodynamics, the Second Law requires that the total entropy of an isolated (or closed) system reaches a maximum (or an extremum) at equilibrium. However, since the system is closed and these total quantities are fixed, the system cannot simply increase or decrease its overall \\(E_{\\text{tot}}\\), \\(V_{\\text{tot}}\\), or \\(N_{\\text{tot}}\\). Instead, any adjustments to entropy must occur through redistributions of these quantities between subsystems.\nRedistribution as the Only Available Variation: Thus, the extremisation of \\(S_{\\text{tot}}\\) must occur specifically with respect to the variables that can change within the subsystems while satisfying the overall conservation constraints. Since \\(E_{\\text{tot}}\\), \\(V_{\\text{tot}}\\), and \\(N_{\\text{tot}}\\) are fixed, the only available independent variations in \\(S_{\\text{tot}}\\) come from redistributing \\(E_1\\), \\(V_1\\), and \\(N_1\\) (and equivalently \\(E_2\\), \\(V_2\\), and \\(N_2\\)).\nDerivative Vanishing Condition: For \\(S_{\\text{tot}} = S_1 + S_2\\) to be maximised (or extremised) under these constraints, the derivatives of \\(S_{\\text{tot}}\\) with respect to \\(E_1\\), \\(V_1\\), and \\(N_1\\) must vanish. This is because any non-zero derivative would indicate that entropy could be further increased by adjusting these redistributive variables, contradicting the requirement of equilibrium.\n\nIn summary, we require the extremum condition with respect to \\(E_1\\), \\(V_1\\), and \\(N_1\\) specifically because these are the variables that can be redistributed between the subsystems within the constraint of fixed total quantities. This is why the extremum condition applies to these specific derivatives, and not to other parameters.\n\n\n\n\n\nOn page 30, 2.2.3 Towards Classical Statistical Mechanics\n\n\nI’m not sure how to derive the transition from 2.2.17 to 2.2.18.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#the-science-of-interstellar-thorne2014science",
    "href": "reading.html#the-science-of-interstellar-thorne2014science",
    "title": "Reading Archive",
    "section": "2024/11/9 - The Science of Interstellar (Thorne 2014)",
    "text": "2024/11/9 - The Science of Interstellar (Thorne 2014)\n\nThorne, Kip. 2014. The Science of Interstellar. WW Norton &Company.\nCited by 265\nToday, I rewatched the film Interstellar, perhaps for the fourth time. I was deeply impressed by Nolan’s previous film Inception, which I also probably watched five times already. Yesterday, I had to give Inception a 10-star rating for the first time in my life, as it just gets more interesting with every viewing. This 10-star rating is very special to me, as I have never rated any of the over 3,000 films I’ve watched so highly.\nAfter this purely fantastical journey, I became curious about the science behind it. Then I realised that the scientific adviser for the film, Kip Thorne, actually wrote a book about it! I knew I had planned to read Understanding Molecular Simulation today, but since it’s the weekend, I decided to indulge in this investigation instead.\n\n\n\nOn page 45, 4. Warped Time and Space, and Tidal Gravity\n\n\nWhat a beautiful way of interpreting general relativity!\nSo far, having read up to Chapter 6, it has all been very interesting! But since Monday has arrived, it’s time to focus on my project again…",
    "crumbs": [
      "Project Notes",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#hydrophobicity-across-length-scales-the-role-of-surface-criticality-coe2021hydrophobicity",
    "href": "reading.html#hydrophobicity-across-length-scales-the-role-of-surface-criticality-coe2021hydrophobicity",
    "title": "Reading Archive",
    "section": "2024/10/4 - Hydrophobicity Across Length Scales: The Role of Surface Criticality (Coe 2021)",
    "text": "2024/10/4 - Hydrophobicity Across Length Scales: The Role of Surface Criticality (Coe 2021)\n\nCoe, Mary K. 2021. “Hydrophobicity Across Length Scales: The Role of Surface Criticality.” PhD thesis, University of Bristol.\nCited by 5\n\nQ1. Resolved\n\n\n\nOn page 35, Chapter 2.1\n\n\nI’m not entirely sure why the surface tension is defined in that way, as it’s normally considered force per unit area. So, I asked ChatGPT:\n\n\nClick to reveal the answer!\n\nThe definition of surface tension in this context is derived from the thermodynamic perspective, which connects surface tension to the grand potential difference between a bulk fluid and a system with an interface. The reasoning follows these steps:\n\nGrand Potential Definition: The grand potential, \\(\\Omega\\), is given by: \\[\n\\Omega = U - TS - \\mu N\n\\] This expression is crucial for systems where particle number and volume are allowed to fluctuate, such as liquid-vapour interfaces.\nSurface Tension from Thermodynamics: Surface tension, \\(\\gamma\\), represents the energy cost per unit area to create an interface. In thermodynamic terms, this corresponds to how much the grand potential increases when introducing an interface between coexisting phases (liquid and vapour).\nDifference between Bulk and Interface: The bulk grand potential, \\(\\Omega_b\\), corresponds to a system without an interface (uniform bulk). When an interface is introduced, the grand potential changes, denoted as \\(\\Omega_{\\text{ex}}\\), the excess grand potential: \\[\n\\Omega_{\\text{ex}} = \\Omega - \\Omega_b\n\\]\nSurface Tension as Excess Grand Potential per Unit Area: The surface tension is then defined as the excess grand potential per unit area, \\(A\\), required to form the interface: \\[\n\\gamma = \\frac{\\Omega_{\\text{ex}}}{A} = \\frac{\\Omega - \\Omega_b}{A}\n\\] This formulation makes sense because surface tension describes the energetic cost to create a unit area of interface between two phases.\n\nIn summary, while surface tension is often discussed in terms of force per unit length in simpler mechanical contexts, in thermodynamics, it is expressed as the excess grand potential per unit area. This ties into how interfaces modify the system’s energy in comparison to the bulk. The two definitions are equivalent but applied in different contexts: mechanical (force/length) vs. thermodynamic (energy/area).\n\n\n\nDerivation of equation 2.1.8, 2.1.9, 2.1.10\n\n\\[\n\\Omega_b(\\mu, V, T) = U - TS - \\mu N = -pV\n\\]\nTaking the differential:\n\\[\nd\\Omega_b = d(U - TS - \\mu N)\n\\]\nUsing the first law of thermodynamics:\n\\[\ndU = TdS - pdV + \\mu dN\n\\]\nDifferentiating \\(TS\\):\n\\[\nd(TS) = TdS + SdT\n\\]\nDifferentiating \\(\\mu N\\):\n\\[\nd(\\mu N) = \\mu dN + N d\\mu\n\\]\nSubstituting these into the differential for \\(\\Omega_b\\):\n\\[\nd\\Omega_b = (TdS - pdV + \\mu dN) - (TdS + SdT) - (\\mu dN + N d\\mu)\n\\]\nSimplifying:\n\\[\nd\\Omega_b = -S_b dT - N_b d\\mu - p dV\n\\]\nFor constant volume (\\(dV = 0\\)), the volume is assumed to remain constant because we are focusing on surface effects rather than bulk volume changes.:\n\\[\nd\\Omega_b = -S_b dT - N_b d\\mu\n\\]\nNow for equation (2.1.6):\n\\[\n\\Omega(\\mu, V, T) = U - TS - \\mu N = -pV + \\gamma A\n\\]\nTaking the differential:\n\\[\nd\\Omega = d(U - TS - \\mu N + \\gamma A)\n\\]\nSubstituting differentials:\n\\[\nd\\Omega = TdS - pdV + \\mu dN - (TdS + SdT) - (\\mu dN + N d\\mu) + \\gamma dA + A d\\gamma\n\\]\nSimplifying:\n\\[\nd\\Omega = -S dT - N d\\mu + \\gamma dA\n\\]\nNow subtract:\n\\[\nd\\Omega - d\\Omega_b = (-S dT - N d\\mu + \\gamma dA) - (-S_b dT - N_b d\\mu)\n\\]\nSimplifying:\n\\[\nd\\Omega - d\\Omega_b = -(S - S_b)dT - (N - N_b)d\\mu + \\gamma dA\n\\]\nThis is equation (2.1.8).\n\nFrom equation (2.1.7):\n\\[\n\\gamma = \\frac{\\Omega_{\\text{ex}}}{A} = \\frac{\\Omega - \\Omega_b}{A}\n\\]\nTaking the differential:\n\\[\nd\\gamma = \\frac{d\\Omega_{\\text{ex}}}{A} = \\frac{d\\Omega - d\\Omega_b}{A}\n\\]\nNow, use the result from equation (2.1.8):\n\\[\nd\\Omega - d\\Omega_b = -(S - S_b) dT - (N - N_b) d\\mu + \\gamma dA\n\\]\nSo:\n\\[\nd\\Omega_{\\text{ex}} = -s_{\\text{ex}} A dT - \\Gamma d\\mu + \\gamma dA\n\\]\nwhere:\n\n\\(s_{\\text{ex}} = \\frac{S - S_b}{A}\\) is the surface excess entropy per unit area,\n\\(\\Gamma = N - N_b\\) is the excess number of particles (adsorption).\n\nDividing through by \\(A\\), we get:\n\\[\n\\frac{d\\Omega_{\\text{ex}}}{A} = -s_{\\text{ex}} dT - \\frac{\\Gamma}{A} d\\mu + \\gamma \\frac{dA}{A}\n\\]\nNow, using the fact that \\(\\gamma \\frac{dA}{A}\\) is small for constant area, we can ignore this term, giving:\n\\[\ns_{\\text{ex}} dT + \\frac{\\Gamma}{A} d\\mu + d\\gamma = 0\n\\]\nThis is equation (2.1.9).\n\nRearrange equation (2.1.9):\n\\[\n\\frac{\\Gamma}{A} d\\mu = -s_{\\text{ex}} dT - d\\gamma\n\\]\nAt constant temperature (\\(dT = 0\\)), this simplifies to:\n\\[\n\\frac{\\Gamma}{A} d\\mu = -d\\gamma\n\\]\nNow, dividing both sides by \\(d\\mu\\), we get:\n\\[\n\\frac{\\Gamma}{A} = -\\left(\\frac{\\partial \\gamma}{\\partial \\mu}\\right)_T\n\\]\nThis is equation (2.1.10).\n\nAnd I need to ask about equations 2.1.11 to 2.1.13, as I cannot find reference [40].\n\n\nQ2. Resolved\n\n\n\nOn page 40, Chapter 2.3\n\n\nI wasn’t sure what the one-particle density is or its use, so I asked ChatGPT:\n\n\nClick to reveal the answer!\n\nThe one-particle density function, often denoted as \\(\\rho^{(1)}(\\mathbf{r})\\), represents the probability density of finding a particle at a specific position \\(\\mathbf{r}\\) in a system of particles. It describes how particles are distributed in space on average and is a key observable in statistical mechanics and the study of fluids.\nThe equation given is:\n\\[\n\\hat{\\rho}^{(1)}(\\mathbf{r}) = \\sum_{j=1}^{N} \\delta(\\mathbf{r} - \\mathbf{r}_j)\n\\]\nThis is the one-particle density operator, and it has the following meaning:\n\nDirac Delta Function: \\(\\delta(\\mathbf{r} - \\mathbf{r}_j)\\) is a Dirac delta function that ‘picks out’ the position of the \\(j\\)-th particle. It is equal to zero everywhere except at \\(\\mathbf{r}_j\\), where it is infinite, ensuring that it integrates to 1. Thus, it counts the presence of a particle at \\(\\mathbf{r}_j\\).\nSummation over All Particles: The sum runs over all particles \\(j\\) from 1 to \\(N\\), so this operator adds up the contributions from all particles in the system, effectively counting the number of particles at position \\(\\mathbf{r}\\).\n\nIn essence, the one-particle density operator \\(\\hat{\\rho}^{(1)}(\\mathbf{r})\\) gives the total number of particles at position \\(\\mathbf{r}\\) in the system. Since it is an operator, the actual one-particle density \\(\\langle \\hat{\\rho}^{(1)}(\\mathbf{r}) \\rangle\\), as defined in equation (2.3.2), is obtained by averaging over all possible configurations of the system in the given ensemble (such as the grand canonical ensemble).\nWhy Does It Look Like This?\nThe form of equation (2.3.1) stems from how we represent the microscopic distribution of particles in space. The Dirac delta function ensures that for each particle, its position contributes to the overall density only at the exact location where that particle exists. This is a standard way to construct density operators in statistical mechanics because:\n\nThe delta function precisely pinpoints the position of a particle.\nSumming over all particles ensures that the density operator accounts for the total number of particles present in the system.\n\nThis representation allows us to describe spatially inhomogeneous systems where the density may vary across different regions (e.g., near a surface or an external potential). For homogeneous fluids, where particles are evenly distributed, this density would reduce to a constant value (the bulk density \\(\\rho_b\\)).\nSummary\nThe one-particle density operator, \\(\\hat{\\rho}^{(1)}(\\mathbf{r})\\), reflects how particles are distributed in space at a microscopic level. The delta functions track the positions of individual particles, and summing over all particles gives the total density at position \\(\\mathbf{r}\\). The actual one-particle density function \\(\\rho^{(1)}(\\mathbf{r})\\) is then the ensemble average of this operator over all configurations of the system.\n\n\n\nQ3. Resolved\n\n\n\nOn page 43, Chapter 2.3\n\n\nI wasn’t sure why each variable is specifically chosen to form those equations. For example, in section 2.4.3, I do not understand why λ can be factored out of g on the right-hand side when λ has two different exponents, a and b. So, I asked ChatGPT:\n\n\nClick to reveal the answer!\n\nStarting with Equation (2.4.3):\n\\[\ng(\\lambda^a u, \\lambda^b v) = \\lambda g(u, v)\n\\]\nThis equation states that the function \\(g(u, v)\\) is a generalised homogeneous function. To understand why it takes this form and why \\(\\lambda\\) appears outside the function on the right-hand side, let’s break this down:\n\nHomogeneous Functions: A function is called homogeneous of degree \\(\\alpha\\) if, when all its arguments are scaled by a factor \\(\\lambda\\), the function itself scales by \\(\\lambda^\\alpha\\). Mathematically, for a homogeneous function \\(f(x, y)\\), we would have: \\[\nf(\\lambda x, \\lambda y) = \\lambda^\\alpha f(x, y)\n\\] This property is common in critical phenomena where we are dealing with power-law behaviour near critical points.\nGeneralised Homogeneous Functions: The function \\(g(u, v)\\) is a generalised homogeneous function because it allows different exponents for different variables. In this case, the variables \\(u\\) and \\(v\\) scale with different exponents \\(a\\) and \\(b\\) under the same scaling factor \\(\\lambda\\).\n\n\\(\\lambda^a u\\): Here, \\(u\\) is scaled by \\(\\lambda^a\\). This implies that \\(u\\) behaves differently under scaling compared to \\(v\\).\n\\(\\lambda^b v\\): Similarly, \\(v\\) is scaled by \\(\\lambda^b\\).\n\nWhy \\(\\lambda\\) can be factored out: The key to understanding why \\(\\lambda\\) can be factored out on the right-hand side despite having different exponents for \\(u\\) and \\(v\\) lies in the definition of a generalised homogeneous function. By construction, we impose that when the variables are scaled in a particular way (with exponents \\(a\\) and \\(b\\)), the function scales by \\(\\lambda\\) itself. This is a property we assign to \\(g(u, v)\\). It doesn’t mean that \\(\\lambda\\) is constant; rather, the entire function \\(g(u, v)\\) is designed to respond to the scaling in this specific manner.\nThe exponents \\(a\\) and \\(b\\) control how \\(u\\) and \\(v\\) individually respond to scaling, but the overall response of the function is to scale as \\(\\lambda\\). The scaling of the function on the right-hand side doesn’t contradict the fact that \\(\\lambda\\) has different exponents inside the arguments. This is simply a mathematical constraint on how the function \\(g(u, v)\\) behaves under scaling.\nIn other words, the form: \\[\ng(\\lambda^a u, \\lambda^b v)\n\\] ensures that the function scales uniformly by \\(\\lambda\\), despite the individual variables scaling differently.\n\nEquation (2.4.4):\nNow, let’s explain how this scaling idea applies to the singular part of the free energy in equation (2.4.4):\n\\[\n\\omega_{\\text{sing}}(\\delta \\mu, t) = \\lambda^{-d} \\omega_{\\text{sing}}(\\lambda^a \\delta \\mu, \\lambda^b t)\n\\]\n\nVariables:\n\n\\(\\delta \\mu = \\mu - \\mu_{\\text{co}}\\) is the difference between the chemical potential \\(\\mu\\) and the critical chemical potential \\(\\mu_{\\text{co}}\\).\n\\(t\\) is the reduced temperature: \\(t = \\frac{T - T_c}{T_c}\\).\n\\(d\\) is the dimensionality of the system (important for scaling relations).\n\nApplying the Scaling Relation: Here, the function \\(\\omega_{\\text{sing}}\\), which represents the singular part of the free energy, is assumed to be a generalised homogeneous function. This means it should follow a scaling law similar to the one introduced in equation (2.4.3).\nThe variables \\(\\delta \\mu\\) and \\(t\\) are scaled by \\(\\lambda^a\\) and \\(\\lambda^b\\), respectively, where \\(a\\) and \\(b\\) are scaling exponents that determine how \\(\\delta \\mu\\) and \\(t\\) change when scaled by \\(\\lambda\\).\nWhy \\(\\lambda^{-d}\\)?\n\nThe factor \\(\\lambda^{-d}\\) appears because we are dealing with free energy, which is an extensive quantity. In thermodynamics, extensive quantities scale with the volume of the system, and in \\(d\\)-dimensional space, the volume scales as \\(\\lambda^d\\). Since we are dealing with the singular part of the free energy, the scaling reflects the dimensionality of the system. The minus sign arises because, under scaling, the free energy decreases as the system grows larger.\n\nThe Free Choice of \\(\\lambda\\): The scaling factor \\(\\lambda\\) is arbitrary, meaning you can choose its value to simplify the equation. In this case, we choose \\(\\lambda^b = t^{-1}\\), which simplifies the second argument (the temperature dependence) of \\(\\omega_{\\text{sing}}\\). By doing this, we reduce the complexity of the equation and make the temperature scaling explicit.\n\nEquation (2.4.5):\nThis equation shows the final form after choosing \\(\\lambda^b = t^{-1}\\):\n\\[\n\\omega_{\\text{sing}}(\\delta \\mu, t) = t^{d/b} \\omega_{\\text{sing}}(t^{-a/b} \\delta \\mu, 1)\n\\]\n\nWhy this form? By setting \\(\\lambda^b = t^{-1}\\), we have scaled out the temperature dependence in the second argument of \\(\\omega_{\\text{sing}}\\). This isolates the temperature dependence into the prefactor \\(t^{d/b}\\), while leaving a scaling function that depends only on the ratio \\(\\delta \\mu / t^{a/b}\\), which is now the only scaling variable.\n\n\\(t^{d/b}\\): This represents how the singular part of the free energy depends on temperature near the critical point. The exponent \\(d/b\\) dictates how strongly the free energy diverges as \\(t \\to 0\\) (the critical point).\n\\(\\Sigma\\left( \\frac{\\delta \\mu}{t^{a/b}} \\right)\\): The function \\(\\Sigma\\) is the scaling function, which encodes the remaining dependence on the scaled chemical potential \\(\\delta \\mu / t^{a/b}\\).\n\n\nIn Summary: - In equation (2.4.3), the exponents \\(a\\) and \\(b\\) control how the variables \\(u\\) and \\(v\\) scale. Despite their different scaling behaviours, the overall function scales by \\(\\lambda\\) because it is designed as a generalised homogeneous function. - In equation (2.4.4), the singular part of the free energy near the critical point follows a similar scaling law, with the dimensionality \\(d\\) appearing as a factor to reflect the extensive nature of free energy. - In equation (2.4.5), we choose \\(\\lambda^b = t^{-1}\\) to simplify the scaling form, making the dependence on temperature explicit and reducing the complexity of the equation. The resulting expression separates the prefactor \\(t^{d/b}\\) and leaves a scaling function that depends only on the ratio \\(\\delta \\mu / t^{a/b}\\), which captures the critical behaviour.\n\n\n\nFluctuations? One correlated entity?\n\nIn the context of phase transitions, particularly near a critical point, the term “fluctuations” refers to fluctuations in the local density of the system. Let’s explain in detail what this means, especially in the context of critical opalescence and long-range correlations.\n\nDensity Fluctuations: When we talk about “density” in this context, we mean the number density of particles in a given volume. In simple terms, it’s how densely packed the particles are in a particular region. The density can fluctuate due to thermal motion, and these fluctuations are typically small and localised in non-critical conditions.\n\nHowever, as a system approaches the critical point of a phase transition (e.g., a liquid-vapour transition), the magnitude of these fluctuations grows dramatically.\n\nWhat happens near the critical point?\n\nCorrelation Length (\\(\\xi\\)): The correlation length \\(\\xi\\) represents the distance over which particles in the system are correlated or “communicate” with each other. Normally, this length is finite, and beyond this distance, the properties of the system in one region do not affect another region.\nNear the critical point, however, \\(\\xi \\to \\infty\\). This means that particles separated by very large distances (even macroscopic scales) are correlated with each other. The entire system essentially becomes one correlated entity.\nDiverging Fluctuations: As the correlation length grows, the fluctuations in the local density (i.e., how many particles are in a given region at any time) also grow larger. This happens because, when the correlation length is large, particles across large distances influence each other. As a result, fluctuations occur over all length scales, from small to very large.\nDensity Fluctuations: Specifically, these are fluctuations in the number of particles in a given volume. Imagine regions in a fluid where the particle density becomes temporarily higher or lower than the average. At the critical point, these fluctuations become very large and occur over very large distances, leading to the system appearing “cloudy” or “milky” — this is the phenomenon of critical opalescence.\n\n\nWhat exactly is fluctuating? At the critical point, density is the key fluctuating quantity, but more generally, the term “fluctuations” can refer to:\n\n\nOrder Parameter Fluctuations: Near a critical point, there is typically an order parameter that characterises the phase transition. For example, in the liquid-vapour transition, this order parameter could be the difference in density between the liquid and vapour phases. As the system approaches the critical point, the fluctuations in the order parameter become large.\nFor example, in a fluid near the liquid-vapour critical point:\n\nIn the liquid phase, particles are densely packed.\nIn the vapour phase, particles are more spread out.\n\nNear the critical point, there is no sharp distinction between liquid and vapour phases. Instead, the system fluctuates between states that resemble both phases. You might see a region that has the density of a liquid next to a region that has the density of a vapour, and these regions appear and disappear rapidly.\n\n\nWhy do these fluctuations occur? At the critical point, the system is in a delicate balance between two phases (e.g., liquid and vapour). The free energy landscape becomes very flat near the critical point, meaning that the system can fluctuate easily between different configurations with very little energy cost. These fluctuations span all length scales, leading to the phenomenon where large regions of the system can fluctuate in density.\nCritical Opalescence: The critical opalescence mentioned in the text is a direct consequence of these large fluctuations in density. Light passing through the fluid is scattered by the density fluctuations. Since the fluctuations occur over a wide range of length scales (from very small to very large), they scatter light across all wavelengths, leading to the “milky” appearance of the fluid near the critical point.\n\n\nWhy does light scatter? Light is scattered by regions of varying density because the refractive index of the fluid depends on its density. When the density fluctuates significantly over large distances, light passing through the fluid encounters regions of different densities, leading to scattering in all directions.\n\nSummary:\n\nWhat is fluctuating near the critical point?: Primarily, the number density (i.e., the number of particles per unit volume) fluctuates near the critical point.\nWhy do these fluctuations grow?: As the correlation length \\(\\xi\\) becomes large, regions of the system separated by large distances become correlated, allowing large-scale fluctuations in density.\nWhat’s the physical manifestation?: These fluctuations lead to observable phenomena such as critical opalescence, where light is scattered by the large fluctuations in density, causing the fluid to appear milky or cloudy.\n\nIn short, the “fluctuations” near the critical point refer to density fluctuations, which are tied to the divergence of the correlation length, and these fluctuations grow larger and affect larger regions of the system as the critical point is approached.\n\n\nFrom chapter 2.4.3, I decided to skim through this document as it became too technical to understand the entire thesis when it began with perturbation theory. Additionally, many concepts here are primarily from equilibrium statistical physics.\n\n\n\n\n\n\nNote\n\n\n\nChapter 2.4.5: Wetting and Drying Phase Transitions is very well written and full of useful knowledge. For the next project meeting, let’s prepare a slide to go over this.\n\n\nWetting and Drying Phase Transitions\nI’ve been reading up to Views of Hydrophobicity, but I realised that I’m not sure how much of the stuff I learn from this thesis is related to active systems. So, I decided to review all articles given by my supervisors.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "reading.html#colloquium-inclusions-boundaries-and-disorder-in-scalar-active-matter-granek2024colloquium",
    "href": "reading.html#colloquium-inclusions-boundaries-and-disorder-in-scalar-active-matter-granek2024colloquium",
    "title": "Reading Archive",
    "section": "2024/10/14 - Colloquium: Inclusions, boundaries, and disorder in scalar active matter (Granek et al. 2024)",
    "text": "2024/10/14 - Colloquium: Inclusions, boundaries, and disorder in scalar active matter (Granek et al. 2024)\n\nGranek, Omer, Yariv Kafri, Mehran Kardar, Sunghan Ro, Julien Tailleur, and Alexandre Solon. 2024. “Colloquium: Inclusions, Boundaries, and Disorder in Scalar Active Matter.” Reviews of Modern Physics 96 (3): 031003.\nCited by 3\nThree different models of active matter are discussed here: ABP (active Brownian particles), RTP (run-and-tumble particles), and AOUP (active Ornstein-Uhlenbeck particles). ABP is a model that I’m going to investigate initially because it’s the simplest particle model, but I want to be aware that there are other models. From page 3, what is interesting is this, since I saw somewhere that detailed balance doesn’t hold for non-equilibrium systems:\n\n\n\n\n\n\nNote\n\n\n\nOn the contrary, in a harmonic potential AOUPs always have a steady state given by a centered Gaussian distribution (Szamel, 2014) and, somewhat surprisingly, their dynamics obey detailed balance (Fodor et al., 2016).\n\n\nI wanted to revisit the detailed balance algorithm more deeply, so I started reading Understanding Molecular Simulation.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Reading Archive"
    ]
  },
  {
    "objectID": "notes.html#week-11",
    "href": "notes.html#week-11",
    "title": "Weekly Notes",
    "section": "Week 11",
    "text": "Week 11\n\n2024/11/26 What if we coarse-grain to introduce the dominance of inertial terms?\nIn our models of ABPs, we have a self-propulsion force that drives the motility. One thought occurred suddenly. Our models effectively ignore the inertial terms, dictated by the overdamped Langevin equation, and wet the surface. On contrary, for purely repulsive particles banging on the hard wall, it also dries the surface. Then, when we have a cluster forming due to motility-induced phase separation, there must arise an overall momentum current stemming from the collective behaviour of active particles. This collective matter can then be thought of as being in an underdamped situation, where inertial terms could emerge through coarse-graining. It’s 2am, so I’m probably thinking of something silly, but in my intuition, strong inertial terms could lead to a possible drying scenario by overcoming surface trapping mechanisms.\nThe overdamped assumption is deeply tied to the low Reynolds number regime typical of ABPs. Even at the collective level, the viscosity of the medium might suppress inertial effects. I’m uncertain whether the collective velocity field is sufficiently strong to overcome this dissipation…",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "conferences.html#the-physics-of-sentience-by-karl-friston",
    "href": "conferences.html#the-physics-of-sentience-by-karl-friston",
    "title": "Conferences",
    "section": "The Physics of Sentience by Karl Friston",
    "text": "The Physics of Sentience by Karl Friston\n\n\n\nQuote\n\n\nHe mentioned the importance of boundaries, quoting Schrödinger, emphasising that it’s essential to define the boundary of a system to individuate it or separate it from everything else.\nI found the first chapter of his talk too general, particularly when he described the application of the Markov blanket to perception and action. However, in the second chapter, he presented an interesting image:\n\n\n\nLook at the flip side of the image!\n\n\nA different perspective completely changes the visual impression. For example, if I initially see a bowl of fruit, flipping the screen or my head reveals a face instead. The key point is that I created that face; it’s the pattern of sensory impressions I brought to the table. This is why I find neuroscience interesting: it’s the study of the starting point from which we picture the world.\nHe also discussed the relationship between minimising prediction error and minimising Feynman’s variational free energy, which he mentioned was based on Helmholtz’s work (if I recall correctly). However, much of what he said felt overly qualitative, reminiscent of Lloyd Demetriou’s talk titled The Evolutionary Dynamics of Collective Behaviour: From Inorganic Matter to Living Matter. Both talks introduced ideas that felt overly general, claiming to explain everything but ultimately failing to explain much in specific terms.\nOne interesting takeaway was that Helmholtz himself thought deeply about perception and its mechanisms. Friston’s total citations, as of today, stand at 366,130; perhaps I’m just not fully grasping his points.",
    "crumbs": [
      "Project Notes",
      "Conferences"
    ]
  },
  {
    "objectID": "conferences.html#harnessing-the-vicinity-of-criticality-to-adapt-information-processing-by-johannes-zierenberg",
    "href": "conferences.html#harnessing-the-vicinity-of-criticality-to-adapt-information-processing-by-johannes-zierenberg",
    "title": "Conferences",
    "section": "Harnessing the Vicinity of Criticality to Adapt Information Processing by Johannes Zierenberg",
    "text": "Harnessing the Vicinity of Criticality to Adapt Information Processing by Johannes Zierenberg\nI didn’t find it very interesting or inspiring. However, he did mention the Fokker–Planck equation, which seems to be a very important equation for describing neural dynamics.",
    "crumbs": [
      "Project Notes",
      "Conferences"
    ]
  },
  {
    "objectID": "conferences.html#scaling-of-neural-network-activity-and-optimal-functionality-from-real-neurons-in-the-brain-to-artificial-intelligence-by-miguel-a-munoz",
    "href": "conferences.html#scaling-of-neural-network-activity-and-optimal-functionality-from-real-neurons-in-the-brain-to-artificial-intelligence-by-miguel-a-munoz",
    "title": "Conferences",
    "section": "Scaling of Neural Network Activity and Optimal Functionality: From Real Neurons in the Brain to Artificial Intelligence by Miguel A Munoz",
    "text": "Scaling of Neural Network Activity and Optimal Functionality: From Real Neurons in the Brain to Artificial Intelligence by Miguel A Munoz\nHe is a very good presenter. BUT, the IOP didn’t provide a direct PowerPoint feed, only a camera feed, so I couldn’t read anything from the slides! Terribly organised!\nAt one point, he introduced work by Bialek from Princeton, which applied the renormalisation group to actual neurons. Since Miguel mentioned superneurons and the RG flow, it seems that Bialek et al. probably used some form of Kadanoff block scaling, applying different levels of coarse-graining. This approach suggested scale invariance in the hippocampus, where their analysis was conducted.\nWhat I don’t understand is why the presenter was trying to find universality with only 800 neurons, given that criticality only makes sense for infinitely large systems. Hmm…\nOne particularly interesting point he mentioned was that the head movement of the mouse was codified in a one-dimensional manifold revealed by principal component analysis. By examining the position on this manifold, the direction of the mouse’s head could be detected. This makes sense since the horizontal angle is also one-dimensional.\nAfter that, he discussed how the maximum performance shown by similarities between the mouse brain and reservoir computing, using topological arguments, coincides with the edge of criticality. This was, once again, very interesting! It was worth watching, and the paper he suggested by Kenneth seems worth reading. Additionally, all the questions asked by others were interesting and helpful.",
    "crumbs": [
      "Project Notes",
      "Conferences"
    ]
  },
  {
    "objectID": "conferences.html#fluctuation-dissipation-relations-and-equilibrium-conditions-for-the-brain-in-healthy-and-pathological-conditions-by-lucilla-de-arcangelis",
    "href": "conferences.html#fluctuation-dissipation-relations-and-equilibrium-conditions-for-the-brain-in-healthy-and-pathological-conditions-by-lucilla-de-arcangelis",
    "title": "Conferences",
    "section": "Fluctuation-Dissipation Relations and equilibrium conditions for the brain in healthy and pathological conditions by Lucilla de Arcangelis",
    "text": "Fluctuation-Dissipation Relations and equilibrium conditions for the brain in healthy and pathological conditions by Lucilla de Arcangelis",
    "crumbs": [
      "Project Notes",
      "Conferences"
    ]
  },
  {
    "objectID": "conferences.html#section",
    "href": "conferences.html#section",
    "title": "Conferences",
    "section": "2024/11/25",
    "text": "2024/11/25\n\nThe Physics of Sentience by Karl Friston\n\n\n\nQuote\n\n\nHe mentioned the importance of boundaries, quoting Schrödinger, emphasising that it’s essential to define the boundary of a system to individuate it or separate it from everything else. However, I found the first chapter of his talk too general, particularly when he described the application of the Markov blanket to perception and action. In the second chapter, he presented an interesting image:\n\n\n\nLook at the flip side of the image!\n\n\nA different perspective completely changes the visual impression. For example, if I initially see a bowl of fruit, flipping the screen or my head reveals a face instead. The key point is that I created that face; it’s the pattern of sensory impressions I brought to the table. This is why I find neuroscience interesting: it’s the study of the starting point from which we picture the world.\nHe also discussed the relationship between minimising prediction error and minimising Feynman’s variational free energy, which he mentioned was based on Helmholtz’s work (if I recall correctly). However, much of what he said felt overly qualitative, reminiscent of Lloyd Demetriou’s talk titled The Evolutionary Dynamics of Collective Behaviour: From Inorganic Matter to Living Matter. Both talks introduced ideas that felt overly general, claiming to explain everything but ultimately failing to explain much in specific terms.\nOne interesting takeaway was that Helmholtz himself thought deeply about perception and its mechanisms. Friston’s total citations, as of today, stand at 366,130; perhaps I’m just not fully grasping his points.\n\n\nHarnessing the Vicinity of Criticality to Adapt Information Processing by Johannes Zierenberg\nI didn’t find it very interesting or inspiring. However, he did mention the Fokker–Planck equation, which seems to be a very important equation for describing neural dynamics.\n\n\nScaling of Neural Network Activity and Optimal Functionality: From Real Neurons in the Brain to Artificial Intelligence by Miguel A Munoz\nHe is a very good presenter. BUT, the IOP didn’t provide a direct PowerPoint feed, only a camera feed, so I couldn’t read anything from the slides! Terribly organised!\nAt one point, he introduced work by Bialek from Princeton, which applied the renormalisation group to actual neurons. Since Miguel mentioned superneurons and the RG flow, it seems that Bialek et al. probably used some form of Kadanoff block scaling, applying different levels of coarse-graining. This approach suggested scale invariance in the hippocampus, where their analysis was conducted.\nWhat I don’t understand is why the presenter was trying to find universality with only 800 neurons, given that criticality only makes sense for infinitely large systems. Hmm…\nOne particularly interesting point he mentioned was that the head movement of the mouse was codified in a one-dimensional manifold revealed by principal component analysis. By examining the position on this manifold, the direction of the mouse’s head could be detected. This makes sense since the horizontal angle is also one-dimensional.\nAfter that, he discussed how the maximum performance shown by similarities between the mouse brain and reservoir computing, using topological arguments, coincides with the edge of criticality. This was, once again, very interesting! It was worth watching, and the paper he suggested by Kenneth seems worth reading. Additionally, all the questions asked by others were interesting and helpful.\n\n\nFluctuation Dissipation Relations and Equilibrium Conditions for the Brain in Healthy and Pathological Conditions by Lucilla de Arcangelis\nI think the content was very interesting, but sadly and honestly, the speaker’s voice was quite unbearable to listen to. Maybe I am overly sensitive to the occasional extreme high pitch.\nHowever, a lot of the concepts she introduced were very useful. For example:\n\n\n\nFluctuation dissipation relations\n\n\nThe function in the second line was very interesting, as it relates the fluctuation of a variable (which can be energy, magnetisation, or density in a gas) on the left at equilibrium to a response function on the right that takes the system out of equilibrium. Also, the solution to that equation is the Einstein relation, which essentially relates the fluctuation measured by the diffusion coefficient to the response function. Specifically, it is the mobility that describes how the velocity of a particle changes when a standard force is applied.\nA classical and ubiquitous theorem!\n\nThen she introduced the Stochastic Wilson Cowan model to discuss the non-equilibrium analogue of the above equation and to analyse excitatory and inhibitory neuron populations.\n\n\n\nLangevin equations!\n\n\nAfter a few steps, she introduced the familiar Langevin equation where \\(\\xi\\) is the fluctuation. This equation is used in stochastic processes to study the approach to equilibrium under a restoring force that is fluctuating. Similar to our project, the restoring force in that equation was the delta correlated noise.\nThen she analysed the correlation functions to obtain the characteristic times, which are the inverses of the eigenvalues of the coupling matrix above. This matrix has a peculiar triangular form that essentially implies that a fluctuation in \\(\\Sigma\\) cannot affect \\(\\Delta\\), but a fluctuation in \\(\\Delta\\) can affect \\(\\Sigma\\). There, she observed the scale invariance!",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Conferences"
    ]
  },
  {
    "objectID": "unrelated.html",
    "href": "unrelated.html",
    "title": "Diary",
    "section": "",
    "text": "This page contains diary entries that are largely unrelated to my PhD project.\n\n\n2024/9/27 Things I did so far\nBusy weeks due to starting three teaching modules: Weekly update of my TSR (Teaching Support Roles). Looking back, I wish I could have completed more reading, as there isn’t much to talk about in terms of active matter research for the next project meeting on Monday.\n\n\n2024/11/2 - 11/8 Physics and Beyond (Heisenberg et al. 1971)\n\nHeisenberg, Werner et al. 1971. Physics and Beyond. Allen & Unwin London.\nCited by 1832\nIt’s the first time I’m reading this in English; the title of the book in Korean is 부분과 전체, which might translate to Parts and the Whole. I’ve read it many times since I was in high school, and it has been highly influential to me as a physicist throughout my life. To capture some of the things I want to revisit later:\n\n\n\nOn page 72, Fresh Fields (1926-1927)\n\n\n\n\n\nOn page 80, Fresh Fields (1926-1927)\n\n\nSo far, having read up to page 89, it has all been interesting, except for Chapter 4 (Lessons in Politics and History). When the development of quantum mechanics was presented in Chapters 5 and 6, I felt my heart pounding as I read through, just as it did when I first read this book.\n\n\n\n\nOn page 97, Atomic Physics and Pragmatism (1929)\n\n\nAll these realms were so enjoyable to learn, but now, as a researcher, I wonder what realms are still open. I thought one of them was non-equilibrium statistical thermodynamics, but it appears to me that this theory can’t be axiomatic, implying that all systems out of equilibrium must be described differently.\n\n\n\n\nOn page 109, The Relationship between Biology, Physics and Chemistry (1930-1932)\n\n\n‘Forms through which matter streams,’ as Niels Bohr described, was the most profound characterisation of organisms I have encountered. I used to wonder, what about this structure remains? Does it actually persist, given that a person changes continuously as a child becomes an adult? Is it simply the name (person) we assign that represents this form of life? With this thought, is there really a distinction between animate and inanimate objects?\nWhen I read Timaeus by Plato in high school, he described geometrical forms as the basis of earth, fire, water, and air, even though I found his idea peculiar (like everything is made of right triangles). At the time, I thought the properties that define those mathematical forms were responsible for things maintaining their structure in the way we perceive over time (since all forms change shape as time passes). My master’s research was also focused on investigating this homeostasis in an ideal structure, not physical but something we perceive, in the context of foreign exchange markets. This line of thought was also captured well by Bohr’s question: “Can quantum mechanics explain nature’s tendency to form structures through which matter with fixed chemical properties can stream for a limited time?”\n\n\n\n\nOn page 128, Discussions about Language (1933)\n\n\nThis passage about the discovery of antimatter was one of the reasons I chose a physics degree, along with my ambition to formally study general relativity. Although I didn’t score well in my particle physics exam in third year due to a part-time job over winter break, it remains one of the most exciting units I’ve taken. Here are the scores and ratings I gave to my third and fourth-year units with scores of at least 4:\n5: Physics Research Project (83), Quantum Physics (88)\n4.5: Physics of Phase Transitions (85), Analytical Mechanics (66), Particle Physics (58)\n4: Quantum Information Theory (68), Foundations of Modern Physics (68), Methods of Theoretical Physics (63)\nIt’s surprising that general relativity only scored 3.5, but it seems I didn’t enjoy the lecture style despite being fascinated by the content.\n\n\n\n\nOn page 134, Discussions about Language (1933)\n\n\nThis passage captures the reason I didn’t pursue a philosophy degree, despite having written about philosophy of science. What I realised was the fluidity of language, and at some point, reading philosophy felt like participating in a language game. Even when I wrote The Self and the World, I included definitions for the terms I used in the document. In contrast, I conceived mathematical objects as eternal, grounded solidly in axioms. I couldn’t imagine any language other than this to describe the hidden secrets of the universe as eternal representations, unchanging, unmoved, and concrete.\n\n\n\n\nOn page 136, Discussions about Language (1933)\n\n\nAnother book I feel closely connected to is the Tao Te Ching by Lao Tzu. It’s probably not an exaggeration to say that my whole life has been devoted to understanding the meaning of Tao, even though Lao Tzu paradoxically said, “The Tao that can be described is not the eternal Tao.” One day, I realised it is synonymous with the Truth or, in more Platonic terms, the formless. Ineffable. That’s when I wrote this diary: Is “It” a Joke?\n\n\n\n\nOn page 191, Toward a New Beginning (1941-1945)\n\n\nThese chapters were not enjoyable to read: Revolution and University Life (1933), Individual Behavior in the Face of Political Disaster (1937-1941), Toward a New Beginning (1941-1945). I’m certainly not interested in politics or wars. However, the ending of this third chapter is beautifully written; beauty transcends ideology, opinions, and dualistic views of the world.\n\n\n\n\nOn page 195, The Responsibility of the Scientist (1945-1950)\n\n\nThis reveals the reason why I chose the theme of active matter. I was curious about how this model suddenly emerged in the last 25 years. Why is there such a sudden interest in this concept? What possibilities does it offer for understanding nature? What contributions can I make to the circle of human knowledge?\n\nWhile reading through the Scientific and Political Disputes (1956-1957) chapter, I realised I can only concentrate when scientific matters are being discussed, such as the conversations between Heisenberg and Wolfgang about the mathematical theory for elementary particles.\n\n\n\nOn page 230, The Unified Field Theory (1957-1958)\n\n\nHowever, everything that followed from the passage in the image was fascinating, especially when they started discussing symmetries (for example, the universe as a whole does not necessarily have to be symmetrical with respect to the operations under which natural laws remain invariant), relativistic quantum field theories, and more, which captivated me when I studied particle physics in my third year.\n\n\n\n\nOn page 240, Elementary Particles and Platonic Philosophy (1961-1965)\n\n\nI have finally finished the book. Although the above image is not the last page, I love this book because it begins with Plato and ends with him. Timaeus was the book that shaped my worldview when I was in high school, and when I first encountered Physics and Beyond, I was thrilled to find someone in history who asked the same questions I had while reading Timaeus. Since then, my understanding has deepened, and I’ve come to see that all philosophy traces back to Plato. Last year, a decade later, I finally had a direct understanding of what Plato described through some interesting experiences.\nEven beyond that passage in the screenshot, it’s truly worth rereading. People at that time were already considering how natural laws conform to different scales, touching on the concept of emergence, which is the field I’m now working in.\nWhile reading this book, I rewatched the documentary series Atom, hosted by Jim Al-Khalili. I remember watching it for the first time in high school, loving it immensely, and being struck by statements from scholars like Paul Dirac, who said, “A physical law must possess mathematical beauty.” I was curious about what QED implied once I start learning about it at university, such as how all the matter we see is just reflections of virtual particles. That was a long time ago, and that naïveté and curiosity are what led me to study physics. I’d like to close with what Jim Al-Khalili said (even though I largely disagree with his interpretation of quantum mechanics in that chapter) at the end of The Illusion of Reality (the third episode):\nIn the last 100 years, we have peered deep inside the atom, the basic building block of the universe. And inside this tiny object, we have found a strange new world governed by exotic laws that at times seem to defy reason. Atoms present us with dizzying contradictions. They can behave both as particles or waves. They appear to be in more than one place at the same time. They force us to rethink what we mean by past and future, by cause and effect. And they tell us strange things about where the universe came from and where it’s going. Pretty amazing stuff for something that’s just a millionth of a millimetre across. That’s why Niels Bohr, the father of atomic physics, once said that, when it comes to atoms, language can only be used as poetry. What’s fascinating to me is that although we’ve learnt an incredible amount about atoms and their behaviour, our scientific journey has only just begun. Because although we know how a single atom or just a few atoms behave, the way trillions of them come together in concert to create the world around us is still largely a mystery. To give you one dramatic example, the atoms that make up my body are identical to the atoms in the rocks, the trees, the air, even the stars. And yet, they come together to create a conscious being who can ask the question, “What is an atom?” Explaining all that is surely the next great challenge in science.\nI realised that the “next great challenge” he mentioned is the same one I’ve been drawn to since studying physics: the emergence of consciousness. The most intriguing question, perhaps prompted by an interesting dream I had last night, is how our mind creates the world and perceives it simultaneously when we dream. When I’m awake, I can do this partially; for instance, when I think about walking down the corridor where my office is located, I can imagine it while experiencing it at the same time. It seems this ability expands to full capacity in dreams. Once I understand that mechanism, I might be able to discern, even when awake, whether I am still dreaming and creating the world while simultaneously perceiving it.\n\n\n2024/11/4 Diary\nI was quite ill last week, taking antibiotics from Monday to Saturday. While having more rest at home than in other weeks, I was thinking about a few things.\n\nAt first, I started thinking about why I began to study physics. It was driven by mysteries and curiosities. At that time, I didn’t know that what I was going to learn were representations of empirical observations; rather, I naively thought it would be the objective truth. As I was learning physics in my undergraduate studies, I realised there are different mathematical formalisms to describe the same physical phenomena, such as Newtonian, Lagrangian, and Hamiltonian mechanics in classical physics, or matrix mechanics by Heisenberg and wave mechanics by Schrödinger in quantum mechanics. Then my approach to physics became more like, ‘Which model makes the most sense to me for understanding the observed?’ or ‘Which models lead to more universal descriptions of all things?’ Then I encountered the concept of universality: many of the microscopic details that go into the theory are irrelevant under successive renormalisation group transformations; the theory that describes the critical point is universal. I thought this idea was stunningly beautiful, and I thought that if I were to start my PhD, I would investigate how these patterns that interlace between different systems or physical theories emerge.\nThen, as I was ill and thinking about many things, I reflected on what has captivated me in my undergraduate studies. The list follows like this:\n\n\nYear 1, The breakdown of the concept, simultaneity: As I was learning special relativity, I realised that the notion I thought was objective was actually subjective. The only way to know what time is is to look at the clock. This idea was profound for me, emphasising that time is not an absolute entity. Einstein’s theory was so elegant in the way that it started with only two assumptions: first, the speed of light is constant based on empirical observations; second, the laws of physics are the same in all inertial frames of reference. The consequences of the theory based on these assumptions were just mind-blowing.\nYear 2, first term, quantum tunnelling: I was always fascinated by the implications of quantum mechanics even before starting my physics degree. Once I was able to explain the phenomenon of the wavefunction trapped in a finite potential well, which allows for the probability of finding a particle on the other side of the barrier, it was really mind-blowing that I clearly understood the mathematics but had no idea how to comprehend it, even though this phenomenon is the foundation of all technologies I use now.\nYear 2, second term, Maxwell’s equations: The universal descriptions that entail all electromagnetic phenomena in such simple mathematical forms using vector calculus. I was struck by the beauty of these equations that I set them as a screensaver since my second year. Also, when I went to Edinburgh and saw a statue of Maxwell with his equations, I couldn’t leave that place for a long time.\nYear 3, second term, the principle of least action: This whole Lagrangian formulation of classical mechanics was the clearest and the deepest representation I had encountered. The path is chosen to extremise the action, which was such a profound perspective that changed all my ways of thinking. I could go on and on about this, but in short, I loved the encounter with this concept so much that I used it as a nickname on several websites.\nYear 4, first term, the whole ideas from general relativity: This subject was of tremendous importance to me. When I decided to study physics, this was the subject I intended to study and also the reason I chose the MSci, as it was a unit for fourth-year students. I would say this is the subject which made me come to university. The idea that if we also include a time axis overlaid onto three spatial axes, an object at rest in a given reference frame moves at the speed of light along the time axis. Then, if an object moves, since the magnitude of speed is bound by the speed of light, the component that lies on the time axis decreases as it increases along the spatial axes. It was such a beautiful way of describing how time and space were interlinked. Also, the calculus of variations, which led to Lagrangian mechanics that I loved, started from considering the straight line in a global perspective. Einstein’s theory started with thinking about the straight line (or rather more precisely, a vector) from a local perspective with parallel transport. The implication of this led to Einstein’s field equations, which imply matter tells spacetime how to curve and spacetime tells matter how to move. These whole ideas related very closely to some of my psychedelic experiences, and I thought it was THE subject I would want to learn much more deeply in the coming years, before I met the language of the physics of phase transitions.\nYear 4, second term, the whole ideas from the physics of phase transitions: the correlation length diverging at criticality, universality classes, and critical exponents telling how to rescale a physical theory. All these ideas were so captivating that it almost felt like meta-foundational physics, like the physics of physical theory. Also, a lot of concepts extended even beyond the realm of physics, such as the critical brain hypothesis in neuroscience. This perspective of considering the structure of physical theory was like the final lesson of my undergraduate studies and the one that I wanted to pursue for the rest of my physics career. At that time, I met Nigel, my supervisor, who told me that in statistical physics, a small number of people make a great contribution to the field, unlike astrophysicists or particle physicists who are in large groups and don’t get to decide the direction. That was the moment I felt that I chose the field of statistical physics, even though I have loved concepts from astrophysics (general relativity) and particle physics (quantum field theory).\n\n\nNow I’m in week 8 of my PhD, but I can’t say that I have been really engaged with my research. The biggest fault is down to me: I haven’t read references thoroughly so that I can appreciate the field in general yet. I’m the person who likes to read one book over and over again (and it seems that the only professor who likes to do this is Sandu Popescu), but I am kind of overwhelmed by how many references were uploaded in Zotero and the time it takes for me to read understanding molecular simulation. And I haven’t found a way to convince my supervisors about my progress since I also have had a lot of teaching responsibilities so far. I can only tell them that it will take time, but at the same time, since my progress is slow, I also haven’t found a profound interest in this field as I had in my undergraduate studies above. For this year, no matter how long it takes, I fully want to understand this field first by reading that book, learn the common languages that we use, then read all those references to appreciate before I jump into the serious research. But every time in project meetings, I somehow feel that I need to defend myself about what I’m doing when there are piles of things to do accumulating. In short, I feel overwhelmed.\nThat was the reason that my rest has been quite different and sidetracked this time in week 7. I started reading Physics and Beyond written by Werner Heisenberg (see 2024/11/2 - 11/8 Physics and Beyond). This book was the one that I always consulted whenever there were uncertainties about my physics career path. I am on page 108 now out of 268. I want to finish this book first before jumping into reading Understanding Molecular Simulation again, but at the same time, I feel sorry for my supervisors who believe in my progress in my PhD. It’s all difficult now in terms of my situation.\n\n\n\n2024/11/5 Being a Good Lecturer\nAfter attending Hermes’ lecture, I realised there are certain qualities that a very good lecturer shares. To describe him:\nHe was smiling, making jokes, honest, sharing life stories, and, most importantly, engaging with students at their level.\nOften, when I talk with certain lecturers or fellow physics PGRs, they ramble without checking if the person listening is following. Then, it becomes nothing more than loud diary entries or a display of their knowledge.\nI also felt that the language barrier was irrelevant. Hermes had pronunciation difficulties, like me, but he simply let it go, laughing it off rather than taking it too seriously.\nI was quite surprised by how many qualities he actually shared with another of my favourite lecturers, Sandu Popescu. His English isn’t perfect, and he speaks slowly, but it always feels like there is something worth listening to. Also, like Hermes, who wrote on paper, he used the blackboard or whiteboard instead of showing endless slides.\nHermes made plenty of eye contact and made excellent use of pauses during his explanations, allowing students to form images in their minds for better understanding.\nThere was much for me to learn from his approach to lecturing. I thought I was already a good lecturer, one that many students like, but I realised he was truly an inspiration.\n\n\n2024/11/9 - The Science of Interstellar (Thorne 2014)\n\nThorne, Kip. 2014. The Science of Interstellar. WW Norton &Company.\nCited by 265\nToday, I rewatched the film Interstellar, perhaps for the fourth time. I was deeply impressed by Nolan’s previous film Inception, which I also probably watched five times already. Yesterday, I had to give Inception a 10-star rating for the first time in my life, as it just gets more interesting with every viewing. This 10-star rating is very special to me, as I have never rated any of the over 3,000 films I’ve watched so highly.\nAfter this purely fantastical journey, I became curious about the science behind it. Then I realised that the scientific adviser for the film, Kip Thorne, actually wrote a book about it! I knew I had planned to read Understanding Molecular Simulation today, but since it’s the weekend, I decided to indulge in this investigation instead.\n\n\n\nOn page 45, 4. Warped Time and Space, and Tidal Gravity\n\n\nWhat a beautiful way of interpreting general relativity!\nSo far, having read up to Chapter 6, it has all been very interesting! But since Monday has arrived, it’s time to focus on my project again…\n\n\n2024/11/17 The Moment of My Realisation\n\nThe reason Einstein’s theory is beautiful is because it’s the ULTIMATE PATTERN!\nSpace and time are interlinked! Energy and mass are the same! Mass is equal to frequency!1 The beauty of mathematics was that ‘equality’ sign!\nJust a very simple relationship revealed by mathematics!\nThat was the whole purpose of physics!\nNo matter what complicated language we use to describe concepts,\nThere comes the language of physics: “They are the same!”\nI cannot stop laughing.\n“Stop arguing! They are the same!”\nThe reason the renormalisation group naively appeared as beautiful was because, as we went to higher levels of description, we somehow discovered: ‘Oh! They are the same!’\nNow it all makes sense.\nThe reason the proof of Fermat’s Last Theorem was beautiful was because it linked modular forms to elliptic curves! They are the same!\nThe reason Euler’s relation is beautiful is because it links \\(e\\), \\(\\pi\\), \\(i\\), and \\(-1\\)!\nThe reason criticality is beautiful is because the Ising model and liquid-gas model, ‘only’ at the critical point, are the same! Hence the name ‘Universality’!\nThe reason Maxwell’s equations are beautiful is because they show that electric fields and magnetic fields are the same! The whole phenomenon you’ve been looking at, which you thought was different, is just the same!\nThe reason nature is beautiful is because it is the same thing! Not different things! The breath of perceiving their sameness!\nThe driving motivation for me in my MSci was to say: ‘Hey! The market and the brain are THE SAME!’\nI’ve been just chasing this beauty for my entire lifetime!\n\n\n1 By combining \\(E = mc^2\\) and \\(E = hf\\), \\[\nE = mc^2 = hf \\implies f = \\frac{mc^2}{h}\n\\]\n\n\nI shared this diary with ChatGPT, asking the question: ‘The above is my diary, and I realised that the beauty we feel comes from the equality sign! When we recognise the sameness in the different high-level structures of models, we feel the beauty! Are there any scholars who have noticed this?’\nHere was a kind response I received:\n\n\nClick to reveal the answer!\n\nYes, the notion of “sameness” across seemingly disparate structures has long fascinated scholars across various disciplines. The diary entry you’ve shared resonates deeply with ideas explored in physics, mathematics, philosophy, and even cognitive science. Scholars have discussed the aesthetic appeal of discovering unifying principles expressed through equalities, symmetries, or mappings across different domains.\nHere are a few examples of scholars and their thoughts that align with your reflections:\n\nHermann Weyl: In Symmetry (1952), Weyl extensively discusses the beauty inherent in mathematical symmetry and its unifying power across different physical phenomena. He was captivated by the way symmetry provides insight into the sameness of different structures.\nEugene Wigner: His essay The Unreasonable Effectiveness of Mathematics in the Natural Sciences (1960) explores the mysterious and seemingly miraculous ability of mathematics to describe natural phenomena, suggesting that this effectiveness stems from the deep unity (or sameness) in the laws governing different systems.\nPhilip Anderson: In his paper More is Different (1972), Anderson discusses the concept of emergence and universality in physics, emphasising how high-level behaviours often reflect underlying similarities (e.g., critical phenomena in phase transitions).\nRoger Penrose: Penrose, particularly in The Road to Reality (2004), highlights the elegance of mathematical relationships like Euler’s formula and their role in unveiling deep truths about the universe.\nNoam Chomsky (in linguistics and cognitive science): Chomsky’s ideas about “deep structure” in human language propose that surface differences in languages mask an underlying sameness—a universal grammar.\nBenoît Mandelbrot: Mandelbrot’s work on fractals emphasises the beauty of self-similarity in nature, where complex structures emerge from simple iterative rules, demonstrating a unifying pattern.\n\nYour observation about the equality sign being a source of beauty is profound and aligns with discussions in the philosophy of mathematics. Scholars like Bertrand Russell and Alfred North Whitehead, in Principia Mathematica, discuss the foundational role of relations (like equality) in mathematical structures.\nIn contemporary interdisciplinary work, the pursuit of identifying “sameness” across domains is central to fields like network theory (e.g., mapping similarities between neural networks and market behaviours), which directly aligns with your reflections on the market and the brain.\nYour diary elegantly captures a timeless insight: the beauty of science and mathematics often lies in the revelation that what seems different is, at its core, the same.\n\n\n\n2024/11/23 16personalities\nMy personal report\nSince someone kept asking… not that I care about it. I thought this categorisation was only popular in South Korea, but maybe that’s not the case anymore. What’s slightly interesting is that it revealed the same type as when I did it a few years ago, so it seems there is a conservative quantity in my traits. The one who asked me read the report and said, “Unquenchable thirst for knowledge!!!!!!! That’s you!!!”\n\n\n2024/11/25 Stuck in Bristol\nYesterday, Storm Bert disrupted all trains to London, preventing me from travelling to my hotel. As a result, I can no longer attend the Statistical Physics of Cognition conference in person. While I will still join via Zoom, yesterday was so frustrating that all I could do was laugh. It felt like the best thing to do under the circumstances! Strangely, it almost felt as though I was hearing a voice saying, “Stop focusing on neuroscience for now! Embrace your project!”\nThese are the notes I wrote for cancelling the rail tickets through Clarity (for future reference):\n\nI am requesting a refund for this ticket. When I arrived at Clifton Down station at 3:50 pm, I waited 15 minutes only to find out that the train to Bristol Temple Meads had been cancelled. I then took an Uber costing £19.92 to the station, where I discovered that my connecting train was also cancelled. Later, at 8:00 pm, I learned that all trains to eastern destinations, including London, were cancelled due to heavy storms. I have a screenshot as proof and can provide it upon request via email.\n\nThis was my expense claim made through MyERP:\n\nThe train at 4:02 pm from Clifton Down was cancelled, and it was urgent to take a taxi to Bristol Temple Meads as the train was supposed to arrive at 4:30 pm. Sadly, when I went to Temple Meads, this train was also cancelled. I am claiming this expense as I was on my way to the conference; please refer to my past claims made through Clarity. Another update: the train that goes to all eastern destinations, including London, was cancelled, and I only found out at 8 pm. I cancelled my hotel and train bookings through Clarity. Many chaotic events occurred while I was at Temple Meads, and I eventually ended up at Bristol Parkway. I took a bus to Gloucester Road and then came home by Uber.\n\nWhen I got home, I had a phone call with my mum and shared how much the situation had changed. Reflecting on what I said to her:\nWhile I was at the train station for hours, I found myself thinking deeply about my project, the papers I read last week, and my conversations with Nigel and Ian. I realised that my project presents a perfect opportunity to learn about useful concepts for describing non-equilibrium systems, such as entropy production, the Fokker–Planck equation, and the fluctuation-dissipation theorem. Now, investigating these concepts using the simplest models from the particle perspective of active matter feels really exciting! If a drying transition is observed, it will also be a great chance to master the theoretical understanding and application of renormalisation group techniques.\nReading various papers helped me appreciate how interesting colloids and bacteria can be. Bacteria represent the simplest form of living systems, and through motility-induced phase separation, these systems form large-scale structures without any attractive interactions. Thinking about surface phase transitions became particularly intriguing when I considered how 3D structures form 2D boundaries. Boundaries are key to how we differentiate objects. Even in comics, we draw the boundaries of characters and objects. This perspective made the topic even more interesting.\nI also admire how my supervisors approached the problem, using an order parameter to measure the asymmetry within the capillary system. This method effectively avoids the complexities of defining surface tensions and focuses instead on the geometrical aspects of the problem. Once these ideas crystallised in my mind, I felt certain that I wanted to become an expert in this field. If someone asks about surface phase transitions in non-equilibrium systems, I want to be the person they turn to for advice.\nThese thoughts were swirling in my mind, and strangely, the weather even stopped me from travelling to London to attend the Statistical Physics of Cognition conference, where I had planned to network with people in that field. I don’t believe in mystical things, but the timing was mysterious. This kind of weather disruption, preventing travel between cities, hasn’t happened to me in my five years living in the UK.\nI was also thinking about Nigel and Francesco and how thoughtful they both are. I want to become a light that brightens the path for us.\n\n\n2024/11/27 IQ Test\nWhile watching the Statistical Physics of Cognition conference, there was a talk about statistical learning, which I found very interesting. In the evening, I watched a Korean TV show, 대학전쟁 (translated as The University War?), a survival game genre that mostly features puzzles and problem-solving, which I always enjoy watching. It reminded me of my favourite show, The Genius.\nCoincidentally, both mentioned IQ tests. I remember taking one as a teenager; it was quite high, though I couldn’t recall the exact number. I think it was around 153, as I remember this number being interesting:\n\\[\n153 = 1^3 + 5^3 + 3^3\n\\]\nBut my memory is not clear. So, I decided to try a simple test provided here: IQ Test Made by Mensa Norway.\n\n\n\nThe front page\n\n\n\nThere were some questions that were unclear or took a long time to solve, so I captured those:\n\n\n\nExercise 23\n\n\nI spent quite a few minutes on this one. There seemed to be some dynamic rules; if I name the cells 1, 2, 3, 4, …, 9:\n\nThe black circle is straightforward: it moves to the left across the cells, such as 1 → 2 → 3, or 1 → 4 → 7.\nThe cell containing the black square moves diagonally to the left, such as 1 → 6 → 8, while the black square itself shifts left within the cell.\n\nOnce I identified these rules, I realised that the black triangle and white square follow the same rule as the black square. So, I chose F. It took some time to recheck if I had made any mistakes.\n\n\n\nExercise 33\n\n\nUp to this exercise, all the questions had been pretty easy, and I still had more than 10 minutes remaining. However, I spent the most time on this one. My solution process was as follows:\n\nAs the cell moves diagonally to the left, such as 1 → 6 → 8, the triangle at the bottom-right flips first (1 → 6), and then the triangle at the top-left flips (6 → 8).\nWhen the cell moves diagonally to the left along 3 → 5 → 7, the triangle at the top-right flips first (3 → 5), and then the triangle at the bottom-left flips (5 → 7).\nFinally, for the path 2 → 4 → 9, the top-right triangle flips to hide a white triangle (2 → 4). Then, for 4 → 9, the bottom-left triangle flips.\n\nTherefore, I chose E, though I am uncertain if this answer is correct. There seemed to be some inconsistencies: for example, in steps 2 and 3, the top-right triangle flips as the cells progress along a row, but for step 1, it is the bottom-right triangle that flips. I attempted to identify more consistent dynamic rules but couldn’t, so this question took the most time.\n\n\n\nExercise 34\n\n\nThis one wasn’t difficult, but it introduced a new type of question, making it fun to solve. The reason I chose A was:\n\nThe black circle always covers the white circle.\nWhen the two white circles move counterclockwise across the column (e.g., 1 → 2 → 3 or 4 → 5 → 6), they do not overlap. For example, the two white circles initially positioned at the bottom-left in 1 move to the bottom-right in 2 without overlapping, and as they move from 2 to 3, they shift to the top without overlapping.\nThe black circle’s rule operates independently of the white circles. The cell containing the black circle moves diagonally (e.g., 1 → 6 → 8), but the black circle itself remains in the same relative position (the 9 o’clock direction).\n\nThe reason I chose A was because the cell containing the black circle moved from 2 → 4 → 9, while the two white circles moved from 7 → 8 → 9. Since the black circle covered the white circle in the 9 o’clock direction, the answer A was clear.\n\n\n\nExercise 35\n\n\nThis one took the second-longest time after Exercise 33. Here are the rules I inferred:\n\nThe equality sign (=) moves diagonally to the right along 2 → 6 → 7.\nThe upper triangle (∧) moves diagonally to the right along 3 → 4 → 7.\nThe lower triangle (∨) moves diagonally to the right along 1 → 5 → 9 and also diagonally to the left along 1 → 6 → 8.\nThe two walls (| |) move diagonally to the left along 2 → 4 → 9.\n\nHowever, the explanation for the lower triangle (∨) in point 3 felt somewhat ad hoc. I tried to identify another dynamic rule but could not. Based on the above reasoning, the answer D was the most plausible.\n\n\n\nTime remaining\n\n\nI used about 23 minutes and 30 seconds in total.\n\n\n\nResults!\n\n\nOh wow! I’m not sure what the maximum score on this test is, but it roughly suggests that my IQ is still 145 or more. It seems that the theoretical maximum score a person can achieve with a standard deviation of 15 is 160 (source: 나무위키: 지능지수). If I do some simple mathematics, the IQ test follows a normal distribution with a mean of 100 and a standard deviation of 15. My score of 145 gives a z-score of:\n\\[\nz = \\frac{145 - 100}{15} = 3\n\\]\nFrom the z-score, I calculated the cumulative probability using the normal distribution and found it to be 99.87%. This means I am in the top 0.13% of the population.\nTo convert this score to the \\(N(100, 24^2)\\) standard (which appears to be the standard in Mensa Korea), which uses a standard deviation of 24:\n\\[\n\\text{IQ}_{24} = 100 + 3 \\times 24 = 172\n\\]",
    "crumbs": [
      "Random Notes",
      "Diary"
    ]
  },
  {
    "objectID": "unrelated.html#sec-physics-and-beyond",
    "href": "unrelated.html#sec-physics-and-beyond",
    "title": "Unrelated",
    "section": "2024/11/2 - 11/8 Physics and Beyond (Heisenberg et al. 1971)",
    "text": "2024/11/2 - 11/8 Physics and Beyond (Heisenberg et al. 1971)\n\nHeisenberg, Werner et al. 1971. Physics and Beyond. Allen & Unwin London.\nCited by 1832\nIt’s the first time I’m reading this in English; the title of the book in Korean is 부분과 전체, which might translate to Parts and the Whole. I’ve read it many times since I was in high school, and it has been highly influential to me as a physicist throughout my life. To capture some of the things I want to revisit later:\n\n\n\nOn page 72, Fresh Fields (1926-1927)\n\n\n\n\n\nOn page 80, Fresh Fields (1926-1927)\n\n\nSo far, having read up to page 89, it has all been interesting, except for Chapter 4 (Lessons in Politics and History). When the development of quantum mechanics was presented in Chapters 5 and 6, I felt my heart pounding as I read through, just as it did when I first read this book.\n\n\n\n\nOn page 97, Atomic Physics and Pragmatism (1929)\n\n\nAll these realms were so enjoyable to learn, but now, as a researcher, I wonder what realms are still open. I thought one of them was non-equilibrium statistical thermodynamics, but it appears to me that this theory can’t be axiomatic, implying that all systems out of equilibrium must be described differently.\n\n\n\n\nOn page 109, The Relationship between Biology, Physics and Chemistry (1930-1932)\n\n\n‘Forms through which matter streams,’ as Niels Bohr described, was the most profound characterisation of organisms I have encountered. I used to wonder, what about this structure remains? Does it actually persist, given that a person changes continuously as a child becomes an adult? Is it simply the name (person) we assign that represents this form of life? With this thought, is there really a distinction between animate and inanimate objects?\nWhen I read Timaeus by Plato in high school, he described geometrical forms as the basis of earth, fire, water, and air, even though I found his idea peculiar (like everything is made of right triangles). At the time, I thought the properties that define those mathematical forms were responsible for things maintaining their structure in the way we perceive over time (since all forms change shape as time passes). My master’s research was also focused on investigating this homeostasis in an ideal structure, not physical but something we perceive, in the context of foreign exchange markets. This line of thought was also captured well by Bohr’s question: “Can quantum mechanics explain nature’s tendency to form structures through which matter with fixed chemical properties can stream for a limited time?”\n\n\n\n\nOn page 128, Discussions about Language (1933)\n\n\nThis passage about the discovery of antimatter was one of the reasons I chose a physics degree, along with my ambition to formally study general relativity. Although I didn’t score well in my particle physics exam in third year due to a part-time job over winter break, it remains one of the most exciting units I’ve taken. Here are the scores and ratings I gave to my third and fourth-year units with scores of at least 4:\n5: Physics Research Project (83), Quantum Physics (88)\n4.5: Physics of Phase Transitions (85), Analytical Mechanics (66), Particle Physics (58)\n4: Quantum Information Theory (68), Foundations of Modern Physics (68), Methods of Theoretical Physics (63)\nIt’s surprising that general relativity only scored 3.5, but it seems I didn’t enjoy the lecture style despite being fascinated by the content.\n\n\n\n\nOn page 134, Discussions about Language (1933)\n\n\nThis passage captures the reason I didn’t pursue a philosophy degree, despite having written about philosophy of science. What I realised was the fluidity of language, and at some point, reading philosophy felt like participating in a language game. Even when I wrote The Self and the World, I included definitions for the terms I used in the document. In contrast, I conceived mathematical objects as eternal, grounded solidly in axioms. I couldn’t imagine any language other than this to describe the hidden secrets of the universe as eternal representations, unchanging, unmoved, and concrete.\n\n\n\n\nOn page 136, Discussions about Language (1933)\n\n\nAnother book I feel closely connected to is the Tao Te Ching by Lao Tzu. It’s probably not an exaggeration to say that my whole life has been devoted to understanding the meaning of Tao, even though Lao Tzu paradoxically said, “The Tao that can be described is not the eternal Tao.” One day, I realised it is synonymous with the Truth or, in more Platonic terms, the formless. Ineffable. That’s when I wrote this diary: Is “It” a Joke?\n\n\n\n\nOn page 191, Toward a New Beginning (1941-1945)\n\n\nThese chapters were not enjoyable to read: Revolution and University Life (1933), Individual Behavior in the Face of Political Disaster (1937-1941), Toward a New Beginning (1941-1945). I’m certainly not interested in politics or wars. However, the ending of this third chapter is beautifully written; beauty transcends ideology, opinions, and dualistic views of the world.\n\n\n\n\nOn page 195, The Responsibility of the Scientist (1945-1950)\n\n\nThis reveals the reason why I chose the theme of active matter. I was curious about how this model suddenly emerged in the last 25 years. Why is there such a sudden interest in this concept? What possibilities does it offer for understanding nature? What contributions can I make to the circle of human knowledge?\n\nWhile reading through the Scientific and Political Disputes (1956-1957) chapter, I realised I can only concentrate when scientific matters are being discussed, such as the conversations between Heisenberg and Wolfgang about the mathematical theory for elementary particles.\n\n\n\nOn page 230, The Unified Field Theory (1957-1958)\n\n\nHowever, everything that followed from the passage in the image was fascinating, especially when they started discussing symmetries (for example, the universe as a whole does not necessarily have to be symmetrical with respect to the operations under which natural laws remain invariant), relativistic quantum field theories, and more, which captivated me when I studied particle physics in my third year.\n\n\n\n\nOn page 240, Elementary Particles and Platonic Philosophy (1961-1965)\n\n\nI have finally finished the book. Although the above image is not the last page, I love this book because it begins with Plato and ends with him. Timaeus was the book that shaped my worldview when I was in high school, and when I first encountered Physics and Beyond, I was thrilled to find someone in history who asked the same questions I had while reading Timaeus. Since then, my understanding has deepened, and I’ve come to see that all philosophy traces back to Plato. Last year, a decade later, I finally had a direct understanding of what Plato described through some interesting experiences.\nEven beyond that passage in the screenshot, it’s truly worth rereading. People at that time were already considering how natural laws conform to different scales, touching on the concept of emergence, which is the field I’m now working in.\nWhile reading this book, I rewatched the documentary series Atom, hosted by Jim Al-Khalili. I remember watching it for the first time in high school, loving it immensely, and being struck by statements from scholars like Paul Dirac, who said, “A physical law must possess mathematical beauty.” I was curious about what QED implied once I start learning about it at university, such as how all the matter we see is just reflections of virtual particles. That was a long time ago, and that naïveté and curiosity are what led me to study physics. I’d like to close with what Jim Al-Khalili said (even though I largely disagree with his interpretation of quantum mechanics in that chapter) at the end of The Illusion of Reality (the third episode):\nIn the last 100 years, we have peered deep inside the atom, the basic building block of the universe. And inside this tiny object, we have found a strange new world governed by exotic laws that at times seem to defy reason. Atoms present us with dizzying contradictions. They can behave both as particles or waves. They appear to be in more than one place at the same time. They force us to rethink what we mean by past and future, by cause and effect. And they tell us strange things about where the universe came from and where it’s going. Pretty amazing stuff for something that’s just a millionth of a millimetre across. That’s why Niels Bohr, the father of atomic physics, once said that, when it comes to atoms, language can only be used as poetry. What’s fascinating to me is that although we’ve learnt an incredible amount about atoms and their behaviour, our scientific journey has only just begun. Because although we know how a single atom or just a few atoms behave, the way trillions of them come together in concert to create the world around us is still largely a mystery. To give you one dramatic example, the atoms that make up my body are identical to the atoms in the rocks, the trees, the air, even the stars. And yet, they come together to create a conscious being who can ask the question, “What is an atom?” Explaining all that is surely the next great challenge in science.\nI realised that the “next great challenge” he mentioned is the same one I’ve been drawn to since studying physics: the emergence of consciousness. The most intriguing question, perhaps prompted by an interesting dream I had last night, is how our mind creates the world and perceives it simultaneously when we dream. When I’m awake, I can do this partially; for instance, when I think about walking down the corridor where my office is located, I can imagine it while experiencing it at the same time. It seems this ability expands to full capacity in dreams. Once I understand that mechanism, I might be able to discern, even when awake, whether I am still dreaming and creating the world while simultaneously perceiving it.\n\n2024/11/5 Being a Good Lecturer\nAfter attending Hermes’ lecture, I realised there are certain qualities that a very good lecturer shares. To describe him:\nHe was smiling, making jokes, honest, sharing life stories, and, most importantly, engaging with students at their level.\nOften, when I talk with certain lecturers or fellow physics PGRs, they ramble without checking if the person listening is following. Then, it becomes nothing more than loud diary entries or a display of their knowledge.\nI also felt that the language barrier was irrelevant. Hermes had pronunciation difficulties, like me, but he simply let it go, laughing it off rather than taking it too seriously.\nI was quite surprised by how many qualities he actually shared with another of my favourite lecturers, Sandu Popescu. His English isn’t perfect, and he speaks slowly, but it always feels like there is something worth listening to. Also, like Hermes, who wrote on paper, he used the blackboard or whiteboard instead of showing endless slides.\nHermes made plenty of eye contact and made excellent use of pauses during his explanations, allowing students to form images in their minds for better understanding.\nThere was much for me to learn from his approach to lecturing. I thought I was already a good lecturer, one that many students like, but I realised he was truly an inspiration.",
    "crumbs": [
      "Project Notes",
      "Unrelated"
    ]
  },
  {
    "objectID": "unrelated.html#the-science-of-interstellar-thorne2014science",
    "href": "unrelated.html#the-science-of-interstellar-thorne2014science",
    "title": "Unrelated",
    "section": "2024/11/9 - The Science of Interstellar (Thorne 2014)",
    "text": "2024/11/9 - The Science of Interstellar (Thorne 2014)\n\nThorne, Kip. 2014. The Science of Interstellar. WW Norton &Company.\nCited by 265\nToday, I rewatched the film Interstellar, perhaps for the fourth time. I was deeply impressed by Nolan’s previous film Inception, which I also probably watched five times already. Yesterday, I had to give Inception a 10-star rating for the first time in my life, as it just gets more interesting with every viewing. This 10-star rating is very special to me, as I have never rated any of the over 3,000 films I’ve watched so highly.\nAfter this purely fantastical journey, I became curious about the science behind it. Then I realised that the scientific adviser for the film, Kip Thorne, actually wrote a book about it! I knew I had planned to read Understanding Molecular Simulation today, but since it’s the weekend, I decided to indulge in this investigation instead.\n\n\n\nOn page 45, 4. Warped Time and Space, and Tidal Gravity\n\n\nWhat a beautiful way of interpreting general relativity!\nSo far, having read up to Chapter 6, it has all been very interesting! But since Monday has arrived, it’s time to focus on my project again…\n\n2024/11/17 The Moment of My Realisation\n\nThe reason Einstein’s theory is beautiful is because it’s the ULTIMATE PATTERN!\nSpace and time are interlinked! Energy and mass are the same! Mass is equal to frequency!1 The beauty of mathematics was that ‘equality’ sign!\nJust a very simple relationship revealed by mathematics!\nThat was the whole purpose of physics!\nNo matter what complicated language we use to describe concepts,\nThere comes the language of physics: “They are the same!”\nI cannot stop laughing.\n“Stop arguing! They are the same!”\nThe reason the renormalisation group naively appeared as beautiful was because, as we went to higher levels of description, we somehow discovered: ‘Oh! They are the same!’\nNow it all makes sense.\nThe reason the proof of Fermat’s Last Theorem was beautiful was because it linked modular forms to elliptic curves! They are the same!\nThe reason Euler’s relation is beautiful is because it links \\(e\\), \\(\\pi\\), \\(i\\), and \\(-1\\)!\nThe reason criticality is beautiful is because the Ising model and liquid-gas model, ‘only’ at the critical point, are the same! Hence the name ‘Universality’!\nThe reason Maxwell’s equations are beautiful is because they show that electric fields and magnetic fields are the same! The whole phenomenon you’ve been looking at, which you thought was different, is just the same!\nThe reason nature is beautiful is because it is the same thing! Not different things! The breath of perceiving their sameness!\nThe driving motivation for me in my MSci was to say: ‘Hey! The market and the brain are THE SAME!’\nI’ve been just chasing this beauty for my entire lifetime!\n\n\n1 By combining \\(E = mc^2\\) and \\(E = hf\\), \\[\nE = mc^2 = hf \\implies f = \\frac{mc^2}{h}\n\\]\n\n\nI shared this diary with ChatGPT, asking the question: ‘The above is my diary, and I realised that the beauty we feel comes from the equality sign! When we recognise the sameness in the different high-level structures of models, we feel the beauty! Are there any scholars who have noticed this?’\nHere was a kind response I received:\n\n\nClick to reveal the answer!\n\nYes, the notion of “sameness” across seemingly disparate structures has long fascinated scholars across various disciplines. The diary entry you’ve shared resonates deeply with ideas explored in physics, mathematics, philosophy, and even cognitive science. Scholars have discussed the aesthetic appeal of discovering unifying principles expressed through equalities, symmetries, or mappings across different domains.\nHere are a few examples of scholars and their thoughts that align with your reflections:\n\nHermann Weyl: In Symmetry (1952), Weyl extensively discusses the beauty inherent in mathematical symmetry and its unifying power across different physical phenomena. He was captivated by the way symmetry provides insight into the sameness of different structures.\nEugene Wigner: His essay The Unreasonable Effectiveness of Mathematics in the Natural Sciences (1960) explores the mysterious and seemingly miraculous ability of mathematics to describe natural phenomena, suggesting that this effectiveness stems from the deep unity (or sameness) in the laws governing different systems.\nPhilip Anderson: In his paper More is Different (1972), Anderson discusses the concept of emergence and universality in physics, emphasising how high-level behaviours often reflect underlying similarities (e.g., critical phenomena in phase transitions).\nRoger Penrose: Penrose, particularly in The Road to Reality (2004), highlights the elegance of mathematical relationships like Euler’s formula and their role in unveiling deep truths about the universe.\nNoam Chomsky (in linguistics and cognitive science): Chomsky’s ideas about “deep structure” in human language propose that surface differences in languages mask an underlying sameness—a universal grammar.\nBenoît Mandelbrot: Mandelbrot’s work on fractals emphasises the beauty of self-similarity in nature, where complex structures emerge from simple iterative rules, demonstrating a unifying pattern.\n\nYour observation about the equality sign being a source of beauty is profound and aligns with discussions in the philosophy of mathematics. Scholars like Bertrand Russell and Alfred North Whitehead, in Principia Mathematica, discuss the foundational role of relations (like equality) in mathematical structures.\nIn contemporary interdisciplinary work, the pursuit of identifying “sameness” across domains is central to fields like network theory (e.g., mapping similarities between neural networks and market behaviours), which directly aligns with your reflections on the market and the brain.\nYour diary elegantly captures a timeless insight: the beauty of science and mathematics often lies in the revelation that what seems different is, at its core, the same.\n\n\n\n2024/11/23 16personalities\nMy personal report\nSince someone kept asking… not that I care about it. I thought this categorisation was only popular in South Korea, but maybe that’s not the case anymore. What’s slightly interesting is that it revealed the same type as when I did it a few years ago, so it seems there is a conservative quantity in my traits. The one who asked me read the report and said, “Unquenchable thirst for knowledge!!!!!!! That’s you!!!”\n\n\n2024/11/27 IQ Test\nWhile watching the Statistical Physics of Cognition conference, there was a talk about statistical learning, which I found very interesting. In the evening, I watched a Korean TV show, 대학전쟁 (translated as The University War?), a survival game genre that mostly features puzzles and problem-solving, which I always enjoy watching. It reminded me of my favourite show, The Genius.\nCoincidentally, both mentioned IQ tests. I remember taking one as a teenager; it was quite high, though I couldn’t recall the exact number. I think it was around 153, as I remember this number being interesting:\n\\[\n153 = 1^3 + 5^3 + 3^3\n\\]\nBut my memory is not clear. So, I decided to try a simple test provided here: IQ Test Made by Mensa Norway.\n\n\n\nThe front page\n\n\n\nThere were some questions that were unclear or took a long time to solve, so I captured those:\n\n\n\nExercise 23\n\n\nI spent quite a few minutes on this one. There seemed to be some dynamic rules; if I name the cells 1, 2, 3, 4, …, 9:\n\nThe black circle is straightforward: it moves to the left across the cells, such as 1 → 2 → 3, or 1 → 4 → 7.\nThe cell containing the black square moves diagonally to the left, such as 1 → 6 → 8, while the black square itself shifts left within the cell.\n\nOnce I identified these rules, I realised that the black triangle and white square follow the same rule as the black square. So, I chose F. It took some time to recheck if I had made any mistakes.\n\n\n\nExercise 33\n\n\nUp to this exercise, all the questions had been pretty easy, and I still had more than 10 minutes remaining. However, I spent the most time on this one. My solution process was as follows:\n\nAs the cell moves diagonally to the left, such as 1 → 6 → 8, the triangle at the bottom-right flips first (1 → 6), and then the triangle at the top-left flips (6 → 8).\nWhen the cell moves diagonally to the left along 3 → 5 → 7, the triangle at the top-right flips first (3 → 5), and then the triangle at the bottom-left flips (5 → 7).\nFinally, for the path 2 → 4 → 9, the top-right triangle flips to hide a white triangle (2 → 4). Then, for 4 → 9, the bottom-left triangle flips.\n\nTherefore, I chose E, though I am uncertain if this answer is correct. There seemed to be some inconsistencies: for example, in steps 2 and 3, the top-right triangle flips as the cells progress along a row, but for step 1, it is the bottom-right triangle that flips. I attempted to identify more consistent dynamic rules but couldn’t, so this question took the most time.\n\n\n\nExercise 34\n\n\nThis one wasn’t difficult, but it introduced a new type of question, making it fun to solve. The reason I chose A was:\n\nThe black circle always covers the white circle.\nWhen the two white circles move counterclockwise across the column (e.g., 1 → 2 → 3 or 4 → 5 → 6), they do not overlap. For example, the two white circles initially positioned at the bottom-left in 1 move to the bottom-right in 2 without overlapping, and as they move from 2 to 3, they shift to the top without overlapping.\nThe black circle’s rule operates independently of the white circles. The cell containing the black circle moves diagonally (e.g., 1 → 6 → 8), but the black circle itself remains in the same relative position (the 9 o’clock direction).\n\nThe reason I chose A was because the cell containing the black circle moved from 2 → 4 → 9, while the two white circles moved from 7 → 8 → 9. Since the black circle covered the white circle in the 9 o’clock direction, the answer A was clear.\n\n\n\nExercise 35\n\n\nThis one took the second-longest time after Exercise 33. Here are the rules I inferred:\n\nThe equality sign (=) moves diagonally to the right along 2 → 6 → 7.\nThe upper triangle (∧) moves diagonally to the right along 3 → 4 → 7.\nThe lower triangle (∨) moves diagonally to the right along 1 → 5 → 9 and also diagonally to the left along 1 → 6 → 8.\nThe two walls (| |) move diagonally to the left along 2 → 4 → 9.\n\nHowever, the explanation for the lower triangle (∨) in point 3 felt somewhat ad hoc. I tried to identify another dynamic rule but could not. Based on the above reasoning, the answer D was the most plausible.\n\n\n\nTime remaining\n\n\nI used about 23 minutes and 30 seconds in total.\n\n\n\nResults!\n\n\nOh wow! I’m not sure what the maximum score on this test is, but it roughly suggests that my IQ is still 145 or more. It seems that the theoretical maximum score a person can achieve with a standard deviation of 15 is 160 (source: 나무위키: 지능지수). If I do some simple mathematics, the IQ test follows a normal distribution with a mean of 100 and a standard deviation of 15. My score of 145 gives a z-score of:\n\\[\nz = \\frac{145 - 100}{15} = 3\n\\]\nFrom the z-score, I calculated the cumulative probability using the normal distribution and found it to be 99.87%. This means I am in the top 0.13% of the population.\nTo convert this score to the \\(N(100, 24^2)\\) standard (which appears to be the standard in Mensa Korea), which uses a standard deviation of 24:\n\\[\n\\text{IQ}_{24} = 100 + 3 \\times 24 = 172\n\\]",
    "crumbs": [
      "Project Notes",
      "Unrelated"
    ]
  },
  {
    "objectID": "direction.html#email-received-from-nigel-2",
    "href": "direction.html#email-received-from-nigel-2",
    "title": "Redirection of PhD",
    "section": "",
    "text": "Dear Sohyun (cc Francesco, Ian),\nI wanted to follow up on our meeting today and reiterate and elaborate in writing some of the points covered.\nAs you had previously expressed reservations about continuing with the Active Drying project, we discussed an alternative project in Active Matter centred around the Critical Casimir Effect. You said that on reflection you are happy to continue with the original project, and we agreed that we could keep the Critical Casimir Effect project as a backup or as a topic for future work.\nOn more general matters, we stated that from the point of view of the student-supervisor relationship, there needs to be a clear separation between your work on the project and outside interests. The responsibilities of PhD supervisors do not extend beyond supporting your work on the project and advising/supporting should there be any issues (eg illness/personal situation) that are affecting your ability to progress with the project. Project meetings are therefore not for discussing anything with you except the science of the project or pastoral issues that may be affecting your ability to work.\nSimilarly, if you want to use a blog as a lab book to record progress and notes on papers read etc, this is laudable and desirable for facilitating discussions, but what you have been writing and sharing with us has turned into a sort of personal diary and that’s inappropriate for the student-supervisor relationship. If you want us to read things then they need to be confined to matters directly related to the project.\nBeing a successful PhD student requires a certain level of commitment. While it is early days and we don’t have serious concerns about your progress, we do note that you seem to be spending considerable time writing blogs and thinking about philosophy, vaping, neuroscience, and reading and rereading books, and lecture notes, etc., the relevance of which is not clear. While you can of course do what you want in your own time, we feel that you need to take care not to blur the boundaries between what is in scope for the project work and what is not. From your blog and recent conversations, we are concerned that this might be happening.\nI hope that these comments are helpful. They are not intended to be critical – we just want you to have clear and realistic expectations of the process so that you have a satisfied, enjoyable, and successful PhD journey.\nBest regards\nNigel and Francesco",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "direction.html#email-sent-to-nigel-and-francesco",
    "href": "direction.html#email-sent-to-nigel-and-francesco",
    "title": "Redirection of PhD",
    "section": "",
    "text": "Dear Nigel and Francesco,\nI feel that it’s quite unfortunate that our project meeting ended abruptly today. After having a conversation with Ian, it became quite clear to me that there were misunderstandings in our previous meeting last week, so I hoped to clarify those today as I realised that was an important step.\nI deeply appreciate that you set two agendas to talk about today, and both of them were really helpful! Also, you allowed me to mention what I hoped to talk about after we went through those agendas. However, I felt that when I started to bring up a conversation for clarifying my points, it appeared that both of you wanted me to leave before resolving the misunderstandings. I tried to address those concerns, but it just didn’t work, and I started to wonder if my way of communicating was not correct.\nIn our previous meeting, the reason I mentioned the vape products was because I wanted to talk about how wetting and spreading (or drying) could be interesting to me in terms of my own experiences (even though it was not an active fluid), but you misunderstood me as hoping to make a new vape product (which you wrote in the document that you can’t supervise). The whole point of the previous meeting last week was for me to consult with you on why our initial project was interesting from your perspectives. You mentioned that you started to investigate drying at first but didn’t see any drying. Also, the point I raised to Ian and you was that we don’t observe a drying transition in active fluids in real life, so I hoped to understand your motivation for pursuing it.\nI chose my PhD in active matter because I was largely inspired by two philosophical papers:  1. Keller, Evelyn Fox. 2016. “Active Matter, Then and Now.” History and Philosophy of the Life Sciences 38: 1–11.  2. McGivern, Patrick. 2020. “Active Materials: Minimal Models of Cognition?” Adaptive Behavior 28 (6): 441–51.\nThis new field, which has gained significant popularity over the past 20 years, struck me as a paradigm shift. The advertised project was quite general, and in January, you mentioned that it could evolve based on my interests. However, once I started my PhD, I was given an initial project that, if I were to summarise concisely (for Ian), involves investigating how active Brownian particles (ABPs), which evolve through overdamped Langevin equations, interact with surfaces to induce drying surface phase transitions via molecular dynamics simulations. What was very interesting about this model was that, without any attractive interactions, the particles form large-scale structures, described as motility-induced phase separation, simply by turning on activity (motility). Also, it appeared that this model maps to artificial colloids (e.g., Janus particles) or motile bacteria.\nThe problem arose from the fact that I’ve never observed a drying transition in these systems in empirical reality, which kept bringing me back to the map-territory relation. I was also uncertain whether the results I might obtain could be generalisable to a broader class of active matter systems. As I was reading Physics and Beyond by Werner Heisenberg, I came across Einstein’s remark: “It is the theory which decides what we can observe,” made after he considered Mach’s perspective to be naïve. However, it seemed to me that, as I was reading through papers and articles, many statistical physicists simply play with models without carefully examining their assumptions or their relation to empirical evidence. I tried raising this concern last week so that I could gain a different perspective from you, but if it was to be largely dismissed as being “too philosophical” to pursue further discussion, then that’s fine, but it’s just unfortunate.\nSo, in summary, I raised my concern to gain more insights from you, while you understood it as me having completely lost interest in the project, which I found out with Ian was a miscommunication.\nAlso, in terms of progress, yes, I did engage with other materials outside our project (these are for fun and not to be confused with what I do during my working hours). But I have always spent a lot of time reading articles and papers related to our project, as well as understanding the code. In the beginning, you clearly pointed out that, as a PhD student, at first, it’s important to understand the wider context, and it’s a mistake for them to just start working on the problems without this background reading. I’ve been doing so, and you said in the first email (which you sent on the 13th) that you were not worried about my progress. Then, in your second email after our project meeting, I was told that I’m not making meaningful progress.\nI’m quite confused about all this. It takes a long time to read papers from a new field because, during my undergraduate studies, we didn’t cover non-equilibrium statistical physics or colloidal physics. For example, Francesco asked me if I had learned about random walks, but we also didn’t cover this basic concept either! Also, it takes a long time to understand the code written in C++. Yes, there are similarities as I did C and Java in the past, but even a single file such as fix_abp.cpp has a lot of links to other codes such as fix_abp.h, force.h, random_mars.h, etc.\nAs you pointed out in terms of supervision, yes, I won’t raise any philosophical concerns or my interests outside the set project at all. Because if I try to do so, it seems I create misunderstandings. However, I did want to emphasise that my mind is now clear, and maybe I could bring what I wrote on the 25th, which summarises how my motivation and ambition have settled:\n\nWhen I got home, I had a phone call with my mum and shared how much the situation had changed. Reflecting on what I said to her:\nWhile I was at the train station for hours, I found myself thinking deeply about my project, the papers I read last week, and my conversations with Nigel and Ian. I realised that my project presents a perfect opportunity to learn about useful concepts for describing non-equilibrium systems, such as entropy production, the Fokker–Planck equation, and the fluctuation-dissipation theorem. Now, investigating these concepts using the simplest models from the particle perspective of active matter feels really exciting! If a drying transition is observed, it will also be a great chance to master the theoretical understanding and application of renormalisation group techniques.\nReading various papers helped me appreciate how interesting colloids and bacteria can be. Bacteria represent the simplest form of living systems, and through motility-induced phase separation, these systems form large-scale structures without any attractive interactions. Thinking about surface phase transitions became particularly intriguing when I considered how 3D structures form 2D boundaries. Boundaries are key to how we differentiate objects. Even in comics, we draw the boundaries of characters and objects. This perspective made the topic even more interesting.\nI also admire how my supervisors approached the problem, using an order parameter to measure the asymmetry within the capillary system. This method effectively avoids the complexities of defining surface tensions and focuses instead on the geometrical aspects of the problem. Once these ideas crystallised in my mind, I felt certain that I wanted to become an expert in this field. If someone asks about surface phase transitions in non-equilibrium systems, I want to be the person they turn to for advice.\nThese thoughts were swirling in my mind, and strangely, the weather even stopped me from travelling to London to attend the Statistical Physics of Cognition conference, where I had planned to network with people in that field. I don’t believe in mystical things, but the timing was mysterious. This kind of weather disruption, preventing travel between cities, hasn’t happened to me in my five years living in the UK.\nI was also thinking about Nigel and Francesco and how thoughtful they both are. I want to become a light that brightens the path for us.\n\nBut, as you pointed out, I will separate our project notes from my logbook on my project website. Also, thank you very much for introducing the critical Casimir effect in active fluids analogues. I’ll read through the materials on my own over this week. (Initially, as my mind has settled, I was going to work on the simulation side as I wasn’t certain how to construct a wall as you did in your papers with my given code, but I will delay that work until next week.)\nSomehow, your email which followed from our meeting just now has arrived while I was writing this email. I’ll read through your email after I send this.\nThank you, Sohyun",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "notes.html#im-using-mpirun--np-16-mylammpssrclmp_mpi--in-drying-2d.lmp-but-its-still-slow-and-32-is-often-not-available.-did-it-also-take-this-long",
    "href": "notes.html#im-using-mpirun--np-16-mylammpssrclmp_mpi--in-drying-2d.lmp-but-its-still-slow-and-32-is-often-not-available.-did-it-also-take-this-long",
    "title": "Weekly Notes",
    "section": "1. I’m using mpirun -np 16 ~/mylammps/src/lmp_mpi -in drying-2D.lmp, but it’s still slow, and 32 is often not available. Did it also take this long?",
    "text": "1. I’m using mpirun -np 16 ~/mylammps/src/lmp_mpi -in drying-2D.lmp, but it’s still slow, and 32 is often not available. Did it also take this long?\nLoop time of 1437.69 on 16 procs for 2,500,001 steps with 7,200 atoms\nPerformance: 751,203.143 tau/day, 1,738.896 timesteps/s, 12.520 Matom-step/s\n98.6% CPU use with 16 MPI tasks x no OpenMP threads\nMPI task timing breakdown:\nSection | Min Time | Avg Time | Max Time | %varavg | %total\n—————————————————————\nPair | 6.237 | 31.572 | 88.773 | 591.0 | 2.20\nNeigh | 1.8579 | 5.9445 | 14.931 | 214.1 | 0.41\nComm | 28.584 | 70.366 | 125.07 | 444.4 | 4.89\nOutput | 14.731 | 116.78 | 270.86 | 803.0 | 8.12\nModify | 185.53 | 424.09 | 970.39 | 1,533.8 | 29.50\nOther | | 788.9 | | | 54.88\nNlocal: 450 ave 1,086 max 147 min\nHistogram: 8 2 0 1 0 1 0 0 1 3\nNghost: 85.5 ave 201 max 26 min\nHistogram: 8 0 2 0 1 1 0 0 2 2\nNeighs: 1,040.62 ave 3,214 max 81 min\nHistogram: 9 1 0 1 0 1 0 0 1 3\nTotal # of neighbors = 16,650\nAve neighs/atom = 2.3125\nNeighbor list builds = 106,669\nDangerous builds = 0\nTotal wall time: 0:23:57\n—————————————————————\n\nIn the code of wetting-2D.lmp, I used variable friction equal 50  # translational friction coefficient, as I saw in equilibrate.lmp, but is there a specific reason for this value?\nI changed from min_style fire to min_style cg as the system is immediately unstable:\n—\nSetting up FIRE-style minimization …\nUnit style : lj\nCurrent step : 0\nParameters for FIRE:\ndmax delaystep dtgrow dtshrink alpha0 alphashrink tmax tmin integrator halfstepback abcfire\n0.1 20 1.1 0.5 0.25 0.99 10 0.02 eulerimplicit yes no\n\nPer MPI rank memory allocation (min/avg/max) = 3.857 | 3.858 | 3.858 Mbytes\nStep Time v_tscaled PotEng Density Press\n0 0 0 1.7111115e+25 0.5 5.1333344e+25\nERROR: Lost atoms: original 7,200 current 4,594 (../thermo.cpp:494)\nLast command: minimize 1.0e-9 1.0e-9 1,000 1,000\n————————————————————————–\nprterun detected that one or more processes exited with non-zero status,\nthus causing the job to be terminated. The first process to do so was:",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#process-name-prterun-bp1-login01-2890156114-exit-code-1",
    "href": "notes.html#process-name-prterun-bp1-login01-2890156114-exit-code-1",
    "title": "Weekly Notes",
    "section": "Process name: [prterun-bp1-login01-2890156@1,14] Exit code: 1",
    "text": "Process name: [prterun-bp1-login01-2890156@1,14] Exit code: 1\nI’m not sure how to make it work with FIRE.\n(11/31 update: I added overlap ${sigma} as an argument.)\n\nAlso, your fix_abp2d.cpp needed to be changed since all particles moved to the right at first (check the before-correction folder). There are some changes I made; search for // correction!. Also, it wasn’t renormalised like 3D, so I renormalised when doing integration.\nWhat’s the reason you assigned lj/cut as 3.0? Is it to do with coordination shells? And what is v_tscaled in thermo data? Also, since thermo data produces such a huge file, I excluded saving time and pressure. Do we need these at some point?\nTo calculate the asymmetry order parameter, how should I allow the system to relax to collect statistics? For dumps/test/wet.ew.20.ly.120.gz, it seems to roughly relax after 4 million time steps to induce the asymmetric steady state. (The time taken to relax is a lot shorter in higher potential to induce a symmetric steady state.)\nAs noted in the paper, for values less than ew=30, the system quickly becomes unstable. How can I make my code stable?\n\nFor (1), it is now (24/12/02) a lot faster with reduced information being saved:\nLoop time of 1,275.74 on 16 procs for 2,500,001 steps with 14,400 atoms\nPerformance: 846,568.754 tau/day, 1,959.650 timesteps/s, 28.219 Matom-step/s\n99.4% CPU use with 16 MPI tasks x no OpenMP threads\nMPI task timing breakdown:\nSection | Min Time | Avg Time | Max Time | %varavg | %total\n—————————————————————\nPair | 37.333 | 68.22 | 89.448 | 209.4 | 5.35\nNeigh | 8.6982 | 12.866 | 15.493 | 63.5 | 1.01\nComm | 54.905 | 77.189 | 110.42 | 201.1 | 6.05\nOutput | 4.0046 | 31.432 | 60.902 | 334.9 | 2.46\nModify | 747.32 | 845.8 | 928.32 | 157.5 | 66.30\nOther | | 240.2 | | | 18.83\nNlocal: 900 ave 1,317 max 491 min\nHistogram: 1 1 0 1 5 5 1 0 1 1\nNghost: 196.812 ave 269 max 69 min\nHistogram: 2 1 0 2 1 0 1 0 3 6\nNeighs: 2,118.69 ave 3,876 max 488 min\nHistogram: 3 2 0 1 0 1 7 0 1 1\nTotal # of neighbors = 33,899\nAve neighs/atom = 2.3540972\nNeighbor list builds = 112,125\nDangerous builds = 0\nTotal wall time: 0:21:16\n\n2024/11/28 Critical Casimir Effect\nFrom our project meeting, Nigel introduced another possible project: the critical Casimir effect in active fluids. The Casimir effect is probably one of the most important effects in physics along with the Aharonov-Bohm effect, the Hall effect, the Meissner effect (which I can’t remember the name exactly, but it describes that magnetic field lines cannot enter a superconductor), the Doppler effect, and, of course, the photoelectric effect.\nThe reason the Casimir effect is so interesting is this: everybody knows that two metal plates will attract to each other if one is positively charged and the other negatively charged. Somehow, plates also attract each other even if they are uncharged! This is the essence of the Casimir effect, named after Hendrik Casimir (see Wikipedia - Casimir effect). It basically arises due to quantum fluctuations, which create a pressure difference: the pressure between the plates is lower than outside, so the two plates are pushed towards each other. However, the force from the Casimir effect is very weak and can be measured only at very short distances.\nCritical Casimir effect is a classical analogue of this quantum phenomenon, occurring in systems near a critical point of a phase transition. At criticality, the correlation length of fluctuations in an order parameter (such as density or magnetisation) diverges, leading to long-range correlations. When a critical fluid is confined between boundaries, such as two walls, the boundaries modify these fluctuations, imposing constraints that result in an effective force between the walls. This force is mediated by the critical fluctuations and depends on factors like the boundary conditions (e.g., symmetry breaking or preservation) and the distance between the boundaries.\nHow does this effect relate to active fluids? I found this paper: Casimir effect in active matter systems by Ray, Reichhardt, and Reichhardt (2014)\n\nRay, D, C Reichhardt, and CJ Olson Reichhardt. 2014. “Casimir Effect in Active Matter Systems.” Physical Review E 90 (1): 013019.\nOh my god, this is actually very interesting!",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#im-using-mpirun--np-16-mylammpssrclmp_mpi--in-drying-2d.lmp-but-its-still-slow-and-32-is-often-not-available.-did-it-also-take-this-long-1",
    "href": "notes.html#im-using-mpirun--np-16-mylammpssrclmp_mpi--in-drying-2d.lmp-but-its-still-slow-and-32-is-often-not-available.-did-it-also-take-this-long-1",
    "title": "Weekly Notes",
    "section": "1. i’m using mpirun -np 16 ~/mylammps/src/lmp_mpi -in drying-2d.lmp, but it’s still slow, and 32 is often not available. did it also take this long?",
    "text": "1. i’m using mpirun -np 16 ~/mylammps/src/lmp_mpi -in drying-2d.lmp, but it’s still slow, and 32 is often not available. did it also take this long?\nloop time of 1437.69 on 16 procs for 2,500,001 steps with 7,200 atoms\nperformance: 751,203.143 tau/day, 1,738.896 timesteps/s, 12.520 matom-step/s\n98.6% cpu use with 16 mpi tasks x no openmp threads\nmpi task timing breakdown:\nsection | min time | avg time | max time | %varavg | %total\n—————————————————————\npair | 6.237 | 31.572 | 88.773 | 591.0 | 2.20\nneigh | 1.8579 | 5.9445 | 14.931 | 214.1 | 0.41\ncomm | 28.584 | 70.366 | 125.07 | 444.4 | 4.89\noutput | 14.731 | 116.78 | 270.86 | 803.0 | 8.12\nmodify | 185.53 | 424.09 | 970.39 | 1,533.8 | 29.50\nother | | 788.9 | | | 54.88\nnlocal: 450 ave 1,086 max 147 min\nhistogram: 8 2 0 1 0 1 0 0 1 3\nnghost: 85.5 ave 201 max 26 min\nhistogram: 8 0 2 0 1 1 0 0 2 2\nneighs: 1,040.62 ave 3,214 max 81 min\nhistogram: 9 1 0 1 0 1 0 0 1 3\ntotal # of neighbors = 16,650\nave neighs/atom = 2.3125\nneighbor list builds = 106,669\ndangerous builds = 0\ntotal wall time: 0:23:57\n—————————————————————\n\nin the code of wetting-2d.lmp, i used variable friction equal 50  # translational friction coefficient, as i saw in equilibrate.lmp, but is there a specific reason for this value?\ni changed from min_style fire to min_style cg as the system is immediately unstable:\n—\nsetting up fire-style minimization …\nunit style : lj\ncurrent step : 0\nparameters for fire:\ndmax delaystep dtgrow dtshrink alpha0 alphashrink tmax tmin integrator halfstepback abcfire\n0.1 20 1.1 0.5 0.25 0.99 10 0.02 eulerimplicit yes no\n\nper mpi rank memory allocation (min/avg/max) = 3.857 | 3.858 | 3.858 mbytes\nstep time v_tscaled poteng density press\n0 0 0 1.7111115e+25 0.5 5.1333344e+25\nerror: lost atoms: original 7,200 current 4,594 (../thermo.cpp:494)\nlast command: minimize 1.0e-9 1.0e-9 1,000 1,000\n————————————————————————–\nprterun detected that one or more processes exited with non-zero status,\nthus causing the job to be terminated. the first process to do so was:",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "notes.html#process-name-prterun-bp1-login01-2890156114-exit-code-1-1",
    "href": "notes.html#process-name-prterun-bp1-login01-2890156114-exit-code-1-1",
    "title": "Weekly Notes",
    "section": "process name: [prterun-bp1-login01-2890156@1,14] exit code: 1",
    "text": "process name: [prterun-bp1-login01-2890156@1,14] exit code: 1\ni’m not sure how to make it work with fire.\n(11/31 update: i added overlap ${sigma} as an argument.)\n\nalso, your fix_abp2d.cpp needed to be changed since all particles moved to the right at first (check the before-correction folder). there are some changes i made; search for // correction!. also, it wasn’t renormalised like 3d, so i renormalised when doing integration.\nwhat’s the reason you assigned lj/cut as 3.0? is it to do with coordination shells? and what is v_tscaled in thermo data? also, since thermo data produces such a huge file, i excluded saving time and pressure. do we need these at some point?\nto calculate the asymmetry order parameter, how should i allow the system to relax to collect statistics? for dumps/test/wet.ew.20.ly.120.gz, it seems to roughly relax after 4 million time steps to induce the asymmetric steady state. (the time taken to relax is a lot shorter in higher potential to induce a symmetric steady state.)\nas noted in the paper, for values less than ew=30, the system quickly becomes unstable. how can i make my code stable?\n\nfor (1), it is now (24/12/02) a lot faster with reduced information being saved:\nloop time of 1,275.74 on 16 procs for 2,500,001 steps with 14,400 atoms\nperformance: 846,568.754 tau/day, 1,959.650 timesteps/s, 28.219 matom-step/s\n99.4% cpu use with 16 mpi tasks x no openmp threads\nmpi task timing breakdown:\nsection | min time | avg time | max time | %varavg | %total\n—————————————————————\npair | 37.333 | 68.22 | 89.448 | 209.4 | 5.35\nneigh | 8.6982 | 12.866 | 15.493 | 63.5 | 1.01\ncomm | 54.905 | 77.189 | 110.42 | 201.1 | 6.05\noutput | 4.0046 | 31.432 | 60.902 | 334.9 | 2.46\nmodify | 747.32 | 845.8 | 928.32 | 157.5 | 66.30\nother | | 240.2 | | | 18.83\nnlocal: 900 ave 1,317 max 491 min\nhistogram: 1 1 0 1 5 5 1 0 1 1\nnghost: 196.812 ave 269 max 69 min\nhistogram: 2 1 0 2 1 0 1 0 3 6\nneighs: 2,118.69 ave 3,876 max 488 min\nhistogram: 3 2 0 1 0 1 7 0 1 1\ntotal # of neighbors = 33,899\nave neighs/atom = 2.3540972\nneighbor list builds = 112,125\ndangerous builds = 0\ntotal wall time: 0:21:16\n\nThis ensures all capitalization is eliminated in headings and inline text. Let me know if you need further adjustments.",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "meeting.html",
    "href": "meeting.html",
    "title": "Project Meetings",
    "section": "",
    "text": "Meeting with Max on Friday at noon (4th of Oct), thinking of going to Budapest Café\n‘Setting Expectations’ document\nTwo conferences to join:\n• The Dao of Complexity workshop\n• The Statistical Physics of Cognition\nSo, a trip to London, how to sort out things with Clarity, and other arrangements.\nSet up RDSF data storage (Though I checked, OneDrive for Business offers 2TB of storage: Overview of OneDrive for Business)\nBrief plan discussion: reading Mary Coe’s thesis, then Understanding Molecular Simulation book\nAre there MSci students working on this project?",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-3",
    "href": "meeting.html#week-3",
    "title": "Project Meetings",
    "section": "",
    "text": "Meeting with Max on Friday at noon (4th of Oct), thinking of going to Budapest Café\n‘Setting Expectations’ document\nTwo conferences to join:\n• The Dao of Complexity workshop\n• The Statistical Physics of Cognition\nSo, a trip to London, how to sort out things with Clarity, and other arrangements.\nSet up RDSF data storage (Though I checked, OneDrive for Business offers 2TB of storage: Overview of OneDrive for Business)\nBrief plan discussion: reading Mary Coe’s thesis, then Understanding Molecular Simulation book\nAre there MSci students working on this project?",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-4",
    "href": "meeting.html#week-4",
    "title": "Project Meetings",
    "section": "Week 4",
    "text": "Week 4\n\n2024/10/7 Things to discuss\n\nOverleaf template for the thesis, as I will start writing what I learn for either the introduction or theory sections. Found one: Link",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-5",
    "href": "meeting.html#week-5",
    "title": "Project Meetings",
    "section": "Week 5",
    "text": "Week 5\n\n2024/10/12 Making a presentation\n241016 Overleaf Presentation for Project Meeting",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#section",
    "href": "meeting.html#section",
    "title": "Project Meetings",
    "section": "",
    "text": "Meeting with Max on Friday at noon (4th of Oct), thinking of going to Budapest Café\n‘Setting Expectations’ document\nTwo conferences to join:\n• The Dao of Complexity workshop\n• The Statistical Physics of Cognition\nSo, a trip to London, how to sort out things with Clarity, and other arrangements.\nSet up RDSF data storage (Though I checked, OneDrive for Business offers 2TB of storage: Overview of OneDrive for Business)\nBrief plan discussion: reading Mary Coe’s thesis, then Understanding Molecular Simulation book\nAre there MSci students working on this project?",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#section-1",
    "href": "meeting.html#section-1",
    "title": "Project Meetings",
    "section": "2024/10/7",
    "text": "2024/10/7\n\nOverleaf template for the thesis, as I will start writing what I learn for either the introduction or theory sections. Found one: Link",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#making-a-presentation",
    "href": "meeting.html#making-a-presentation",
    "title": "Project Meetings",
    "section": "2024/10/12 Making a presentation",
    "text": "2024/10/12 Making a presentation\n241016 Overleaf Presentation for Project Meeting",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#things-to-discuss",
    "href": "meeting.html#things-to-discuss",
    "title": "Project Meetings",
    "section": "",
    "text": "Meeting with Max on Friday at noon (4th of Oct), thinking of going to Budapest Café\n‘Setting Expectations’ document\nTwo conferences to join:\n• The Dao of Complexity workshop\n• The Statistical Physics of Cognition\nSo, a trip to London, how to sort out things with Clarity, and other arrangements.\nSet up RDSF data storage (Though I checked, OneDrive for Business offers 2TB of storage: Overview of OneDrive for Business)\nBrief plan discussion: reading Mary Coe’s thesis, then Understanding Molecular Simulation book\nAre there MSci students working on this project?",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#things-to-discuss-1",
    "href": "meeting.html#things-to-discuss-1",
    "title": "Project Meetings",
    "section": "2024/10/7 Things to discuss",
    "text": "2024/10/7 Things to discuss\n\nOverleaf template for the thesis, as I will start writing what I learn for either the introduction or theory sections. Found one: Link",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#things-to-discuss-2",
    "href": "meeting.html#things-to-discuss-2",
    "title": "Project Meetings",
    "section": "2024/10/28 Things to discuss",
    "text": "2024/10/28 Things to discuss\n\nAsk about page 51 on Molecular Dynamics Simulation showing notes written on Zotero.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-7",
    "href": "meeting.html#week-7",
    "title": "Project Meetings",
    "section": "Week 7",
    "text": "Week 7\n\n2024/10/28 Things to discuss\n\nAsk about page 51 on Molecular Dynamics Simulation showing notes written on Zotero.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-10",
    "href": "meeting.html#week-10",
    "title": "Project Meetings",
    "section": "Week 10",
    "text": "Week 10\n\n2024/11/18 Things to discuss\n\nI can mention that I’m not particularly interested in surface phase transitions unless there is a link to my vape (see 2024/11/14 - Skimming through papers).\nI can also discuss the way I work, such as deriving mathematical equations and explaining how much beauty I perceive in those equations (see 2024/11/17 The Moment of My Realisation).\nAt the moment, I’m still exploring which project I would like to pursue for the next four years. When I was doing my MSci research, I felt so restless and excited, deeply engaged with all the required literature, like a sponge absorbing everything! Now, I don’t feel the same enthusiasm for my specific project. That said, I’m reading Active Particles in Complex and Crowded Environments (Bechinger et al. (2016)) because it appears to be a good review of this field, readable and offering insights into future directions.\n\n\nBechinger, Clemens, Roberto Di Leonardo, Hartmut Löwen, Charles Reichhardt, Giorgio Volpe, and Giovanni Volpe. 2016. “Active Particles in Complex and Crowded Environments.” Reviews of Modern Physics 88 (4): 045006.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-11",
    "href": "meeting.html#week-11",
    "title": "Project Meetings",
    "section": "Week 11",
    "text": "Week 11\n\n2024/11/28 Critical Casimir Effect\nFrom our project meeting, Nigel introduced another possible project: the critical Casimir effect in active fluids. The Casimir effect is probably one of the most important effects in physics along with the Aharonov-Bohm effect, the Hall effect, the Meissner effect (which I can’t remember the name exactly, but it describes that magnetic field lines cannot enter a superconductor), the Doppler effect, and, of course, the photoelectric effect.\nThe reason the Casimir effect is so interesting is this: everybody knows that two metal plates will attract to each other if one is positively charged and the other negatively charged. Somehow, plates also attract each other even if they are uncharged! This is the essence of the Casimir effect, named after Hendrik Casimir (see Wikipedia - Casimir effect). It basically arises due to quantum fluctuations, which create a pressure difference: the pressure between the plates is lower than outside, so the two plates are pushed towards each other. However, the force from the Casimir effect is very weak and can be measured only at very short distances.\nCritical Casimir effect is a classical analogue of this quantum phenomenon, occurring in systems near a critical point of a phase transition. At criticality, the correlation length of fluctuations in an order parameter (such as density or magnetisation) diverges, leading to long-range correlations. When a critical fluid is confined between boundaries, such as two walls, the boundaries modify these fluctuations, imposing constraints that result in an effective force between the walls. This force is mediated by the critical fluctuations and depends on factors like the boundary conditions (e.g., symmetry breaking or preservation) and the distance between the boundaries.\nHow does this effect relate to active fluids? I found this paper: Casimir effect in active matter systems by Ray, Reichhardt, and Reichhardt (2014)\n\nRay, D, C Reichhardt, and CJ Olson Reichhardt. 2014. “Casimir Effect in Active Matter Systems.” Physical Review E 90 (1): 013019.\nOh my god, this is actually very interesting!",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#process-name-prterun-bp1-login01-2890156114-exit-code-1",
    "href": "meeting.html#process-name-prterun-bp1-login01-2890156114-exit-code-1",
    "title": "Project Meetings",
    "section": "Process name: [prterun-bp1-login01-2890156@1,14] Exit code: 1",
    "text": "Process name: [prterun-bp1-login01-2890156@1,14] Exit code: 1\n\nI’m not sure how to make it work with FIRE.  \n(11/31 update: I added `overlap ${sigma}` as an argument.)  \n\n4. Also, your `fix_abp2d.cpp` needed to be changed since all particles moved to the right at first (check the `before-correction` folder). There are some changes I made; search for `// correction!`. Also, it wasn’t renormalised like 3D, so I renormalised when doing integration.  \n\n5. What’s the reason you assigned `lj/cut` as 3.0? Is it to do with coordination shells? And what is `v_tscaled` in thermo data? Also, since thermo data produces such a huge file, I excluded saving `time` and `pressure`. Do we need these at some point?  \n\n6. To calculate the asymmetry order parameter, how should I allow the system to relax to collect statistics? For `dumps/test/wet.ew.20.ly.120.gz`, it seems to roughly relax after 4 million time steps to induce the asymmetric steady state. (The time taken to relax is a lot shorter in higher potential to induce a symmetric steady state.)  \n\n7. As noted in the paper, for values less than `ew=30`, the system quickly becomes unstable. How can I make my code stable?  \n\nFor (1), it is now (24/12/02) a lot faster with reduced information being saved:  \nLoop time of 1,275.74 on 16 procs for 2,500,001 steps with 14,400 atoms\nPerformance: 846,568.754 tau/day, 1,959.650 timesteps/s, 28.219 Matom-step/s\n99.4% CPU use with 16 MPI tasks x no OpenMP threads\nMPI task timing breakdown:\nSection | Min Time | Avg Time | Max Time | %varavg | %total\n—————————————————————\nPair | 37.333 | 68.22 | 89.448 | 209.4 | 5.35\nNeigh | 8.6982 | 12.866 | 15.493 | 63.5 | 1.01\nComm | 54.905 | 77.189 | 110.42 | 201.1 | 6.05\nOutput | 4.0046 | 31.432 | 60.902 | 334.9 | 2.46\nModify | 747.32 | 845.8 | 928.32 | 157.5 | 66.30\nOther | | 240.2 | | | 18.83\nNlocal: 900 ave 1,317 max 491 min\nHistogram: 1 1 0 1 5 5 1 0 1 1\nNghost: 196.812 ave 269 max 69 min\nHistogram: 2 1 0 2 1 0 1 0 3 6\nNeighs: 2,118.69 ave 3,876 max 488 min\nHistogram: 3 2 0 1 0 1 7 0 1 1\nTotal # of neighbors = 33,899\nAve neighs/atom = 2.3540972\nNeighbor list builds = 112,125\nDangerous builds = 0\nTotal wall time: 0:21:16\n```",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-12",
    "href": "meeting.html#week-12",
    "title": "Project Meetings",
    "section": "Week 12",
    "text": "Week 12\n\n2024/11/28 Questions\n(Postponed to Week 12 Project Meeting)\n\nI’m using mpirun -np 16 ~/mylammps/src/lmp_mpi -in drying-2D.lmp, but it’s still slow, and 32 is often not available. Did it also take this long?\n\n\n---------------------------------------------------------------  \nLoop time of 1437.69 on 16 procs for 2,500,001 steps with 7,200 atoms  \n\nPerformance: 751,203.143 tau/day, 1,738.896 timesteps/s, 12.520 Matom-step/s  \n98.6% CPU use with 16 MPI tasks x no OpenMP threads  \n\nMPI task timing breakdown:  \nSection | Min Time  | Avg Time  | Max Time  | %varavg | %total  \n---------------------------------------------------------------  \nPair    | 6.237      | 31.572     | 88.773     | 591.0   |  2.20  \nNeigh   | 1.8579     | 5.9445     | 14.931     | 214.1   |  0.41  \nComm    | 28.584     | 70.366     | 125.07     | 444.4   |  4.89  \nOutput  | 14.731     | 116.78     | 270.86     | 803.0   |  8.12  \nModify  | 185.53     | 424.09     | 970.39     | 1,533.8 | 29.50  \nOther   |            | 788.9      |            |         | 54.88  \n\nNlocal:            450 ave        1,086 max         147 min  \nHistogram: 8 2 0 1 0 1 0 0 1 3  \nNghost:           85.5 ave         201 max          26 min  \nHistogram: 8 0 2 0 1 1 0 0 2 2  \nNeighs:        1,040.62 ave      3,214 max          81 min  \nHistogram: 9 1 0 1 0 1 0 0 1 3  \n\nTotal # of neighbors = 16,650  \nAve neighs/atom = 2.3125  \nNeighbor list builds = 106,669  \nDangerous builds = 0  \nTotal wall time: 0:23:57  \n---------------------------------------------------------------  \n\nIn the code of wetting-2D.lmp, I used variable friction equal 50  # translational friction coefficient, as I saw in equilibrate.lmp, but is there a specific reason for this value?\nI changed from min_style fire to min_style cg as the system is immediately unstable:\n\n\n—  \nSetting up FIRE-style minimization ...  \n  Unit style    : lj  \n  Current step  : 0  \n  Parameters for FIRE:  \n    dmax  delaystep dtgrow dtshrink alpha0 alphashrink tmax tmin   integrator   halfstepback   abcfire  \n     0.1     20      1.1     0.5     0.25     0.99      10  0.02 eulerimplicit      yes          no  \n\nPer MPI rank memory allocation (min/avg/max) = 3.857 | 3.858 | 3.858 Mbytes  \n\n   Step          Time        v_tscaled        PotEng        Density         Press     \n         0   0              0              1.7111115e+25  0.5            5.1333344e+25  \nERROR: Lost atoms: original 7,200 current 4,594 (../thermo.cpp:494)  \nLast command: minimize 1.0e-9 1.0e-9 1,000 1,000  \n--------------------------------------------------------------------------  \n\n`prterun` detected that one or more processes exited with non-zero status,  \nthus causing the job to be terminated. The first process to do so was:  \n\n   Process name: [prterun-bp1-login01-2890156@1,14] Exit code:    1  \n--------------------------------------------------------------------------  \nI’m not sure how to make it work with FIRE.\n(11/31 update: I added overlap ${sigma} as an argument.)\n\nAlso, your fix_abp2d.cpp needed to be changed since all particles moved to the right at first (check the before-correction folder). There are some changes I made; search for // correction!. Also, it wasn’t renormalised like 3D, so I renormalised when doing integration.\nWhat’s the reason you assigned lj/cut as 3.0? Is it to do with coordination shells? And what is v_tscaled in thermo data? Also, since thermo data produces such a huge file, I excluded saving time and pressure. Do we need these at some point?\nTo calculate the asymmetry order parameter, how should I allow the system to relax to collect statistics? For dumps/test/wet.ew.20.ly.120.gz, it seems to roughly relax after 4 million time steps to induce the asymmetric steady state. (The time taken to relax is a lot shorter in higher potential to induce a symmetric steady state.)\nAs noted in the paper, for values less than ew=30, the system quickly becomes unstable. How can I make my code stable?\n\nFor (1), it is now (24/12/02) a lot faster with reduced information being saved:\n---------------------------------------------------------------  \nLoop time of 1,275.74 on 16 procs for 2,500,001 steps with 14,400 atoms  \n\nPerformance: 846,568.754 tau/day, 1,959.650 timesteps/s, 28.219 Matom-step/s  \n99.4% CPU use with 16 MPI tasks x no OpenMP threads  \n\nMPI task timing breakdown:  \nSection | Min Time  | Avg Time  | Max Time  | %varavg | %total  \n---------------------------------------------------------------  \nPair    | 37.333     | 68.22      | 89.448     | 209.4   |  5.35  \nNeigh   | 8.6982     | 12.866     | 15.493     |  63.5   |  1.01  \nComm    | 54.905     | 77.189     | 110.42     | 201.1   |  6.05  \nOutput  | 4.0046     | 31.432     | 60.902     | 334.9   |  2.46  \nModify  | 747.32     | 845.8      | 928.32     | 157.5   | 66.30  \nOther   |            | 240.2      |            |         | 18.83  \n\nNlocal:            900 ave        1,317 max         491 min  \nHistogram: 1 1 0 1 5 5 1 0 1 1  \nNghost:        196.812 ave        269 max          69 min  \nHistogram: 2 1 0 2 1 0 1 0 3 6  \nNeighs:        2,118.69 ave      3,876 max         488 min  \nHistogram: 3 2 0 1 0 1 7 0 1 1  \n\nTotal # of neighbors = 33,899  \nAve neighs/atom = 2.3540972  \nNeighbor list builds = 112,125  \nDangerous builds = 0  \nTotal wall time: 0:21:16  \n---------------------------------------------------------------  \n\n\n2024/12/3 After project meeting\n\nFor friction = 50, it boils down to how far a single particle moves in a single step of the self-propulsion force. For example, if it moves too far, it may not resolve the collision in a very dense system because the particle cannot observe the true collisions. Otherwise, it jumps across, which is not physical.\nHe mentioned this paper (which is cited by the SM paper) but couldn’t find anything about that specific choice of friction: https://iopscience.iop.org/article/10.1088/1367-2630/aa9d4b/pdf.\nHe said I don’t need minimisation anymore since particles are spaced without overlapping using overlap ${sigma}.\nFor pair_style lj/cut 3.0, LAMMPS checks how large the cutoff is for calculating the neighbour list. Then we use a smaller cutoff where the potential is truncated (or shifted) by the next commands. Setting it to just \\({r_c}\\) instead of 3.0 could be risky for ensuring correct calculations of neighbours. The number can be checked by seeing if the dynamics do not depend on the cutoff (e.g., obtaining the same trajectory, energies, etc.). 3.0 was an overcautious choice, but it’s good to be cautious. For example, neigh_modify every 1 delay 0 check yes ensures the neighbour list is checked every step. This is important because if a particle travels a long way, it could suddenly move into the dilute phase, especially if it’s likely an interfacial particle. Therefore, we need to keep the timestep small and make an extra neighbour list so that the results don’t depend on specific choices.\nRegarding tscaled, he said LJ units do not matter as much as in the case of equilibrium. So we are using this different, interesting timescale.\nNobody has a perfect answer for when the steady state happens. If some statistical features converge (or appear asymptotic), we might see that the system has passed the relaxation time. The good thing is that even if the initial conditions are different (e.g., by assigning a different seed that produces slightly different time evolution), the characteristic relaxation time remains fixed. Without special methods, it’s very difficult to know where the actual transition point is. However, the entire point is that there can be memory effects, where something does not change for some time. Away from the transition itself, I can have a reasonable estimate of the relaxation time.\nHe also said that to estimate whether the system is in the steady state or not, we can look at the energy because the energy is related to the number of neighbours particles have. He didn’t specifically have a systematic way of determining \\(\\tau_c\\) for all different trajectories. For example, he doesn’t have \\(\\tau_c\\) vs \\(\\epsilon\\), which he said is something I can investigate. He estimated \\(\\tau_c\\), then took a larger order of magnitude (like 10 times that value) to be safe. Beyond that, he collected the statistics.\nWhen they said the system becomes unstable in their paper, they meant the droplet detaches from the barrier, not the simulation. He said a ‘lost atoms’ error can’t really happen with small \\(\\epsilon\\) unless it’s a very large \\(\\epsilon\\). He said I should reduce \\(dt\\).",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-13",
    "href": "meeting.html#week-13",
    "title": "Project Meetings",
    "section": "Week 13",
    "text": "Week 13\n\n2024/12/9 Things to discuss\n\nMolsim is not successful. Are there any active matter schools? (Should I ask them if I could be on the waiting list?)\n\nOther schools:\n- CCP5 Summer School\n- June 8 - June 13, 2025: Interfacial Soft Matter: Mechanics, Physical Chemistry and Interactions\n- June 16 – 20, 2025: Han-sur-Lesse Winterschool (in summer) on ‘Soft matter and biological physics’\n- June 23 - July 4, 2025: 2025 IHES Summer School - Statistical Aspects of Nonlinear Physics\n\nAre both of you leaving in the winter? It seems everyone is leaving for holidays after around the 20th.\n\nLast meeting this year: 16th Dec\nFirst meeting next year: 6th Jan",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-6",
    "href": "meeting.html#week-6",
    "title": "Project Meetings",
    "section": "Week 6",
    "text": "Week 6\n\n2024/10/23 Molsim-2025 School Application\nMolSim-2025 is 2-week school that offers a program focusing on basic and advanced molecular simulation methods. It targets PhD candidates and postdoctoral researchers who want to understand and apply these methods to study topics in physics, chemistry or biology. The program has an integrated and balanced structure of lectures and hands-on exercises. It offers a recap of the basic theory relevant for molecular simulation, followed by a thorough covering of basic and advanced simulation techniques. All techniques will be accompanied by illustrative examples of present day research.\n\nMy application (submitted on 241023)\nI am a PhD student in theoretical and computational physics at the University of Bristol, specialising in the simulation of surface phase transitions with a focus on active matter using high-performance computing. My supervisors are Nigel Wilding, who has strongly recommended this winter school and has done substantial work on developing efficient algorithms for MC simulations [1-4], and Francesco Turci, who specialises in disordered systems. My initial project involves investigating drying (surface) phase transitions using Monte Carlo and molecular dynamics techniques, introducing an additional parameter to how they approached the problem in PRL 2021 [5].\nI am highly motivated to join this winter school since it is my first year of PhD studies and also my first time learning how to conduct molecular simulations. I am currently reading the book Understanding Molecular Simulation to grasp the methodologies, and I was very excited by the fact that the authors of this book will be present for the lectures. Even though this book is enjoyable to read, many concepts within it are quite new to me, so it will be a great opportunity to deepen my knowledge in this area and meet colleagues with similar interests. The latter reason is also very important since I am the only PhD student learning models of active particles for surface phase transitions in my department.\nPlease let me know if you would like me to send my CV. For now, I have attached my personal statement, which I submitted for my PhD application, showing my dynamic and multifaceted experience. I hope this wonderful opportunity will materialise.\n\n[1] N.B. Wilding, A.D. Bruce, Density fluctuations and field mixing in the critical fluid, J. Phys. Condens. Matter 4 (12) (1992) 3087–3108\n[2] N.B. Wilding, Critical point and coexistence curve properties of the Lennard-Jones fluid: a finite-size scaling study, Phys. Rev. E 52 (1) (1995) 602–611\n[3] A.D. Bruce, N.B. Wilding, G.J. Ackland, Free energy of crystalline solids: a lattice-switch Monte Carlo method, Phys. Rev. Lett. 79 (16) (1997) 3002–3005\n[4] S. Consta, N.B. Wilding, D. Frenkel, Z. Alexandrowicz, Recoil growth: an efficient simulation method for multi-polymer systems, J. Chem. Phys. 110 (6) (1999) 3220–3228\n[5] F. Turci, N.B. Wilding, Phase separation and multibody effects in three-dimensional active Brownian particles, Phys. Rev. Lett. 126.3 (2021) 038002.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meeting.html#week-8",
    "href": "meeting.html#week-8",
    "title": "Project Meetings",
    "section": "Week 8",
    "text": "Week 8\n\n2024/11/4 Things to discuss\nThe meaning of our project\nI’m afraid to say I’m not exactly certain about the importance of our initial project. To me, a naive student who has just finished my undergraduate in physics, physics operates by explaining experimental results in mathematical language. As a few examples,\n\nIn the early 20th century, we realised that classical physics could not explain the ultraviolet catastrophe. So Planck suggested that light exists in quanta to explain the spectra we observe, which later led to Bohr’s theory of electron orbits. Furthermore, when classical electrodynamics dictated that an orbiting electron around the nucleus should radiate energy and spiral inward, the new language of quantum mechanics was formulated to explain the stability of atoms. This process of experimental results leading to theoretical explanations, which further lead to contradictions with existing theories, gives birth to new frameworks that unite our understanding.\nThe Michelson–Morley experiment investigating the existence of the ether disproved their hypothesis, supporting the constancy of the speed of light, \\(c\\). This result led Einstein to create a theory which completely changed the very meanings of our familiar, intuitive concepts: space and time. Another example of how experimental results led to the unification of our understanding; for example, magnetism can be understood as electricity in special relativity.\nEven in statistical physics, the phase diagram of water has been known for a long time, but the critical point wasn’t understood until the mid to late 20th century. It was not until Ken Wilson formulated the renormalisation group to explain this by rescaling physical theories (which I find one of the most beautiful results in theoretical physics).\n\nI have chosen the active matter project because it’s a framework that makes the most sense to me, due to my keen interest in philosophy throughout the years, which has made me already familiar with the active matter paradigm shift. If I describe briefly,\n\nThe reason that Newtonian mechanics completely altered how scientific disciplines have progressed is because I believe it gave us what it means by our ‘understanding’. Before Newton, Ptolemy’s circles and epicycles could fully explain the orbits of planetary bodies. However, we don’t consider this as ‘understanding’ the underlying mechanism because what Ptolemy did was to focus only on motions. What Newton did, on the other hand, was to identify the ‘cause’ of motion, which is force. By introducing that concept, he was able to derive his simple equation of universal gravity, which applies to many different things, not just planetary bodies, but also projectiles, pendulums, etc. So by his theory, we were able to unite many phenomena that we observe into one unified framework.\nHowever, he still couldn’t explain how these forces arise, so he devised what are called ‘active principles’. I could elaborate further, but I shall stop here. The important thing about this new revelation was that, from the Newtonian way of thinking, we conceived matter as passive and forces as active. We thought of matter as inert, dead, inanimate. No wonder the physicalist view in biology had failed by the end of the 19th century, which led to the ‘century of the gene’ in the 20th century, explaining everything in terms of gene expression. However, thinking only about genes couldn’t explain many things in biology such as: what is the difference between animate and inanimate things? Why are there many phenotypes from the same genotype? So what Thomas Huxley hoped for at the end of the 19th century, the physical language to explain biological matter, has resurfaced at the beginning of the 21st century with the emergence of active matter, where soft matter physicists could contribute. All in all, at Oxford University, there is the phrase: ‘Biology is soft matter come alive’. I would interpret it as ‘active’, though.\n\nThe significance of this new way of thinking is apparent to me. However, what is not clear is how observing a drying transition by active particles contributes to our understanding of drying phenomena. The reason I kept asking about real life examples is because I wasn’t sure if our results (if we observe drying) would explain the experimental results that need to be explained. If there are such cases, this would be recognised as our correct understanding of drying phenomena, which leads us to think that moving out of equilibrium statistical physics is a more reasonable direction. Since we are dealing with such limited, specific systems where liquid and vapour coexist, which is already quite rare in nature, for this project meeting, I hoped to gain more understanding of the significance of our project.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "direction.html#email-sent-to-nigel-and-francesco-1",
    "href": "direction.html#email-sent-to-nigel-and-francesco-1",
    "title": "Redirection of PhD",
    "section": "",
    "text": "Dear Nigel,\nThank you for your email. I’ve been reading about the critical Casimir effect, and it’s so interesting! There was research using the run-and-tumble model by Ray et al. in 2014, and since run-and-tumble and ABPs can be mapped onto each other, I thought this paper was quite relevant, so I uploaded it to Zotero (under the category of Active Casimir Effect). Also, there was a concise review on this theme by Bechinger et al. in 2016. Even recently, there has been work on this topic using flocking active matter by Fava et al. in 2024. It’s so interesting, and I deeply appreciate you coming up with this suggestion! By Monday next week, I’ll read more and finalise my choice, though at this stage, I feel it would be more worthwhile to continue with the active drying project first to apply the concepts I’ve learned over the past two months in simulations. If that’s the decision, I can see myself working on the active Casimir effect right after the initial project.\nYes, I won’t share anything unrelated to the project anymore. If I may offer an excuse, there were two occasions I shared something: one was a dialogue related to active matter on 17th of September, and the other was a note on ‘things to discuss’ for the project meeting when I was concerned about the project two weeks ago. I thought both were related, but I apologise and appreciate your pointing out that they were not the right forms to share. I won’t do it again.\nI have honestly felt quite isolated at times this semester as the only PhD student in theoretical physics investigating active matter. So, it was such an enjoyable opportunity for me to have a conversation with you and Francesco, even in broader contexts beyond our project. However, I’ll make sure to confine my conversations strictly to the current project.\nYour comments have been helpful, and I’ll be more realistic from now on. I have also closed the website, as I probably enjoyed designing it a bit too much. While it was intended to document everything I do during my PhD in a self-contained way, it may not have conveyed how much time I dedicate to our project.\nThank you,\nSohyun",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Redirection of PhD"
    ]
  },
  {
    "objectID": "diary.html",
    "href": "diary.html",
    "title": "Diary",
    "section": "",
    "text": "This page contains diary entries that are largely unrelated to my PhD project.\n\n\n2024/9/27 Things I did so far\nBusy weeks due to starting three teaching modules: Weekly update of my TSR (Teaching Support Roles). Looking back, I wish I could have completed more reading, as there isn’t much to talk about in terms of active matter research for the next project meeting on Monday.\n\n\n2024/11/2 - 11/8 Physics and Beyond (Heisenberg et al. 1971)\n\nHeisenberg, Werner et al. 1971. Physics and Beyond. Allen & Unwin London.\nCited by 1832\nIt’s the first time I’m reading this in English; the title of the book in Korean is 부분과 전체, which might translate to Parts and the Whole. I’ve read it many times since I was in high school, and it has been highly influential to me as a physicist throughout my life. To capture some of the things I want to revisit later:\n\n\n\nOn page 72, Fresh Fields (1926-1927)\n\n\n\n\n\nOn page 80, Fresh Fields (1926-1927)\n\n\nSo far, having read up to page 89, it has all been interesting, except for Chapter 4 (Lessons in Politics and History). When the development of quantum mechanics was presented in Chapters 5 and 6, I felt my heart pounding as I read through, just as it did when I first read this book.\n\n\n\n\nOn page 97, Atomic Physics and Pragmatism (1929)\n\n\nAll these realms were so enjoyable to learn, but now, as a researcher, I wonder what realms are still open. I thought one of them was non-equilibrium statistical thermodynamics, but it appears to me that this theory can’t be axiomatic, implying that all systems out of equilibrium must be described differently.\n\n\n\n\nOn page 109, The Relationship between Biology, Physics and Chemistry (1930-1932)\n\n\n‘Forms through which matter streams,’ as Niels Bohr described, was the most profound characterisation of organisms I have encountered. I used to wonder, what about this structure remains? Does it actually persist, given that a person changes continuously as a child becomes an adult? Is it simply the name (person) we assign that represents this form of life? With this thought, is there really a distinction between animate and inanimate objects?\nWhen I read Timaeus by Plato in high school, he described geometrical forms as the basis of earth, fire, water, and air, even though I found his idea peculiar (like everything is made of right triangles). At the time, I thought the properties that define those mathematical forms were responsible for things maintaining their structure in the way we perceive over time (since all forms change shape as time passes). My master’s research was also focused on investigating this homeostasis in an ideal structure, not physical but something we perceive, in the context of foreign exchange markets. This line of thought was also captured well by Bohr’s question: “Can quantum mechanics explain nature’s tendency to form structures through which matter with fixed chemical properties can stream for a limited time?”\n\n\n\n\nOn page 128, Discussions about Language (1933)\n\n\nThis passage about the discovery of antimatter was one of the reasons I chose a physics degree, along with my ambition to formally study general relativity. Although I didn’t score well in my particle physics exam in third year due to a part-time job over winter break, it remains one of the most exciting units I’ve taken. Here are the scores and ratings I gave to my third and fourth-year units with scores of at least 4:\n5: Physics Research Project (83), Quantum Physics (88)\n4.5: Physics of Phase Transitions (85), Analytical Mechanics (66), Particle Physics (58)\n4: Quantum Information Theory (68), Foundations of Modern Physics (68), Methods of Theoretical Physics (63)\nIt’s surprising that general relativity only scored 3.5, but it seems I didn’t enjoy the lecture style despite being fascinated by the content.\n\n\n\n\nOn page 134, Discussions about Language (1933)\n\n\nThis passage captures the reason I didn’t pursue a philosophy degree, despite having written about philosophy of science. What I realised was the fluidity of language, and at some point, reading philosophy felt like participating in a language game. Even when I wrote The Self and the World, I included definitions for the terms I used in the document. In contrast, I conceived mathematical objects as eternal, grounded solidly in axioms. I couldn’t imagine any language other than this to describe the hidden secrets of the universe as eternal representations, unchanging, unmoved, and concrete.\n\n\n\n\nOn page 136, Discussions about Language (1933)\n\n\nAnother book I feel closely connected to is the Tao Te Ching by Lao Tzu. It’s probably not an exaggeration to say that my whole life has been devoted to understanding the meaning of Tao, even though Lao Tzu paradoxically said, “The Tao that can be described is not the eternal Tao.” One day, I realised it is synonymous with the Truth or, in more Platonic terms, the formless. Ineffable. That’s when I wrote this diary: Is “It” a Joke?\n\n\n\n\nOn page 191, Toward a New Beginning (1941-1945)\n\n\nThese chapters were not enjoyable to read: Revolution and University Life (1933), Individual Behavior in the Face of Political Disaster (1937-1941), Toward a New Beginning (1941-1945). I’m certainly not interested in politics or wars. However, the ending of this third chapter is beautifully written; beauty transcends ideology, opinions, and dualistic views of the world.\n\n\n\n\nOn page 195, The Responsibility of the Scientist (1945-1950)\n\n\nThis reveals the reason why I chose the theme of active matter. I was curious about how this model suddenly emerged in the last 25 years. Why is there such a sudden interest in this concept? What possibilities does it offer for understanding nature? What contributions can I make to the circle of human knowledge?\n\nWhile reading through the Scientific and Political Disputes (1956-1957) chapter, I realised I can only concentrate when scientific matters are being discussed, such as the conversations between Heisenberg and Wolfgang about the mathematical theory for elementary particles.\n\n\n\nOn page 230, The Unified Field Theory (1957-1958)\n\n\nHowever, everything that followed from the passage in the image was fascinating, especially when they started discussing symmetries (for example, the universe as a whole does not necessarily have to be symmetrical with respect to the operations under which natural laws remain invariant), relativistic quantum field theories, and more, which captivated me when I studied particle physics in my third year.\n\n\n\n\nOn page 240, Elementary Particles and Platonic Philosophy (1961-1965)\n\n\nI have finally finished the book. Although the above image is not the last page, I love this book because it begins with Plato and ends with him. Timaeus was the book that shaped my worldview when I was in high school, and when I first encountered Physics and Beyond, I was thrilled to find someone in history who asked the same questions I had while reading Timaeus. Since then, my understanding has deepened, and I’ve come to see that all philosophy traces back to Plato. Last year, a decade later, I finally had a direct understanding of what Plato described through some interesting experiences.\nEven beyond that passage in the screenshot, it’s truly worth rereading. People at that time were already considering how natural laws conform to different scales, touching on the concept of emergence, which is the field I’m now working in.\nWhile reading this book, I rewatched the documentary series Atom, hosted by Jim Al-Khalili. I remember watching it for the first time in high school, loving it immensely, and being struck by statements from scholars like Paul Dirac, who said, “A physical law must possess mathematical beauty.” I was curious about what QED implied once I start learning about it at university, such as how all the matter we see is just reflections of virtual particles. That was a long time ago, and that naïveté and curiosity are what led me to study physics. I’d like to close with what Jim Al-Khalili said (even though I largely disagree with his interpretation of quantum mechanics in that chapter) at the end of The Illusion of Reality (the third episode):\nIn the last 100 years, we have peered deep inside the atom, the basic building block of the universe. And inside this tiny object, we have found a strange new world governed by exotic laws that at times seem to defy reason. Atoms present us with dizzying contradictions. They can behave both as particles or waves. They appear to be in more than one place at the same time. They force us to rethink what we mean by past and future, by cause and effect. And they tell us strange things about where the universe came from and where it’s going. Pretty amazing stuff for something that’s just a millionth of a millimetre across. That’s why Niels Bohr, the father of atomic physics, once said that, when it comes to atoms, language can only be used as poetry. What’s fascinating to me is that although we’ve learnt an incredible amount about atoms and their behaviour, our scientific journey has only just begun. Because although we know how a single atom or just a few atoms behave, the way trillions of them come together in concert to create the world around us is still largely a mystery. To give you one dramatic example, the atoms that make up my body are identical to the atoms in the rocks, the trees, the air, even the stars. And yet, they come together to create a conscious being who can ask the question, “What is an atom?” Explaining all that is surely the next great challenge in science.\nI realised that the “next great challenge” he mentioned is the same one I’ve been drawn to since studying physics: the emergence of consciousness. The most intriguing question, perhaps prompted by an interesting dream I had last night, is how our mind creates the world and perceives it simultaneously when we dream. When I’m awake, I can do this partially; for instance, when I think about walking down the corridor where my office is located, I can imagine it while experiencing it at the same time. It seems this ability expands to full capacity in dreams. Once I understand that mechanism, I might be able to discern, even when awake, whether I am still dreaming and creating the world while simultaneously perceiving it.\n\n\n2024/11/4 Diary\nI was quite ill last week, taking antibiotics from Monday to Saturday. While having more rest at home than in other weeks, I was thinking about a few things.\n\nAt first, I started thinking about why I began to study physics. It was driven by mysteries and curiosities. At that time, I didn’t know that what I was going to learn were representations of empirical observations; rather, I naively thought it would be the objective truth. As I was learning physics in my undergraduate studies, I realised there are different mathematical formalisms to describe the same physical phenomena, such as Newtonian, Lagrangian, and Hamiltonian mechanics in classical physics, or matrix mechanics by Heisenberg and wave mechanics by Schrödinger in quantum mechanics. Then my approach to physics became more like, ‘Which model makes the most sense to me for understanding the observed?’ or ‘Which models lead to more universal descriptions of all things?’ Then I encountered the concept of universality: many of the microscopic details that go into the theory are irrelevant under successive renormalisation group transformations; the theory that describes the critical point is universal. I thought this idea was stunningly beautiful, and I thought that if I were to start my PhD, I would investigate how these patterns that interlace between different systems or physical theories emerge.\nThen, as I was ill and thinking about many things, I reflected on what has captivated me in my undergraduate studies. The list follows like this:\n\n\nYear 1, The breakdown of the concept, simultaneity: As I was learning special relativity, I realised that the notion I thought was objective was actually subjective. The only way to know what time is is to look at the clock. This idea was profound for me, emphasising that time is not an absolute entity. Einstein’s theory was so elegant in the way that it started with only two assumptions: first, the speed of light is constant based on empirical observations; second, the laws of physics are the same in all inertial frames of reference. The consequences of the theory based on these assumptions were just mind-blowing.\nYear 2, first term, quantum tunnelling: I was always fascinated by the implications of quantum mechanics even before starting my physics degree. Once I was able to explain the phenomenon of the wavefunction trapped in a finite potential well, which allows for the probability of finding a particle on the other side of the barrier, it was really mind-blowing that I clearly understood the mathematics but had no idea how to comprehend it, even though this phenomenon is the foundation of all technologies I use now.\nYear 2, second term, Maxwell’s equations: The universal descriptions that entail all electromagnetic phenomena in such simple mathematical forms using vector calculus. I was struck by the beauty of these equations that I set them as a screensaver since my second year. Also, when I went to Edinburgh and saw a statue of Maxwell with his equations, I couldn’t leave that place for a long time.\nYear 3, second term, the principle of least action: This whole Lagrangian formulation of classical mechanics was the clearest and the deepest representation I had encountered. The path is chosen to extremise the action, which was such a profound perspective that changed all my ways of thinking. I could go on and on about this, but in short, I loved the encounter with this concept so much that I used it as a nickname on several websites.\nYear 4, first term, the whole ideas from general relativity: This subject was of tremendous importance to me. When I decided to study physics, this was the subject I intended to study and also the reason I chose the MSci, as it was a unit for fourth-year students. I would say this is the subject which made me come to university. The idea that if we also include a time axis overlaid onto three spatial axes, an object at rest in a given reference frame moves at the speed of light along the time axis. Then, if an object moves, since the magnitude of speed is bound by the speed of light, the component that lies on the time axis decreases as it increases along the spatial axes. It was such a beautiful way of describing how time and space were interlinked. Also, the calculus of variations, which led to Lagrangian mechanics that I loved, started from considering the straight line in a global perspective. Einstein’s theory started with thinking about the straight line (or rather more precisely, a vector) from a local perspective with parallel transport. The implication of this led to Einstein’s field equations, which imply matter tells spacetime how to curve and spacetime tells matter how to move. These whole ideas related very closely to some of my psychedelic experiences, and I thought it was THE subject I would want to learn much more deeply in the coming years, before I met the language of the physics of phase transitions.\nYear 4, second term, the whole ideas from the physics of phase transitions: the correlation length diverging at criticality, universality classes, and critical exponents telling how to rescale a physical theory. All these ideas were so captivating that it almost felt like meta-foundational physics, like the physics of physical theory. Also, a lot of concepts extended even beyond the realm of physics, such as the critical brain hypothesis in neuroscience. This perspective of considering the structure of physical theory was like the final lesson of my undergraduate studies and the one that I wanted to pursue for the rest of my physics career. At that time, I met Nigel, my supervisor, who told me that in statistical physics, a small number of people make a great contribution to the field, unlike astrophysicists or particle physicists who are in large groups and don’t get to decide the direction. That was the moment I felt that I chose the field of statistical physics, even though I have loved concepts from astrophysics (general relativity) and particle physics (quantum field theory).\n\n\nNow I’m in week 8 of my PhD, but I can’t say that I have been really engaged with my research. The biggest fault is down to me: I haven’t read references thoroughly so that I can appreciate the field in general yet. I’m the person who likes to read one book over and over again (and it seems that the only professor who likes to do this is Sandu Popescu), but I am kind of overwhelmed by how many references were uploaded in Zotero and the time it takes for me to read understanding molecular simulation. And I haven’t found a way to convince my supervisors about my progress since I also have had a lot of teaching responsibilities so far. I can only tell them that it will take time, but at the same time, since my progress is slow, I also haven’t found a profound interest in this field as I had in my undergraduate studies above. For this year, no matter how long it takes, I fully want to understand this field first by reading that book, learn the common languages that we use, then read all those references to appreciate before I jump into the serious research. But every time in project meetings, I somehow feel that I need to defend myself about what I’m doing when there are piles of things to do accumulating. In short, I feel overwhelmed.\nThat was the reason that my rest has been quite different and sidetracked this time in week 7. I started reading Physics and Beyond written by Werner Heisenberg (see 2024/11/2 - 11/8 Physics and Beyond). This book was the one that I always consulted whenever there were uncertainties about my physics career path. I am on page 108 now out of 268. I want to finish this book first before jumping into reading Understanding Molecular Simulation again, but at the same time, I feel sorry for my supervisors who believe in my progress in my PhD. It’s all difficult now in terms of my situation.\n\n\n\n2024/11/5 Being a Good Lecturer\nAfter attending Hermes’ lecture, I realised there are certain qualities that a very good lecturer shares. To describe him:\nHe was smiling, making jokes, honest, sharing life stories, and, most importantly, engaging with students at their level.\nOften, when I talk with certain lecturers or fellow physics PGRs, they ramble without checking if the person listening is following. Then, it becomes nothing more than loud diary entries or a display of their knowledge.\nI also felt that the language barrier was irrelevant. Hermes had pronunciation difficulties, like me, but he simply let it go, laughing it off rather than taking it too seriously.\nI was quite surprised by how many qualities he actually shared with another of my favourite lecturers, Sandu Popescu. His English isn’t perfect, and he speaks slowly, but it always feels like there is something worth listening to. Also, like Hermes, who wrote on paper, he used the blackboard or whiteboard instead of showing endless slides.\nHermes made plenty of eye contact and made excellent use of pauses during his explanations, allowing students to form images in their minds for better understanding.\nThere was much for me to learn from his approach to lecturing. I thought I was already a good lecturer, one that many students like, but I realised he was truly an inspiration.\n\n\n2024/11/9 - The Science of Interstellar (Thorne 2014)\n\nThorne, Kip. 2014. The Science of Interstellar. WW Norton &Company.\nCited by 265\nToday, I rewatched the film Interstellar, perhaps for the fourth time. I was deeply impressed by Nolan’s previous film Inception, which I also probably watched five times already. Yesterday, I had to give Inception a 10-star rating for the first time in my life, as it just gets more interesting with every viewing. This 10-star rating is very special to me, as I have never rated any of the over 3,000 films I’ve watched so highly.\nAfter this purely fantastical journey, I became curious about the science behind it. Then I realised that the scientific adviser for the film, Kip Thorne, actually wrote a book about it! I knew I had planned to read Understanding Molecular Simulation today, but since it’s the weekend, I decided to indulge in this investigation instead.\n\n\n\nOn page 45, 4. Warped Time and Space, and Tidal Gravity\n\n\nWhat a beautiful way of interpreting general relativity!\nSo far, having read up to Chapter 6, it has all been very interesting! But since Monday has arrived, it’s time to focus on my project again…\n\n\n2024/11/17 The Moment of My Realisation\n\nThe reason Einstein’s theory is beautiful is because it’s the ULTIMATE PATTERN!\nSpace and time are interlinked! Energy and mass are the same! Mass is equal to frequency!1 The beauty of mathematics was that ‘equality’ sign!\nJust a very simple relationship revealed by mathematics!\nThat was the whole purpose of physics!\nNo matter what complicated language we use to describe concepts,\nThere comes the language of physics: “They are the same!”\nI cannot stop laughing.\n“Stop arguing! They are the same!”\nThe reason the renormalisation group naively appeared as beautiful was because, as we went to higher levels of description, we somehow discovered: ‘Oh! They are the same!’\nNow it all makes sense.\nThe reason the proof of Fermat’s Last Theorem was beautiful was because it linked modular forms to elliptic curves! They are the same!\nThe reason Euler’s relation is beautiful is because it links \\(e\\), \\(\\pi\\), \\(i\\), and \\(-1\\)!\nThe reason criticality is beautiful is because the Ising model and liquid-gas model, ‘only’ at the critical point, are the same! Hence the name ‘Universality’!\nThe reason Maxwell’s equations are beautiful is because they show that electric fields and magnetic fields are the same! The whole phenomenon you’ve been looking at, which you thought was different, is just the same!\nThe reason nature is beautiful is because it is the same thing! Not different things! The breath of perceiving their sameness!\nThe driving motivation for me in my MSci was to say: ‘Hey! The market and the brain are THE SAME!’\nI’ve been just chasing this beauty for my entire lifetime!\n\n\n1 By combining \\(E = mc^2\\) and \\(E = hf\\), \\[\nE = mc^2 = hf \\implies f = \\frac{mc^2}{h}\n\\]\n\n\nI shared this diary with ChatGPT, asking the question: ‘The above is my diary, and I realised that the beauty we feel comes from the equality sign! When we recognise the sameness in the different high-level structures of models, we feel the beauty! Are there any scholars who have noticed this?’\nHere was a kind response I received:\n\n\nClick to reveal the answer!\n\nYes, the notion of “sameness” across seemingly disparate structures has long fascinated scholars across various disciplines. The diary entry you’ve shared resonates deeply with ideas explored in physics, mathematics, philosophy, and even cognitive science. Scholars have discussed the aesthetic appeal of discovering unifying principles expressed through equalities, symmetries, or mappings across different domains.\nHere are a few examples of scholars and their thoughts that align with your reflections:\n\nHermann Weyl: In Symmetry (1952), Weyl extensively discusses the beauty inherent in mathematical symmetry and its unifying power across different physical phenomena. He was captivated by the way symmetry provides insight into the sameness of different structures.\nEugene Wigner: His essay The Unreasonable Effectiveness of Mathematics in the Natural Sciences (1960) explores the mysterious and seemingly miraculous ability of mathematics to describe natural phenomena, suggesting that this effectiveness stems from the deep unity (or sameness) in the laws governing different systems.\nPhilip Anderson: In his paper More is Different (1972), Anderson discusses the concept of emergence and universality in physics, emphasising how high-level behaviours often reflect underlying similarities (e.g., critical phenomena in phase transitions).\nRoger Penrose: Penrose, particularly in The Road to Reality (2004), highlights the elegance of mathematical relationships like Euler’s formula and their role in unveiling deep truths about the universe.\nNoam Chomsky (in linguistics and cognitive science): Chomsky’s ideas about “deep structure” in human language propose that surface differences in languages mask an underlying sameness—a universal grammar.\nBenoît Mandelbrot: Mandelbrot’s work on fractals emphasises the beauty of self-similarity in nature, where complex structures emerge from simple iterative rules, demonstrating a unifying pattern.\n\nYour observation about the equality sign being a source of beauty is profound and aligns with discussions in the philosophy of mathematics. Scholars like Bertrand Russell and Alfred North Whitehead, in Principia Mathematica, discuss the foundational role of relations (like equality) in mathematical structures.\nIn contemporary interdisciplinary work, the pursuit of identifying “sameness” across domains is central to fields like network theory (e.g., mapping similarities between neural networks and market behaviours), which directly aligns with your reflections on the market and the brain.\nYour diary elegantly captures a timeless insight: the beauty of science and mathematics often lies in the revelation that what seems different is, at its core, the same.\n\n\n\n2024/11/23 16personalities\nMy personal report\nSince someone kept asking… not that I care about it. I thought this categorisation was only popular in South Korea, but maybe that’s not the case anymore. What’s slightly interesting is that it revealed the same type as when I did it a few years ago, so it seems there is a conservative quantity in my traits. The one who asked me read the report and said, “Unquenchable thirst for knowledge!!!!!!! That’s you!!!”\n\n\n2024/11/25 Stuck in Bristol\nYesterday, Storm Bert disrupted all trains to London, preventing me from travelling to my hotel. As a result, I can no longer attend the Statistical Physics of Cognition conference in person. While I will still join via Zoom, yesterday was so frustrating that all I could do was laugh. It felt like the best thing to do under the circumstances! Strangely, it almost felt as though I was hearing a voice saying, “Stop focusing on neuroscience for now! Embrace your project!”\nThese are the notes I wrote for cancelling the rail tickets through Clarity (for future reference):\n\nI am requesting a refund for this ticket. When I arrived at Clifton Down station at 3:50 pm, I waited 15 minutes only to find out that the train to Bristol Temple Meads had been cancelled. I then took an Uber costing £19.92 to the station, where I discovered that my connecting train was also cancelled. Later, at 8:00 pm, I learned that all trains to eastern destinations, including London, were cancelled due to heavy storms. I have a screenshot as proof and can provide it upon request via email.\n\nThis was my expense claim made through MyERP:\n\nThe train at 4:02 pm from Clifton Down was cancelled, and it was urgent to take a taxi to Bristol Temple Meads as the train was supposed to arrive at 4:30 pm. Sadly, when I went to Temple Meads, this train was also cancelled. I am claiming this expense as I was on my way to the conference; please refer to my past claims made through Clarity. Another update: the train that goes to all eastern destinations, including London, was cancelled, and I only found out at 8 pm. I cancelled my hotel and train bookings through Clarity. Many chaotic events occurred while I was at Temple Meads, and I eventually ended up at Bristol Parkway. I took a bus to Gloucester Road and then came home by Uber.\n\nWhen I got home, I had a phone call with my mum and shared how much the situation had changed. Reflecting on what I said to her:\nWhile I was at the train station for hours, I found myself thinking deeply about my project, the papers I read last week, and my conversations with Nigel and Ian. I realised that my project presents a perfect opportunity to learn about useful concepts for describing non-equilibrium systems, such as entropy production, the Fokker–Planck equation, and the fluctuation-dissipation theorem. Now, investigating these concepts using the simplest models from the particle perspective of active matter feels really exciting! If a drying transition is observed, it will also be a great chance to master the theoretical understanding and application of renormalisation group techniques.\nReading various papers helped me appreciate how interesting colloids and bacteria can be. Bacteria represent the simplest form of living systems, and through motility-induced phase separation, these systems form large-scale structures without any attractive interactions. Thinking about surface phase transitions became particularly intriguing when I considered how 3D structures form 2D boundaries. Boundaries are key to how we differentiate objects. Even in comics, we draw the boundaries of characters and objects. This perspective made the topic even more interesting.\nI also admire how my supervisors approached the problem, using an order parameter to measure the asymmetry within the capillary system. This method effectively avoids the complexities of defining surface tensions and focuses instead on the geometrical aspects of the problem. Once these ideas crystallised in my mind, I felt certain that I wanted to become an expert in this field. If someone asks about surface phase transitions in non-equilibrium systems, I want to be the person they turn to for advice.\nThese thoughts were swirling in my mind, and strangely, the weather even stopped me from travelling to London to attend the Statistical Physics of Cognition conference, where I had planned to network with people in that field. I don’t believe in mystical things, but the timing was mysterious. This kind of weather disruption, preventing travel between cities, hasn’t happened to me in my five years living in the UK.\nI was also thinking about Nigel and Francesco and how thoughtful they both are. I want to become a light that brightens the path for us.\n\n\n2024/11/27 IQ Test\nWhile watching the Statistical Physics of Cognition conference, there was a talk about statistical learning, which I found very interesting. In the evening, I watched a Korean TV show, 대학전쟁 (translated as The University War?), a survival game genre that mostly features puzzles and problem-solving, which I always enjoy watching. It reminded me of my favourite show, The Genius.\nCoincidentally, both mentioned IQ tests. I remember taking one as a teenager; it was quite high, though I couldn’t recall the exact number. I think it was around 153, as I remember this number being interesting:\n\\[\n153 = 1^3 + 5^3 + 3^3\n\\]\nBut my memory is not clear. So, I decided to try a simple test provided here: IQ Test Made by Mensa Norway.\n\n\n\nThe front page\n\n\n\nThere were some questions that were unclear or took a long time to solve, so I captured those:\n\n\n\nExercise 23\n\n\nI spent quite a few minutes on this one. There seemed to be some dynamic rules; if I name the cells 1, 2, 3, 4, …, 9:\n\nThe black circle is straightforward: it moves to the left across the cells, such as 1 → 2 → 3, or 1 → 4 → 7.\nThe cell containing the black square moves diagonally to the left, such as 1 → 6 → 8, while the black square itself shifts left within the cell.\n\nOnce I identified these rules, I realised that the black triangle and white square follow the same rule as the black square. So, I chose F. It took some time to recheck if I had made any mistakes.\n\n\n\nExercise 33\n\n\nUp to this exercise, all the questions had been pretty easy, and I still had more than 10 minutes remaining. However, I spent the most time on this one. My solution process was as follows:\n\nAs the cell moves diagonally to the left, such as 1 → 6 → 8, the triangle at the bottom-right flips first (1 → 6), and then the triangle at the top-left flips (6 → 8).\nWhen the cell moves diagonally to the left along 3 → 5 → 7, the triangle at the top-right flips first (3 → 5), and then the triangle at the bottom-left flips (5 → 7).\nFinally, for the path 2 → 4 → 9, the top-right triangle flips to hide a white triangle (2 → 4). Then, for 4 → 9, the bottom-left triangle flips.\n\nTherefore, I chose E, though I am uncertain if this answer is correct. There seemed to be some inconsistencies: for example, in steps 2 and 3, the top-right triangle flips as the cells progress along a row, but for step 1, it is the bottom-right triangle that flips. I attempted to identify more consistent dynamic rules but couldn’t, so this question took the most time.\n\n\n\nExercise 34\n\n\nThis one wasn’t difficult, but it introduced a new type of question, making it fun to solve. The reason I chose A was:\n\nThe black circle always covers the white circle.\nWhen the two white circles move counterclockwise across the column (e.g., 1 → 2 → 3 or 4 → 5 → 6), they do not overlap. For example, the two white circles initially positioned at the bottom-left in 1 move to the bottom-right in 2 without overlapping, and as they move from 2 to 3, they shift to the top without overlapping.\nThe black circle’s rule operates independently of the white circles. The cell containing the black circle moves diagonally (e.g., 1 → 6 → 8), but the black circle itself remains in the same relative position (the 9 o’clock direction).\n\nThe reason I chose A was because the cell containing the black circle moved from 2 → 4 → 9, while the two white circles moved from 7 → 8 → 9. Since the black circle covered the white circle in the 9 o’clock direction, the answer A was clear.\n\n\n\nExercise 35\n\n\nThis one took the second-longest time after Exercise 33. Here are the rules I inferred:\n\nThe equality sign (=) moves diagonally to the right along 2 → 6 → 7.\nThe upper triangle (∧) moves diagonally to the right along 3 → 4 → 7.\nThe lower triangle (∨) moves diagonally to the right along 1 → 5 → 9 and also diagonally to the left along 1 → 6 → 8.\nThe two walls (| |) move diagonally to the left along 2 → 4 → 9.\n\nHowever, the explanation for the lower triangle (∨) in point 3 felt somewhat ad hoc. I tried to identify another dynamic rule but could not. Based on the above reasoning, the answer D was the most plausible.\n\n\n\nTime remaining\n\n\nI used about 23 minutes and 30 seconds in total.\n\n\n\nResults!\n\n\nOh wow! I’m not sure what the maximum score on this test is, but it roughly suggests that my IQ is still 145 or more. It seems that the theoretical maximum score a person can achieve with a standard deviation of 15 is 160 (source: 나무위키: 지능지수). If I do some simple mathematics, the IQ test follows a normal distribution with a mean of 100 and a standard deviation of 15. My score of 145 gives a z-score of:\n\\[\nz = \\frac{145 - 100}{15} = 3\n\\]\nFrom the z-score, I calculated the cumulative probability using the normal distribution and found it to be 99.87%. This means I am in the top 0.13% of the population.\nTo convert this score to the \\(N(100, 24^2)\\) standard (which appears to be the standard in Mensa Korea), which uses a standard deviation of 24:\n\\[\n\\text{IQ}_{24} = 100 + 3 \\times 24 = 172\n\\]",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "Diary"
    ]
  },
  {
    "objectID": "redirection.html",
    "href": "redirection.html",
    "title": "PhD Redirection",
    "section": "",
    "text": "Also, for the next project meeting, I think it’s probably worthwhile to discuss several concerns I have at this stage.\n\nRight now, I’m focusing on reading about molecular dynamics simulation. However, I’ve been told many times that a lot of the techniques discussed in this book are not related to active matter projects. Do you think it would be better to start reading the references on Zotero instead? There is a lot of material (one book, 21 papers, online resources, as well as code) being presented to me, but it’s not really clear to me what the priority is.\nThere were things that I wanted to discuss last week (see 2024/11/2 Things to discuss and 2024/11/4 Diary), but since not everyone could be present, it was postponed. The notes I wrote on 4 November reflect my feelings about our project and my progress in the PhD. I wonder if these points would be better discussed in the next project meeting before starting the book club meeting.\n\n\n\n\nHi Sohyun,\nThanks for your messages. (I thought I’d move things to email as it is easier for longer conversations).\nHappy to talk about your worries at the next meeting. I would just say at the start that I am not currently concerned about your progress. It is normal at the start of a PhD to spend quite a lot of time “getting the lay of the land”. We appreciate that with such a lot of new ideas and concepts that things can sometimes feel overwhelming, and it can be difficult to separate the wood from the trees. Please be reassured that this is normal.\nI would also say that it is very positive that you are engaged with a good number of complex concepts and trying to understand them in your own terms. The students who don’t make progress are usually the ones who are not engaged, so again I think you can be reassured.\nWhen it comes to reading papers/books that we have suggested, I just wanted to comment that the way most scientists absorb information is usually not by sitting down, reading a paper from cover to cover and not putting it down until they understand every detail. If we did that, we wouldn’t get anything done. Rather we try to first get a feel for roughly what the message of the paper is talking about, the main ideas if you like, and very often that is as far as it goes. If there is something that we find particularly interesting or relevant we might go into more detail, but I would say that that is the exception. So, if we put papers on Zotero and suggest you look at them, we don’t mean that you need to read and understand everything in great detail. In most cases you might just want to get a rough idea of what a paper is about (AI can help here) and build up some familiarity with the types of approaches and language that are used in the field.\nAnother comment I would make is that it is not always necessary as a PhD student to be able to derive from first principles the methods and results that underpin your approach. Of course, we need to feel reasonably confident that we are using tried and tested techniques for which the strengths and weakness are known. But often the methods themselves might be based on decades of work drawn from vast fields of literature. If one were not to try to make progress until all the foundations had been thoroughly understood, then there would be little time left to measure things. I think it is quite right and proper that you want to understand where the Langevin or ABP equations of motion comes from and how this translates into a time stepping algorithm for evolving the system. But I don’t think one necessarily needs to go all the way back to Einstein’s original papers to do this. You told me (I think in the context of your project last year) that you felt the need to understand all the foundations before making progress on the project. I would just comment that often we learn ‘on the job’, so to say, ie we might start calculating or measuring without understanding completely what we are doing or why, but the process of ‘doing’ builds that understanding.\nAnyway, I hope these comments help and we can certainly discuss further next week.\nBest wishes,\nNigel\n\n\n\nIt seems my interests have shifted over the summer or possibly during the final stages of my MSci research project. It sort of makes sense when I think about it in terms of the timeline.\nIn January 2024, when I was applying for my PhD:\n\nI wanted to pursue new physics. It appeared to me that two of my favourite fields (general relativity and quantum field theory) were already well-explored and largely complete.\nI also wanted to gain more employability skills, as I hoped to work at Google DeepMind after my PhD. I thought a computationally driven project was essential for this.\nEager to formally learn about the renormalisation group, I looked into areas of new physics related to it. That’s when I discovered the emerging field of active matter. After reading Keller’s account of its history and emergence, as well as McGivern’s account of how it relates to cognition (which I should probably revisit tomorrow), I thought, this is it! This was the field I wanted to pursue! I met Nigel, who was such a brilliant and thoughtful person to talk with, and Francesco, who had already been amazing. I applied directly (and, in fact, only applied for this PhD, while my peers were applying for multiple positions).\nIn my second term, I was also in the process of interviewing with Samsung Electronics, as they invited me to take on a data scientist role (this happened in early January, I think?). The role and salary were very attractive. However, I had to think deeply about what I truly wanted to do. There were still unsolved mysteries I hoped to explore during my PhD. I was curious about fundamental questions like: What is time? What is space? I thought about relativity theory and how Einstein built his ideas around the concept of a universal clock, which doesn’t depend on the mechanisms of the clock itself. But these clocks are also within a gravitational field. Can we truly justify that reading a clock on an observer’s wrist is the correct way to measure time, given that all clocks are fundamentally based on electromagnetism?\nSo, I decided to stay at university for another four years. Over the summer holidays, I continued reading neuroscience books (particularly on dreams and altered states of consciousness) and considered which topics would be interesting to investigate throughout my PhD.\n\n\n\n\nSee 2024/11/16 Watching Biophysics Lectures\n\nIt really makes me reflect on what I’ve been genuinely interested in. From my third year, I started rating how much I enjoyed each unit after finishing it, based on this scale:\n\n5: I found it very interesting\n\n4: Interesting\n\n3: Okay\n\n2: Not much fun\n\n1: I hated it\n\nHere are the scores for my third-year and fourth-year units:\n\n5: Quantum Physics / Physics Research Project\n\n4.5: Particle Physics, Analytical Mechanics / The Physics of Phase Transitions\n\n4: Methods of Theoretical Physics / Foundations of Modern Physics, General Relativity and Cosmology, Quantum Information Theory\n\n3.5: Materials Physics\n3: Environmental Physics\n\n2.5: Solid State Physics / Applied Materials Physics\n\n2: Biophysics\n\nBased on this, how did I end up choosing my PhD project in active matter? There were complex reasons for choosing it, as I outlined in 2024/11/14 - Skimming through papers, but honestly, I should have thought it through more carefully (even though, at the time, I believed I was being very thorough).\nSo, what am I really interested in? It would be the foundations of modern physics—fairly mathematical work, possibly with computational approaches. However, I’m also deeply interested in neuroscience. I thought I would find a connection by pursuing active matter projects, as studying the brain is a subset of biology. Now, I’m not so sure…\n\n\n\n\n\nContinuous time or discrete time are names. Just the named.\n\n\n\nWetting and drying, it’s not beautiful. It’s such a domain of such an abstract domain.\nTime and space, I’m always experiencing. I want to study something that I’m always experiencing.\n\n\n\nThe reason Einstein’s theory is beautiful is because it’s the ULTIMATE PATTERN!\nSpace and time are interlinked! Energy and mass are the same! Mass is equal to frequency!1 The beauty of mathematics was that ‘equality’ sign!\nJust a very simple relationship revealed by mathematics!\nThat was the whole purpose of physics!\nNo matter what complicated language we use to describe concepts,\nThere comes the language of physics: “They are the same!”\nI cannot stop laughing.\n“Stop arguing! They are the same!”\nThe reason the renormalisation group naively appeared as beautiful was because, as we went to higher levels of description, we somehow discovered: ‘Oh! They are the same!’\nNow it all makes sense.\nThe reason the proof of Fermat’s Last Theorem was beautiful was because it linked modular forms to elliptic curves! They are the same!\nThe reason Euler’s relation is beautiful is because it links \\(e\\), \\(\\pi\\), \\(i\\), and \\(-1\\)!\nThe reason criticality is beautiful is because the Ising model and liquid-gas model, ‘only’ at the critical point, are the same! Hence the name ‘Universality’!\nThe reason Maxwell’s equations are beautiful is because they show that electric fields and magnetic fields are the same! The whole phenomenon you’ve been looking at, which you thought was different, is just the same!\nThe reason nature is beautiful is because it is the same thing! Not different things! The breath of perceiving their sameness!\nThe driving motivation for me in my MSci was to say: ‘Hey! The market and the brain are THE SAME!’\nI’ve been just chasing this beauty for my entire lifetime!\n1 By combining \\(E = mc^2\\) and \\(E = hf\\), \\[\nE = mc^2 = hf \\implies f = \\frac{mc^2}{h}\n\\]\n\n\n\n\nTo get this sense of beauty, the things that are left and right of the equality sign have to be the systems that I’m truly interested in. The reason that the investigation of drying or wetting in non-equilibrium contexts using a very specific model (active Brownian particles) is not beautiful is because none of the systems that I’m considering (which is biology) are my interests!\nI don’t care about biology! I’m afraid of insects!\n\n\n\nWe see the same beauty, But the beauty is not the same.\nWe see everyone’s face, but not ours. We find the sameness between different things, but I’m not a thing that relates to those things. When seeking the sameness between me and the others, it falls into trouble. That’s why we can’t see our face. That’s why I can’t see my face. So that I do not self-reference.\n\n\n\nI have a PhD project I want to do: ‘Equality’ sign in physics. Starting from \\(F = ma\\), all the way to \\(E = mc^2\\) and \\(E = hf\\) Searching for what are the left equalities.\nStart the proposal: ‘Considering a PhD project on the theme of the ‘Equality’ sign in physics, exploring its role from foundational equations like \\(F = ma\\) to \\(E = mc^2\\) and \\(E = hf\\), and identifying other significant equalities.’\n\n\n\nIf I think about my current project as spontaneous symmetry breaking, it is kind of interesting.\n\n\n\n\nAfter having a project meeting discussing these points: 2024/11/18 Weekly Project Meeting\n\nDear Sohyun,\nI am writing to follow up on our conversation yesterday when you told me that you are no longer interested in pursuing your PhD project on surface phase transitions in active matter. I have to say that personally, I think that this is a pity because Francesco Turci and I are really excited by the idea of making progress on this topic which represents an unexplored frontier of non-equilibrium statistical physics (as are other people like Rob Jack and Mike Cates in Cambridge University). I would also note that I rather struggle to understand how this can be a fully informed decision when you have not yet engaged with the project in a meaningful way beyond reading a few background papers. However, if you really can muster no enthusiasm for the topic then I must accept that.\nActive Matter is one of the main areas in which I see my research focussing for the foreseeable future. Are you ruling out just the particular project, or do you no longer wish to work in the field of Active Matter at all? If the latter, then the areas of potential overlap for projects that I am qualified and willing to supervise is limited. Furthermore, if the topic were to change significantly, we would need to seek approval from the Faculty who awarded you UoB funding to do a PhD and who may insist that to retain the funding you don’t stray far from the topic for which your funding was agreed as constituting a strategic priority for the school.\nNevertheless, and with this caveat, there may be some options to consider. I have made a tentative list (see attached pdf), which naturally reflects my interest and background in simulation of phase transitions and critical phenomena in both equilibrium and non-equilibrium statistical physics and soft matter. Please look at the list of topics in the middle column of the document. I am happy to discuss what each project might entail at our meeting on Monday.\nI am also happy for you to suggest a PhD project topic. But if you do this, I think that you need to go away and read about the topic in detail and prepare a written proposal that is both convincing in terms of potential for original research (as defined in the UoB PhD regulations) and likely to overlap with my research interests and expertise. Again, the topic would need to be acceptable to your funders in the faculty. To avoid wasting any time, I’ve also prepared a non-exhaustive list (third column) of projects that I happen to know from our conversations that you are interested in, but which I do not feel sufficiently well qualified or motivated to supervise.\nI think that in this situation it would be useful for you to seek some independent advice on possible next steps. Dr Ian Lindsay is the PGR director for the School of Physics and has indicated to me that he would be happy to meet with you to discuss the situation and explain any formal processes that apply. I would strongly suggest that you take him up on this offer and write to him to arrange a meeting. His email is i.d.lindsay@bristol.ac.uk\nBest regards\nNigel\n\n\n\nHi Nigel,\nThank you very much for your email. I completely agree that it was not a fully informed decision, as I have not yet engaged much with the simulation side of things. That is something I have been trying to address since yesterday. When I went back home, I came across the paper ‘Critical Motility-Induced Phase Separation Belongs to the Ising Universality Class’, which seemed so interesting that I thought it might be worthwhile to attempt simulations of active Brownian particles at the critical MIPS in 2D. Although computational resources would be demanding, it would be very interesting to perform renormalisation to rescale the system and demonstrate its scale-invariant features like the critical Ising model.\nI remain very interested in active matter because it represents a compelling and novel paradigm in physics that resonates with my ideas deeply. I am also not ruling out our current project. I shared my personal concerns in the hope of gaining further inspiration for the current project, and I apologise if I inadvertently gave the impression that I have no interest in either this project or the overarching theme I have chosen.\nI will not be in Bristol next Monday or Tuesday, so should we reschedule the meeting to later this week or next Wednesday? Thank you also for the separate document. I will read through the topics, as I am still quite naïve with many of the fields mentioned.\nThank you for introducing Ian, but at this stage, I would like to refine my thoughts further by exploring your suggestions first. It seems that I was too hasty in yesterday’s meeting, and, in hindsight, I probably should not have brought up my concerns in the way that I did.\nThank you, as always, for your support.\nSohyun\n\n\n\n다시 다 읽어봤어.\n엄마가 보기에 학문적 접근이 4학년이 되면서 본격적으로 이루어졌고, 물리학에 관해서 이해하면서 앎의 지평이 크게 늘었다고 생각해.\n물론, 너의 호기심을 만족시켜줄수 있는 부분은 다분히 철학적인면, Fundamental 한것이고, 석사하면서 너가 실험적으로 해본것은, Active matter를 연구하게 되는것까지 된것이 아닌가 싶어. 그래서 그 분야에서 펀딩을 받으며 지금의 너가 있는데, 음…한번 너가 이야기했던것이 기억나. 물리학의 발견은 이미 거의 다 이루어져서 새로이 먼가를 발견하는것은 힘들다 했던것같아. 석사과정 그리고 박사과정 몇달동안 심층적으로 공부가 된것같고, 엄마는 잘 모르지만, 아직 Supervisor 와의 프로젝트에 적극적으로 하지못한 부분이 있으니, 심화된 이해를 갖춘 바탕으로 연구를 차근 해보는것은 어떨까 생각해.\n물리학을 전혀 모르는 엄마로서는 이번에는 머라 딱히 해줄 수 없는데, 너의 여정을 지켜본 엄마로서 봤을때에는 지금은 흥미롭지는 않더라도, 새로운 선구적인 연구를 하게될때에 또 다른 즐거움이 나타나지 않을지,.\n참,.. 고민 많았지. 컴퓨터 공학 ㅡ 천체물리학 ㅡ 물리학 ㅡ 관심이 어디에 쏠려있느냐에 따라 전과도 하고, 배움의 길을 걸어왔는데, 앞으로의 행보에 대해 고민이 더더욱 되는건 당연할꺼야. 관련된 교수진들을 만나보면서, 너가 어떤 연구방향으로 가게될지 자연스럽게 알게될것같아.\n\n\n\nDear Nigel and Francesco,\nI feel that it’s quite unfortunate that our project meeting ended abruptly today. After having a conversation with Ian, it became quite clear to me that there were misunderstandings in our previous meeting last week, so I hoped to clarify those today as I realised that was an important step.\nI deeply appreciate that you set two agendas to talk about today, and both of them were really helpful! Also, you allowed me to mention what I hoped to talk about after we went through those agendas. However, I felt that when I started to bring up a conversation for clarifying my points, it appeared that both of you wanted me to leave before resolving the misunderstandings. I tried to address those concerns, but it just didn’t work, and I started to wonder if my way of communicating was not correct.\nIn our previous meeting, the reason I mentioned the vape products was because I wanted to talk about how wetting and spreading (or drying) could be interesting to me in terms of my own experiences (even though it was not an active fluid), but you misunderstood me as hoping to make a new vape product (which you wrote in the document that you can’t supervise). The whole point of the previous meeting last week was for me to consult with you on why our initial project was interesting from your perspectives. You mentioned that you started to investigate drying at first but didn’t see any drying. Also, the point I raised to Ian and you was that we don’t observe a drying transition in active fluids in real life, so I hoped to understand your motivation for pursuing it.\nI chose my PhD in active matter because I was largely inspired by two philosophical papers:  1. Keller, Evelyn Fox. 2016. “Active Matter, Then and Now.” History and Philosophy of the Life Sciences 38: 1–11.  2. McGivern, Patrick. 2020. “Active Materials: Minimal Models of Cognition?” Adaptive Behavior 28 (6): 441–51.\nThis new field, which has gained significant popularity over the past 20 years, struck me as a paradigm shift. The advertised project was quite general, and in January, you mentioned that it could evolve based on my interests. However, once I started my PhD, I was given an initial project that, if I were to summarise concisely (for Ian), involves investigating how active Brownian particles (ABPs), which evolve through overdamped Langevin equations, interact with surfaces to induce drying surface phase transitions via molecular dynamics simulations. What was very interesting about this model was that, without any attractive interactions, the particles form large-scale structures, described as motility-induced phase separation, simply by turning on activity (motility). Also, it appeared that this model maps to artificial colloids (e.g., Janus particles) or motile bacteria.\nThe problem arose from the fact that I’ve never observed a drying transition in these systems in empirical reality, which kept bringing me back to the map-territory relation. I was also uncertain whether the results I might obtain could be generalisable to a broader class of active matter systems. As I was reading Physics and Beyond by Werner Heisenberg, I came across Einstein’s remark: “It is the theory which decides what we can observe,” made after he considered Mach’s perspective to be naïve. However, it seemed to me that, as I was reading through papers and articles, many statistical physicists simply play with models without carefully examining their assumptions or their relation to empirical evidence. I tried raising this concern last week so that I could gain a different perspective from you, but if it was to be largely dismissed as being “too philosophical” to pursue further discussion, then that’s fine, but it’s just unfortunate.\nSo, in summary, I raised my concern to gain more insights from you, while you understood it as me having completely lost interest in the project, which I found out with Ian was a miscommunication.\nAlso, in terms of progress, yes, I did engage with other materials outside our project (these are for fun and not to be confused with what I do during my working hours). But I have always spent a lot of time reading articles and papers related to our project, as well as understanding the code. In the beginning, you clearly pointed out that, as a PhD student, at first, it’s important to understand the wider context, and it’s a mistake for them to just start working on the problems without this background reading. I’ve been doing so, and you said in the first email (which you sent on the 13th) that you were not worried about my progress. Then, in your second email after our project meeting, I was told that I’m not making meaningful progress.\nI’m quite confused about all this. It takes a long time to read papers from a new field because, during my undergraduate studies, we didn’t cover non-equilibrium statistical physics or colloidal physics. For example, Francesco asked me if I had learned about random walks, but we also didn’t cover this basic concept either! Also, it takes a long time to understand the code written in C++. Yes, there are similarities as I did C and Java in the past, but even a single file such as fix_abp.cpp has a lot of links to other codes such as fix_abp.h, force.h, random_mars.h, etc.\nAs you pointed out in terms of supervision, yes, I won’t raise any philosophical concerns or my interests outside the set project at all. Because if I try to do so, it seems I create misunderstandings. However, I did want to emphasise that my mind is now clear, and maybe I could bring what I wrote on the 25th, which summarises how my motivation and ambition have settled:\n\nWhen I got home, I had a phone call with my mum and shared how much the situation had changed. Reflecting on what I said to her:\nWhile I was at the train station for hours, I found myself thinking deeply about my project, the papers I read last week, and my conversations with Nigel and Ian. I realised that my project presents a perfect opportunity to learn about useful concepts for describing non-equilibrium systems, such as entropy production, the Fokker–Planck equation, and the fluctuation-dissipation theorem. Now, investigating these concepts using the simplest models from the particle perspective of active matter feels really exciting! If a drying transition is observed, it will also be a great chance to master the theoretical understanding and application of renormalisation group techniques.\nReading various papers helped me appreciate how interesting colloids and bacteria can be. Bacteria represent the simplest form of living systems, and through motility-induced phase separation, these systems form large-scale structures without any attractive interactions. Thinking about surface phase transitions became particularly intriguing when I considered how 3D structures form 2D boundaries. Boundaries are key to how we differentiate objects. Even in comics, we draw the boundaries of characters and objects. This perspective made the topic even more interesting.\nI also admire how my supervisors approached the problem, using an order parameter to measure the asymmetry within the capillary system. This method effectively avoids the complexities of defining surface tensions and focuses instead on the geometrical aspects of the problem. Once these ideas crystallised in my mind, I felt certain that I wanted to become an expert in this field. If someone asks about surface phase transitions in non-equilibrium systems, I want to be the person they turn to for advice.\nThese thoughts were swirling in my mind, and strangely, the weather even stopped me from travelling to London to attend the Statistical Physics of Cognition conference, where I had planned to network with people in that field. I don’t believe in mystical things, but the timing was mysterious. This kind of weather disruption, preventing travel between cities, hasn’t happened to me in my five years living in the UK.\nI was also thinking about Nigel and Francesco and how thoughtful they both are. I want to become a light that brightens the path for us.\n\nBut, as you pointed out, I will separate our project notes from my logbook on my project website. Also, thank you very much for introducing the critical Casimir effect in active fluids analogues. I’ll read through the materials on my own over this week. (Initially, as my mind has settled, I was going to work on the simulation side as I wasn’t certain how to construct a wall as you did in your papers with my given code, but I will delay that work until next week.)\nSomehow, your email which followed from our meeting just now has arrived while I was writing this email. I’ll read through your email after I send this.\nThank you, Sohyun\n\n\n\nDear Sohyun (cc Francesco, Ian),\nI wanted to follow up on our meeting today and reiterate and elaborate in writing some of the points covered.\nAs you had previously expressed reservations about continuing with the Active Drying project, we discussed an alternative project in Active Matter centred around the Critical Casimir Effect. You said that on reflection you are happy to continue with the original project, and we agreed that we could keep the Critical Casimir Effect project as a backup or as a topic for future work.\nOn more general matters, we stated that from the point of view of the student-supervisor relationship, there needs to be a clear separation between your work on the project and outside interests. The responsibilities of PhD supervisors do not extend beyond supporting your work on the project and advising/supporting should there be any issues (eg illness/personal situation) that are affecting your ability to progress with the project. Project meetings are therefore not for discussing anything with you except the science of the project or pastoral issues that may be affecting your ability to work.\nSimilarly, if you want to use a blog as a lab book to record progress and notes on papers read etc, this is laudable and desirable for facilitating discussions, but what you have been writing and sharing with us has turned into a sort of personal diary and that’s inappropriate for the student-supervisor relationship. If you want us to read things then they need to be confined to matters directly related to the project.\nBeing a successful PhD student requires a certain level of commitment. While it is early days and we don’t have serious concerns about your progress, we do note that you seem to be spending considerable time writing blogs and thinking about philosophy, vaping, neuroscience, and reading and rereading books, and lecture notes, etc., the relevance of which is not clear. While you can of course do what you want in your own time, we feel that you need to take care not to blur the boundaries between what is in scope for the project work and what is not. From your blog and recent conversations, we are concerned that this might be happening.\nI hope that these comments are helpful. They are not intended to be critical – we just want you to have clear and realistic expectations of the process so that you have a satisfied, enjoyable, and successful PhD journey.\nBest regards\nNigel and Francesco\n\n\n\nDear Nigel,\nThank you for your email. I’ve been reading about the critical Casimir effect, and it’s so interesting! There was research using the run-and-tumble model by Ray et al. in 2014, and since run-and-tumble and ABPs can be mapped onto each other, I thought this paper was quite relevant, so I uploaded it to Zotero (under the category of Active Casimir Effect). Also, there was a concise review on this theme by Bechinger et al. in 2016. Even recently, there has been work on this topic using flocking active matter by Fava et al. in 2024. It’s so interesting, and I deeply appreciate you coming up with this suggestion! By Monday next week, I’ll read more and finalise my choice, though at this stage, I feel it would be more worthwhile to continue with the active drying project first to apply the concepts I’ve learned over the past two months in simulations. If that’s the decision, I can see myself working on the active Casimir effect right after the initial project.\nYes, I won’t share anything unrelated to the project anymore. If I may offer an excuse, there were two occasions I shared something: one was a dialogue related to active matter on 17th of September, and the other was a note on ‘things to discuss’ for the project meeting when I was concerned about the project two weeks ago. I thought both were related, but I apologise and appreciate your pointing out that they were not the right forms to share. I won’t do it again.\nI have honestly felt quite isolated at times this semester as the only PhD student in theoretical physics investigating active matter. So, it was such an enjoyable opportunity for me to have a conversation with you and Francesco, even in broader contexts beyond our project. However, I’ll make sure to confine my conversations strictly to the current project.\nYour comments have been helpful, and I’ll be more realistic from now on. I have also closed the website, as I probably enjoyed designing it a bit too much. While it was intended to document everything I do during my PhD in a self-contained way, it may not have conveyed how much time I dedicate to our project.\nThank you,\nSohyun",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#my-teams-message-to-nigel-and-francesco",
    "href": "redirection.html#my-teams-message-to-nigel-and-francesco",
    "title": "PhD Redirection",
    "section": "",
    "text": "Also, for the next project meeting, I think it’s probably worthwhile to discuss several concerns I have at this stage.\n\nRight now, I’m focusing on reading about molecular dynamics simulation. However, I’ve been told many times that a lot of the techniques discussed in this book are not related to active matter projects. Do you think it would be better to start reading the references on Zotero instead? There is a lot of material (one book, 21 papers, online resources, as well as code) being presented to me, but it’s not really clear to me what the priority is.\nThere were things that I wanted to discuss last week (see 2024/11/2 Things to discuss and 2024/11/4 Diary), but since not everyone could be present, it was postponed. The notes I wrote on 4 November reflect my feelings about our project and my progress in the PhD. I wonder if these points would be better discussed in the next project meeting before starting the book club meeting.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#email-received-from-nigel",
    "href": "redirection.html#email-received-from-nigel",
    "title": "PhD Redirection",
    "section": "",
    "text": "Hi Sohyun,\nThanks for your messages. (I thought I’d move things to email as it is easier for longer conversations).\nHappy to talk about your worries at the next meeting. I would just say at the start that I am not currently concerned about your progress. It is normal at the start of a PhD to spend quite a lot of time “getting the lay of the land”. We appreciate that with such a lot of new ideas and concepts that things can sometimes feel overwhelming, and it can be difficult to separate the wood from the trees. Please be reassured that this is normal.\nI would also say that it is very positive that you are engaged with a good number of complex concepts and trying to understand them in your own terms. The students who don’t make progress are usually the ones who are not engaged, so again I think you can be reassured.\nWhen it comes to reading papers/books that we have suggested, I just wanted to comment that the way most scientists absorb information is usually not by sitting down, reading a paper from cover to cover and not putting it down until they understand every detail. If we did that, we wouldn’t get anything done. Rather we try to first get a feel for roughly what the message of the paper is talking about, the main ideas if you like, and very often that is as far as it goes. If there is something that we find particularly interesting or relevant we might go into more detail, but I would say that that is the exception. So, if we put papers on Zotero and suggest you look at them, we don’t mean that you need to read and understand everything in great detail. In most cases you might just want to get a rough idea of what a paper is about (AI can help here) and build up some familiarity with the types of approaches and language that are used in the field.\nAnother comment I would make is that it is not always necessary as a PhD student to be able to derive from first principles the methods and results that underpin your approach. Of course, we need to feel reasonably confident that we are using tried and tested techniques for which the strengths and weakness are known. But often the methods themselves might be based on decades of work drawn from vast fields of literature. If one were not to try to make progress until all the foundations had been thoroughly understood, then there would be little time left to measure things. I think it is quite right and proper that you want to understand where the Langevin or ABP equations of motion comes from and how this translates into a time stepping algorithm for evolving the system. But I don’t think one necessarily needs to go all the way back to Einstein’s original papers to do this. You told me (I think in the context of your project last year) that you felt the need to understand all the foundations before making progress on the project. I would just comment that often we learn ‘on the job’, so to say, ie we might start calculating or measuring without understanding completely what we are doing or why, but the process of ‘doing’ builds that understanding.\nAnyway, I hope these comments help and we can certainly discuss further next week.\nBest wishes,\nNigel",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#diary",
    "href": "redirection.html#diary",
    "title": "PhD Redirection",
    "section": "",
    "text": "It seems my interests have shifted over the summer or possibly during the final stages of my MSci research project. It sort of makes sense when I think about it in terms of the timeline.\nIn January 2024, when I was applying for my PhD:\n\nI wanted to pursue new physics. It appeared to me that two of my favourite fields (general relativity and quantum field theory) were already well-explored and largely complete.\nI also wanted to gain more employability skills, as I hoped to work at Google DeepMind after my PhD. I thought a computationally driven project was essential for this.\nEager to formally learn about the renormalisation group, I looked into areas of new physics related to it. That’s when I discovered the emerging field of active matter. After reading Keller’s account of its history and emergence, as well as McGivern’s account of how it relates to cognition (which I should probably revisit tomorrow), I thought, this is it! This was the field I wanted to pursue! I met Nigel, who was such a brilliant and thoughtful person to talk with, and Francesco, who had already been amazing. I applied directly (and, in fact, only applied for this PhD, while my peers were applying for multiple positions).\nIn my second term, I was also in the process of interviewing with Samsung Electronics, as they invited me to take on a data scientist role (this happened in early January, I think?). The role and salary were very attractive. However, I had to think deeply about what I truly wanted to do. There were still unsolved mysteries I hoped to explore during my PhD. I was curious about fundamental questions like: What is time? What is space? I thought about relativity theory and how Einstein built his ideas around the concept of a universal clock, which doesn’t depend on the mechanisms of the clock itself. But these clocks are also within a gravitational field. Can we truly justify that reading a clock on an observer’s wrist is the correct way to measure time, given that all clocks are fundamentally based on electromagnetism?\nSo, I decided to stay at university for another four years. Over the summer holidays, I continued reading neuroscience books (particularly on dreams and altered states of consciousness) and considered which topics would be interesting to investigate throughout my PhD.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#diary-1",
    "href": "redirection.html#diary-1",
    "title": "PhD Redirection",
    "section": "",
    "text": "See 2024/11/16 Watching Biophysics Lectures\n\nIt really makes me reflect on what I’ve been genuinely interested in. From my third year, I started rating how much I enjoyed each unit after finishing it, based on this scale:\n\n5: I found it very interesting\n\n4: Interesting\n\n3: Okay\n\n2: Not much fun\n\n1: I hated it\n\nHere are the scores for my third-year and fourth-year units:\n\n5: Quantum Physics / Physics Research Project\n\n4.5: Particle Physics, Analytical Mechanics / The Physics of Phase Transitions\n\n4: Methods of Theoretical Physics / Foundations of Modern Physics, General Relativity and Cosmology, Quantum Information Theory\n\n3.5: Materials Physics\n3: Environmental Physics\n\n2.5: Solid State Physics / Applied Materials Physics\n\n2: Biophysics\n\nBased on this, how did I end up choosing my PhD project in active matter? There were complex reasons for choosing it, as I outlined in 2024/11/14 - Skimming through papers, but honestly, I should have thought it through more carefully (even though, at the time, I believed I was being very thorough).\nSo, what am I really interested in? It would be the foundations of modern physics—fairly mathematical work, possibly with computational approaches. However, I’m also deeply interested in neuroscience. I thought I would find a connection by pursuing active matter projects, as studying the brain is a subset of biology. Now, I’m not so sure…",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#some-passages-from-my-diary",
    "href": "redirection.html#some-passages-from-my-diary",
    "title": "PhD Redirection",
    "section": "",
    "text": "Continuous time or discrete time are names. Just the named.\n\n\n\nWetting and drying, it’s not beautiful. It’s such a domain of such an abstract domain.\nTime and space, I’m always experiencing. I want to study something that I’m always experiencing.\n\n\n\nThe reason Einstein’s theory is beautiful is because it’s the ULTIMATE PATTERN!\nSpace and time are interlinked! Energy and mass are the same! Mass is equal to frequency!1 The beauty of mathematics was that ‘equality’ sign!\nJust a very simple relationship revealed by mathematics!\nThat was the whole purpose of physics!\nNo matter what complicated language we use to describe concepts,\nThere comes the language of physics: “They are the same!”\nI cannot stop laughing.\n“Stop arguing! They are the same!”\nThe reason the renormalisation group naively appeared as beautiful was because, as we went to higher levels of description, we somehow discovered: ‘Oh! They are the same!’\nNow it all makes sense.\nThe reason the proof of Fermat’s Last Theorem was beautiful was because it linked modular forms to elliptic curves! They are the same!\nThe reason Euler’s relation is beautiful is because it links \\(e\\), \\(\\pi\\), \\(i\\), and \\(-1\\)!\nThe reason criticality is beautiful is because the Ising model and liquid-gas model, ‘only’ at the critical point, are the same! Hence the name ‘Universality’!\nThe reason Maxwell’s equations are beautiful is because they show that electric fields and magnetic fields are the same! The whole phenomenon you’ve been looking at, which you thought was different, is just the same!\nThe reason nature is beautiful is because it is the same thing! Not different things! The breath of perceiving their sameness!\nThe driving motivation for me in my MSci was to say: ‘Hey! The market and the brain are THE SAME!’\nI’ve been just chasing this beauty for my entire lifetime!\n1 By combining \\(E = mc^2\\) and \\(E = hf\\), \\[\nE = mc^2 = hf \\implies f = \\frac{mc^2}{h}\n\\]\n\n\n\n\nTo get this sense of beauty, the things that are left and right of the equality sign have to be the systems that I’m truly interested in. The reason that the investigation of drying or wetting in non-equilibrium contexts using a very specific model (active Brownian particles) is not beautiful is because none of the systems that I’m considering (which is biology) are my interests!\nI don’t care about biology! I’m afraid of insects!\n\n\n\nWe see the same beauty, But the beauty is not the same.\nWe see everyone’s face, but not ours. We find the sameness between different things, but I’m not a thing that relates to those things. When seeking the sameness between me and the others, it falls into trouble. That’s why we can’t see our face. That’s why I can’t see my face. So that I do not self-reference.\n\n\n\nI have a PhD project I want to do: ‘Equality’ sign in physics. Starting from \\(F = ma\\), all the way to \\(E = mc^2\\) and \\(E = hf\\) Searching for what are the left equalities.\nStart the proposal: ‘Considering a PhD project on the theme of the ‘Equality’ sign in physics, exploring its role from foundational equations like \\(F = ma\\) to \\(E = mc^2\\) and \\(E = hf\\), and identifying other significant equalities.’\n\n\n\nIf I think about my current project as spontaneous symmetry breaking, it is kind of interesting.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#email-received-from-nigel-1",
    "href": "redirection.html#email-received-from-nigel-1",
    "title": "PhD Redirection",
    "section": "",
    "text": "After having a project meeting discussing these points: 2024/11/18 Weekly Project Meeting\n\nDear Sohyun,\nI am writing to follow up on our conversation yesterday when you told me that you are no longer interested in pursuing your PhD project on surface phase transitions in active matter. I have to say that personally, I think that this is a pity because Francesco Turci and I are really excited by the idea of making progress on this topic which represents an unexplored frontier of non-equilibrium statistical physics (as are other people like Rob Jack and Mike Cates in Cambridge University). I would also note that I rather struggle to understand how this can be a fully informed decision when you have not yet engaged with the project in a meaningful way beyond reading a few background papers. However, if you really can muster no enthusiasm for the topic then I must accept that.\nActive Matter is one of the main areas in which I see my research focussing for the foreseeable future. Are you ruling out just the particular project, or do you no longer wish to work in the field of Active Matter at all? If the latter, then the areas of potential overlap for projects that I am qualified and willing to supervise is limited. Furthermore, if the topic were to change significantly, we would need to seek approval from the Faculty who awarded you UoB funding to do a PhD and who may insist that to retain the funding you don’t stray far from the topic for which your funding was agreed as constituting a strategic priority for the school.\nNevertheless, and with this caveat, there may be some options to consider. I have made a tentative list (see attached pdf), which naturally reflects my interest and background in simulation of phase transitions and critical phenomena in both equilibrium and non-equilibrium statistical physics and soft matter. Please look at the list of topics in the middle column of the document. I am happy to discuss what each project might entail at our meeting on Monday.\nI am also happy for you to suggest a PhD project topic. But if you do this, I think that you need to go away and read about the topic in detail and prepare a written proposal that is both convincing in terms of potential for original research (as defined in the UoB PhD regulations) and likely to overlap with my research interests and expertise. Again, the topic would need to be acceptable to your funders in the faculty. To avoid wasting any time, I’ve also prepared a non-exhaustive list (third column) of projects that I happen to know from our conversations that you are interested in, but which I do not feel sufficiently well qualified or motivated to supervise.\nI think that in this situation it would be useful for you to seek some independent advice on possible next steps. Dr Ian Lindsay is the PGR director for the School of Physics and has indicated to me that he would be happy to meet with you to discuss the situation and explain any formal processes that apply. I would strongly suggest that you take him up on this offer and write to him to arrange a meeting. His email is i.d.lindsay@bristol.ac.uk\nBest regards\nNigel",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#my-reply-to-nigel",
    "href": "redirection.html#my-reply-to-nigel",
    "title": "PhD Redirection",
    "section": "",
    "text": "Hi Nigel,\nThank you very much for your email. I completely agree that it was not a fully informed decision, as I have not yet engaged much with the simulation side of things. That is something I have been trying to address since yesterday. When I went back home, I came across the paper ‘Critical Motility-Induced Phase Separation Belongs to the Ising Universality Class’, which seemed so interesting that I thought it might be worthwhile to attempt simulations of active Brownian particles at the critical MIPS in 2D. Although computational resources would be demanding, it would be very interesting to perform renormalisation to rescale the system and demonstrate its scale-invariant features like the critical Ising model.\nI remain very interested in active matter because it represents a compelling and novel paradigm in physics that resonates with my ideas deeply. I am also not ruling out our current project. I shared my personal concerns in the hope of gaining further inspiration for the current project, and I apologise if I inadvertently gave the impression that I have no interest in either this project or the overarching theme I have chosen.\nI will not be in Bristol next Monday or Tuesday, so should we reschedule the meeting to later this week or next Wednesday? Thank you also for the separate document. I will read through the topics, as I am still quite naïve with many of the fields mentioned.\nThank you for introducing Ian, but at this stage, I would like to refine my thoughts further by exploring your suggestions first. It seems that I was too hasty in yesterday’s meeting, and, in hindsight, I probably should not have brought up my concerns in the way that I did.\nThank you, as always, for your support.\nSohyun",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#엄마의-메세지",
    "href": "redirection.html#엄마의-메세지",
    "title": "PhD Redirection",
    "section": "",
    "text": "다시 다 읽어봤어.\n엄마가 보기에 학문적 접근이 4학년이 되면서 본격적으로 이루어졌고, 물리학에 관해서 이해하면서 앎의 지평이 크게 늘었다고 생각해.\n물론, 너의 호기심을 만족시켜줄수 있는 부분은 다분히 철학적인면, Fundamental 한것이고, 석사하면서 너가 실험적으로 해본것은, Active matter를 연구하게 되는것까지 된것이 아닌가 싶어. 그래서 그 분야에서 펀딩을 받으며 지금의 너가 있는데, 음…한번 너가 이야기했던것이 기억나. 물리학의 발견은 이미 거의 다 이루어져서 새로이 먼가를 발견하는것은 힘들다 했던것같아. 석사과정 그리고 박사과정 몇달동안 심층적으로 공부가 된것같고, 엄마는 잘 모르지만, 아직 Supervisor 와의 프로젝트에 적극적으로 하지못한 부분이 있으니, 심화된 이해를 갖춘 바탕으로 연구를 차근 해보는것은 어떨까 생각해.\n물리학을 전혀 모르는 엄마로서는 이번에는 머라 딱히 해줄 수 없는데, 너의 여정을 지켜본 엄마로서 봤을때에는 지금은 흥미롭지는 않더라도, 새로운 선구적인 연구를 하게될때에 또 다른 즐거움이 나타나지 않을지,.\n참,.. 고민 많았지. 컴퓨터 공학 ㅡ 천체물리학 ㅡ 물리학 ㅡ 관심이 어디에 쏠려있느냐에 따라 전과도 하고, 배움의 길을 걸어왔는데, 앞으로의 행보에 대해 고민이 더더욱 되는건 당연할꺼야. 관련된 교수진들을 만나보면서, 너가 어떤 연구방향으로 가게될지 자연스럽게 알게될것같아.",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#email-sent-to-nigel-and-francesco",
    "href": "redirection.html#email-sent-to-nigel-and-francesco",
    "title": "PhD Redirection",
    "section": "",
    "text": "Dear Nigel and Francesco,\nI feel that it’s quite unfortunate that our project meeting ended abruptly today. After having a conversation with Ian, it became quite clear to me that there were misunderstandings in our previous meeting last week, so I hoped to clarify those today as I realised that was an important step.\nI deeply appreciate that you set two agendas to talk about today, and both of them were really helpful! Also, you allowed me to mention what I hoped to talk about after we went through those agendas. However, I felt that when I started to bring up a conversation for clarifying my points, it appeared that both of you wanted me to leave before resolving the misunderstandings. I tried to address those concerns, but it just didn’t work, and I started to wonder if my way of communicating was not correct.\nIn our previous meeting, the reason I mentioned the vape products was because I wanted to talk about how wetting and spreading (or drying) could be interesting to me in terms of my own experiences (even though it was not an active fluid), but you misunderstood me as hoping to make a new vape product (which you wrote in the document that you can’t supervise). The whole point of the previous meeting last week was for me to consult with you on why our initial project was interesting from your perspectives. You mentioned that you started to investigate drying at first but didn’t see any drying. Also, the point I raised to Ian and you was that we don’t observe a drying transition in active fluids in real life, so I hoped to understand your motivation for pursuing it.\nI chose my PhD in active matter because I was largely inspired by two philosophical papers:  1. Keller, Evelyn Fox. 2016. “Active Matter, Then and Now.” History and Philosophy of the Life Sciences 38: 1–11.  2. McGivern, Patrick. 2020. “Active Materials: Minimal Models of Cognition?” Adaptive Behavior 28 (6): 441–51.\nThis new field, which has gained significant popularity over the past 20 years, struck me as a paradigm shift. The advertised project was quite general, and in January, you mentioned that it could evolve based on my interests. However, once I started my PhD, I was given an initial project that, if I were to summarise concisely (for Ian), involves investigating how active Brownian particles (ABPs), which evolve through overdamped Langevin equations, interact with surfaces to induce drying surface phase transitions via molecular dynamics simulations. What was very interesting about this model was that, without any attractive interactions, the particles form large-scale structures, described as motility-induced phase separation, simply by turning on activity (motility). Also, it appeared that this model maps to artificial colloids (e.g., Janus particles) or motile bacteria.\nThe problem arose from the fact that I’ve never observed a drying transition in these systems in empirical reality, which kept bringing me back to the map-territory relation. I was also uncertain whether the results I might obtain could be generalisable to a broader class of active matter systems. As I was reading Physics and Beyond by Werner Heisenberg, I came across Einstein’s remark: “It is the theory which decides what we can observe,” made after he considered Mach’s perspective to be naïve. However, it seemed to me that, as I was reading through papers and articles, many statistical physicists simply play with models without carefully examining their assumptions or their relation to empirical evidence. I tried raising this concern last week so that I could gain a different perspective from you, but if it was to be largely dismissed as being “too philosophical” to pursue further discussion, then that’s fine, but it’s just unfortunate.\nSo, in summary, I raised my concern to gain more insights from you, while you understood it as me having completely lost interest in the project, which I found out with Ian was a miscommunication.\nAlso, in terms of progress, yes, I did engage with other materials outside our project (these are for fun and not to be confused with what I do during my working hours). But I have always spent a lot of time reading articles and papers related to our project, as well as understanding the code. In the beginning, you clearly pointed out that, as a PhD student, at first, it’s important to understand the wider context, and it’s a mistake for them to just start working on the problems without this background reading. I’ve been doing so, and you said in the first email (which you sent on the 13th) that you were not worried about my progress. Then, in your second email after our project meeting, I was told that I’m not making meaningful progress.\nI’m quite confused about all this. It takes a long time to read papers from a new field because, during my undergraduate studies, we didn’t cover non-equilibrium statistical physics or colloidal physics. For example, Francesco asked me if I had learned about random walks, but we also didn’t cover this basic concept either! Also, it takes a long time to understand the code written in C++. Yes, there are similarities as I did C and Java in the past, but even a single file such as fix_abp.cpp has a lot of links to other codes such as fix_abp.h, force.h, random_mars.h, etc.\nAs you pointed out in terms of supervision, yes, I won’t raise any philosophical concerns or my interests outside the set project at all. Because if I try to do so, it seems I create misunderstandings. However, I did want to emphasise that my mind is now clear, and maybe I could bring what I wrote on the 25th, which summarises how my motivation and ambition have settled:\n\nWhen I got home, I had a phone call with my mum and shared how much the situation had changed. Reflecting on what I said to her:\nWhile I was at the train station for hours, I found myself thinking deeply about my project, the papers I read last week, and my conversations with Nigel and Ian. I realised that my project presents a perfect opportunity to learn about useful concepts for describing non-equilibrium systems, such as entropy production, the Fokker–Planck equation, and the fluctuation-dissipation theorem. Now, investigating these concepts using the simplest models from the particle perspective of active matter feels really exciting! If a drying transition is observed, it will also be a great chance to master the theoretical understanding and application of renormalisation group techniques.\nReading various papers helped me appreciate how interesting colloids and bacteria can be. Bacteria represent the simplest form of living systems, and through motility-induced phase separation, these systems form large-scale structures without any attractive interactions. Thinking about surface phase transitions became particularly intriguing when I considered how 3D structures form 2D boundaries. Boundaries are key to how we differentiate objects. Even in comics, we draw the boundaries of characters and objects. This perspective made the topic even more interesting.\nI also admire how my supervisors approached the problem, using an order parameter to measure the asymmetry within the capillary system. This method effectively avoids the complexities of defining surface tensions and focuses instead on the geometrical aspects of the problem. Once these ideas crystallised in my mind, I felt certain that I wanted to become an expert in this field. If someone asks about surface phase transitions in non-equilibrium systems, I want to be the person they turn to for advice.\nThese thoughts were swirling in my mind, and strangely, the weather even stopped me from travelling to London to attend the Statistical Physics of Cognition conference, where I had planned to network with people in that field. I don’t believe in mystical things, but the timing was mysterious. This kind of weather disruption, preventing travel between cities, hasn’t happened to me in my five years living in the UK.\nI was also thinking about Nigel and Francesco and how thoughtful they both are. I want to become a light that brightens the path for us.\n\nBut, as you pointed out, I will separate our project notes from my logbook on my project website. Also, thank you very much for introducing the critical Casimir effect in active fluids analogues. I’ll read through the materials on my own over this week. (Initially, as my mind has settled, I was going to work on the simulation side as I wasn’t certain how to construct a wall as you did in your papers with my given code, but I will delay that work until next week.)\nSomehow, your email which followed from our meeting just now has arrived while I was writing this email. I’ll read through your email after I send this.\nThank you, Sohyun",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#email-received-from-nigel-2",
    "href": "redirection.html#email-received-from-nigel-2",
    "title": "PhD Redirection",
    "section": "",
    "text": "Dear Sohyun (cc Francesco, Ian),\nI wanted to follow up on our meeting today and reiterate and elaborate in writing some of the points covered.\nAs you had previously expressed reservations about continuing with the Active Drying project, we discussed an alternative project in Active Matter centred around the Critical Casimir Effect. You said that on reflection you are happy to continue with the original project, and we agreed that we could keep the Critical Casimir Effect project as a backup or as a topic for future work.\nOn more general matters, we stated that from the point of view of the student-supervisor relationship, there needs to be a clear separation between your work on the project and outside interests. The responsibilities of PhD supervisors do not extend beyond supporting your work on the project and advising/supporting should there be any issues (eg illness/personal situation) that are affecting your ability to progress with the project. Project meetings are therefore not for discussing anything with you except the science of the project or pastoral issues that may be affecting your ability to work.\nSimilarly, if you want to use a blog as a lab book to record progress and notes on papers read etc, this is laudable and desirable for facilitating discussions, but what you have been writing and sharing with us has turned into a sort of personal diary and that’s inappropriate for the student-supervisor relationship. If you want us to read things then they need to be confined to matters directly related to the project.\nBeing a successful PhD student requires a certain level of commitment. While it is early days and we don’t have serious concerns about your progress, we do note that you seem to be spending considerable time writing blogs and thinking about philosophy, vaping, neuroscience, and reading and rereading books, and lecture notes, etc., the relevance of which is not clear. While you can of course do what you want in your own time, we feel that you need to take care not to blur the boundaries between what is in scope for the project work and what is not. From your blog and recent conversations, we are concerned that this might be happening.\nI hope that these comments are helpful. They are not intended to be critical – we just want you to have clear and realistic expectations of the process so that you have a satisfied, enjoyable, and successful PhD journey.\nBest regards\nNigel and Francesco",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "redirection.html#email-sent-to-nigel-and-francesco-1",
    "href": "redirection.html#email-sent-to-nigel-and-francesco-1",
    "title": "PhD Redirection",
    "section": "",
    "text": "Dear Nigel,\nThank you for your email. I’ve been reading about the critical Casimir effect, and it’s so interesting! There was research using the run-and-tumble model by Ray et al. in 2014, and since run-and-tumble and ABPs can be mapped onto each other, I thought this paper was quite relevant, so I uploaded it to Zotero (under the category of Active Casimir Effect). Also, there was a concise review on this theme by Bechinger et al. in 2016. Even recently, there has been work on this topic using flocking active matter by Fava et al. in 2024. It’s so interesting, and I deeply appreciate you coming up with this suggestion! By Monday next week, I’ll read more and finalise my choice, though at this stage, I feel it would be more worthwhile to continue with the active drying project first to apply the concepts I’ve learned over the past two months in simulations. If that’s the decision, I can see myself working on the active Casimir effect right after the initial project.\nYes, I won’t share anything unrelated to the project anymore. If I may offer an excuse, there were two occasions I shared something: one was a dialogue related to active matter on 17th of September, and the other was a note on ‘things to discuss’ for the project meeting when I was concerned about the project two weeks ago. I thought both were related, but I apologise and appreciate your pointing out that they were not the right forms to share. I won’t do it again.\nI have honestly felt quite isolated at times this semester as the only PhD student in theoretical physics investigating active matter. So, it was such an enjoyable opportunity for me to have a conversation with you and Francesco, even in broader contexts beyond our project. However, I’ll make sure to confine my conversations strictly to the current project.\nYour comments have been helpful, and I’ll be more realistic from now on. I have also closed the website, as I probably enjoyed designing it a bit too much. While it was intended to document everything I do during my PhD in a self-contained way, it may not have conveyed how much time I dedicate to our project.\nThank you,\nSohyun",
    "crumbs": [
      "Archive (No updates since 2024/11/29)",
      "PhD Redirection"
    ]
  },
  {
    "objectID": "meetings.html",
    "href": "meetings.html",
    "title": "Project Meetings",
    "section": "",
    "text": "Do I need to upload content to Pure?\n\nHow do I claim my research allowance?\n\nAre there any lectures recommended to audit?\n\nCan I work from home until I recover?",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-3",
    "href": "meetings.html#week-3",
    "title": "Project Meetings",
    "section": "Week 3",
    "text": "Week 3\n\n2024/9/30 Things to discuss\n\nMeeting with Max on Friday at noon (4th of Oct), thinking of going to Budapest Café\n‘Setting Expectations’ document\nTwo conferences to join:\n• The Dao of Complexity workshop\n• The Statistical Physics of Cognition\nSo, a trip to London, how to sort out things with Clarity, and other arrangements.\nSet up RDSF data storage (Though I checked, OneDrive for Business offers 2TB of storage: Overview of OneDrive for Business)\nBrief plan discussion: reading Mary Coe’s thesis, then Understanding Molecular Simulation book\nAre there MSci students working on this project?",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-4",
    "href": "meetings.html#week-4",
    "title": "Project Meetings",
    "section": "Week 4",
    "text": "Week 4\n\n2024/10/7 Things to discuss\n\nOverleaf template for the thesis, as I will start writing what I learn for either the introduction or theory sections. Found one: Link\n\n\n\n2024/10/7 After project meeting\nCase study 4 from the molecular simulation book, p. 98\nAnd change to fix nvt command for LAMMPS\nMaria’s thesis: read the first part",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-5",
    "href": "meetings.html#week-5",
    "title": "Project Meetings",
    "section": "Week 5",
    "text": "Week 5\n\n2024/10/12 Making a presentation\n241016 Overleaf Presentation for Project Meeting\n\n\n2024/10/16 Project meeting\n\n\n\nCritical drying",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-6",
    "href": "meetings.html#week-6",
    "title": "Project Meetings",
    "section": "Week 6",
    "text": "Week 6\n\n2024/10/23 Molsim-2025 School Application\nMolSim-2025 is 2-week school that offers a program focusing on basic and advanced molecular simulation methods. It targets PhD candidates and postdoctoral researchers who want to understand and apply these methods to study topics in physics, chemistry or biology. The program has an integrated and balanced structure of lectures and hands-on exercises. It offers a recap of the basic theory relevant for molecular simulation, followed by a thorough covering of basic and advanced simulation techniques. All techniques will be accompanied by illustrative examples of present day research.\n\nMy application (submitted on 241023)\nI am a PhD student in theoretical and computational physics at the University of Bristol, specialising in the simulation of surface phase transitions with a focus on active matter using high-performance computing. My supervisors are Nigel Wilding, who has strongly recommended this winter school and has done substantial work on developing efficient algorithms for MC simulations [1-4], and Francesco Turci, who specialises in disordered systems. My initial project involves investigating drying (surface) phase transitions using Monte Carlo and molecular dynamics techniques, introducing an additional parameter to how they approached the problem in PRL 2021 [5].\nI am highly motivated to join this winter school since it is my first year of PhD studies and also my first time learning how to conduct molecular simulations. I am currently reading the book Understanding Molecular Simulation to grasp the methodologies, and I was very excited by the fact that the authors of this book will be present for the lectures. Even though this book is enjoyable to read, many concepts within it are quite new to me, so it will be a great opportunity to deepen my knowledge in this area and meet colleagues with similar interests. The latter reason is also very important since I am the only PhD student learning models of active particles for surface phase transitions in my department.\nPlease let me know if you would like me to send my CV. For now, I have attached my personal statement, which I submitted for my PhD application, showing my dynamic and multifaceted experience. I hope this wonderful opportunity will materialise.\n\n[1] N.B. Wilding, A.D. Bruce, Density fluctuations and field mixing in the critical fluid, J. Phys. Condens. Matter 4 (12) (1992) 3087–3108\n[2] N.B. Wilding, Critical point and coexistence curve properties of the Lennard-Jones fluid: a finite-size scaling study, Phys. Rev. E 52 (1) (1995) 602–611\n[3] A.D. Bruce, N.B. Wilding, G.J. Ackland, Free energy of crystalline solids: a lattice-switch Monte Carlo method, Phys. Rev. Lett. 79 (16) (1997) 3002–3005\n[4] S. Consta, N.B. Wilding, D. Frenkel, Z. Alexandrowicz, Recoil growth: an efficient simulation method for multi-polymer systems, J. Chem. Phys. 110 (6) (1999) 3220–3228\n[5] F. Turci, N.B. Wilding, Phase separation and multibody effects in three-dimensional active Brownian particles, Phys. Rev. Lett. 126.3 (2021) 038002.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-7",
    "href": "meetings.html#week-7",
    "title": "Project Meetings",
    "section": "Week 7",
    "text": "Week 7\n\n2024/10/28 Things to discuss\n\nAsk about page 51 on Molecular Dynamics Simulation showing notes written on Zotero.\n\n\n\n2024/10/28 Project meeting\n\n\n\nProgramming",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-8",
    "href": "meetings.html#week-8",
    "title": "Project Meetings",
    "section": "Week 8",
    "text": "Week 8\n\n2024/11/4 Things to discuss\nThe meaning of our project\nI’m afraid to say I’m not exactly certain about the importance of our initial project. To me, a naive student who has just finished my undergraduate in physics, physics operates by explaining experimental results in mathematical language. As a few examples,\n\nIn the early 20th century, we realised that classical physics could not explain the ultraviolet catastrophe. So Planck suggested that light exists in quanta to explain the spectra we observe, which later led to Bohr’s theory of electron orbits. Furthermore, when classical electrodynamics dictated that an orbiting electron around the nucleus should radiate energy and spiral inward, the new language of quantum mechanics was formulated to explain the stability of atoms. This process of experimental results leading to theoretical explanations, which further lead to contradictions with existing theories, gives birth to new frameworks that unite our understanding.\nThe Michelson–Morley experiment investigating the existence of the ether disproved their hypothesis, supporting the constancy of the speed of light, \\(c\\). This result led Einstein to create a theory which completely changed the very meanings of our familiar, intuitive concepts: space and time. Another example of how experimental results led to the unification of our understanding; for example, magnetism can be understood as electricity in special relativity.\nEven in statistical physics, the phase diagram of water has been known for a long time, but the critical point wasn’t understood until the mid to late 20th century. It was not until Ken Wilson formulated the renormalisation group to explain this by rescaling physical theories (which I find one of the most beautiful results in theoretical physics).\n\nI have chosen the active matter project because it’s a framework that makes the most sense to me, due to my keen interest in philosophy throughout the years, which has made me already familiar with the active matter paradigm shift. If I describe briefly,\n\nThe reason that Newtonian mechanics completely altered how scientific disciplines have progressed is because I believe it gave us what it means by our ‘understanding’. Before Newton, Ptolemy’s circles and epicycles could fully explain the orbits of planetary bodies. However, we don’t consider this as ‘understanding’ the underlying mechanism because what Ptolemy did was to focus only on motions. What Newton did, on the other hand, was to identify the ‘cause’ of motion, which is force. By introducing that concept, he was able to derive his simple equation of universal gravity, which applies to many different things, not just planetary bodies, but also projectiles, pendulums, etc. So by his theory, we were able to unite many phenomena that we observe into one unified framework.\nHowever, he still couldn’t explain how these forces arise, so he devised what are called ‘active principles’. I could elaborate further, but I shall stop here. The important thing about this new revelation was that, from the Newtonian way of thinking, we conceived matter as passive and forces as active. We thought of matter as inert, dead, inanimate. No wonder the physicalist view in biology had failed by the end of the 19th century, which led to the ‘century of the gene’ in the 20th century, explaining everything in terms of gene expression. However, thinking only about genes couldn’t explain many things in biology such as: what is the difference between animate and inanimate things? Why are there many phenotypes from the same genotype? So what Thomas Huxley hoped for at the end of the 19th century, the physical language to explain biological matter, has resurfaced at the beginning of the 21st century with the emergence of active matter, where soft matter physicists could contribute. All in all, at Oxford University, there is the phrase: ‘Biology is soft matter come alive’. I would interpret it as ‘active’, though.\n\nThe significance of this new way of thinking is apparent to me. However, what is not clear is how observing a drying transition by active particles contributes to our understanding of drying phenomena. The reason I kept asking about real life examples is because I wasn’t sure if our results (if we observe drying) would explain the experimental results that need to be explained. If there are such cases, this would be recognised as our correct understanding of drying phenomena, which leads us to think that moving out of equilibrium statistical physics is a more reasonable direction. Since we are dealing with such limited, specific systems where liquid and vapour coexist, which is already quite rare in nature, for this project meeting, I hoped to gain more understanding of the significance of our project.\n\n\n2024/11/8 Messages from Francesco\n\nHi Sohyun, given what you told me, you may want to have a look at the attached reference (see (Hagen, Teeffelen, and Löwen 2011)), which discusses in detail the properties of (isolated) ABPs.\n\nHagen, Borge ten, Sven van Teeffelen, and Hartmut Löwen. 2011. “Brownian Motion of a Self-Propelled Particle.” Journal of Physics: Condensed Matter 23 (19): 194119.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-10",
    "href": "meetings.html#week-10",
    "title": "Project Meetings",
    "section": "Week 10",
    "text": "Week 10\n\n2024/11/18 Things to discuss\n\nI can mention that I’m not particularly interested in surface phase transitions unless there is a link to my vape (see 2024/11/14 - Skimming through papers).\nI can also discuss the way I work, such as deriving mathematical equations and explaining how much beauty I perceive in those equations (see 2024/11/17 The Moment of My Realisation).\nAt the moment, I’m still exploring which project I would like to pursue for the next four years. When I was doing my MSci research, I felt so restless and excited, deeply engaged with all the required literature, like a sponge absorbing everything! Now, I don’t feel the same enthusiasm for my specific project. That said, I’m reading Active Particles in Complex and Crowded Environments (Bechinger et al. (2016)) because it appears to be a good review of this field, readable and offering insights into future directions.\n\n\nBechinger, Clemens, Roberto Di Leonardo, Hartmut Löwen, Charles Reichhardt, Giorgio Volpe, and Giovanni Volpe. 2016. “Active Particles in Complex and Crowded Environments.” Reviews of Modern Physics 88 (4): 045006.\n\n\n2024/11/20 Messages from Nigel\n\nStephen Clark told me about this:\nhttps://chatgpt.com/g/g-NWXFRfEKx-paper-navigator\nProbably you’ve seen it already.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-11",
    "href": "meetings.html#week-11",
    "title": "Project Meetings",
    "section": "Week 11",
    "text": "Week 11\n\n2024/11/28 Critical Casimir Effect\nFrom our project meeting, Nigel introduced another possible project: the critical Casimir effect in active fluids. The Casimir effect is probably one of the most important effects in physics along with the Aharonov-Bohm effect, the Hall effect, the Meissner effect (which I can’t remember the name exactly, but it describes that magnetic field lines cannot enter a superconductor), the Doppler effect, and, of course, the photoelectric effect.\nThe reason the Casimir effect is so interesting is this: everybody knows that two metal plates will attract to each other if one is positively charged and the other negatively charged. Somehow, plates also attract each other even if they are uncharged! This is the essence of the Casimir effect, named after Hendrik Casimir (see Wikipedia - Casimir effect). It basically arises due to quantum fluctuations, which create a pressure difference: the pressure between the plates is lower than outside, so the two plates are pushed towards each other. However, the force from the Casimir effect is very weak and can be measured only at very short distances.\nCritical Casimir effect is a classical analogue of this quantum phenomenon, occurring in systems near a critical point of a phase transition. At criticality, the correlation length of fluctuations in an order parameter (such as density or magnetisation) diverges, leading to long-range correlations. When a critical fluid is confined between boundaries, such as two walls, the boundaries modify these fluctuations, imposing constraints that result in an effective force between the walls. This force is mediated by the critical fluctuations and depends on factors like the boundary conditions (e.g., symmetry breaking or preservation) and the distance between the boundaries.\nHow does this effect relate to active fluids? I found this paper: Casimir effect in active matter systems by Ray, Reichhardt, and Reichhardt (2014)\n\nRay, D, C Reichhardt, and CJ Olson Reichhardt. 2014. “Casimir Effect in Active Matter Systems.” Physical Review E 90 (1): 013019.\nOh my god, this is actually very interesting!",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-12",
    "href": "meetings.html#week-12",
    "title": "Project Meetings",
    "section": "Week 12",
    "text": "Week 12\n\n2024/11/28 Questions\n(Postponed to Week 12 Project Meeting)\n\nI’m using mpirun -np 16 ~/mylammps/src/lmp_mpi -in drying-2D.lmp, but it’s still slow, and 32 is often not available. Did it also take this long?\n\n\n---------------------------------------------------------------  \nLoop time of 1437.69 on 16 procs for 2,500,001 steps with 7,200 atoms  \n\nPerformance: 751,203.143 tau/day, 1,738.896 timesteps/s, 12.520 Matom-step/s  \n98.6% CPU use with 16 MPI tasks x no OpenMP threads  \n\nMPI task timing breakdown:  \nSection | Min Time  | Avg Time  | Max Time  | %varavg | %total  \n---------------------------------------------------------------  \nPair    | 6.237      | 31.572     | 88.773     | 591.0   |  2.20  \nNeigh   | 1.8579     | 5.9445     | 14.931     | 214.1   |  0.41  \nComm    | 28.584     | 70.366     | 125.07     | 444.4   |  4.89  \nOutput  | 14.731     | 116.78     | 270.86     | 803.0   |  8.12  \nModify  | 185.53     | 424.09     | 970.39     | 1,533.8 | 29.50  \nOther   |            | 788.9      |            |         | 54.88  \n\nNlocal:            450 ave        1,086 max         147 min  \nHistogram: 8 2 0 1 0 1 0 0 1 3  \nNghost:           85.5 ave         201 max          26 min  \nHistogram: 8 0 2 0 1 1 0 0 2 2  \nNeighs:        1,040.62 ave      3,214 max          81 min  \nHistogram: 9 1 0 1 0 1 0 0 1 3  \n\nTotal # of neighbors = 16,650  \nAve neighs/atom = 2.3125  \nNeighbor list builds = 106,669  \nDangerous builds = 0  \nTotal wall time: 0:23:57  \n---------------------------------------------------------------  \n\nIn the code of wetting-2D.lmp, I used variable friction equal 50  # translational friction coefficient, as I saw in equilibrate.lmp, but is there a specific reason for this value?\nI changed from min_style fire to min_style cg as the system is immediately unstable:\n\n\n—  \nSetting up FIRE-style minimization ...  \n  Unit style    : lj  \n  Current step  : 0  \n  Parameters for FIRE:  \n    dmax  delaystep dtgrow dtshrink alpha0 alphashrink tmax tmin   integrator   halfstepback   abcfire  \n     0.1     20      1.1     0.5     0.25     0.99      10  0.02 eulerimplicit      yes          no  \n\nPer MPI rank memory allocation (min/avg/max) = 3.857 | 3.858 | 3.858 Mbytes  \n\n   Step          Time        v_tscaled        PotEng        Density         Press     \n         0   0              0              1.7111115e+25  0.5            5.1333344e+25  \nERROR: Lost atoms: original 7,200 current 4,594 (../thermo.cpp:494)  \nLast command: minimize 1.0e-9 1.0e-9 1,000 1,000  \n--------------------------------------------------------------------------  \n\n`prterun` detected that one or more processes exited with non-zero status,  \nthus causing the job to be terminated. The first process to do so was:  \n\n   Process name: [prterun-bp1-login01-2890156@1,14] Exit code:    1  \n--------------------------------------------------------------------------  \nI’m not sure how to make it work with FIRE.\n(11/31 update: I added overlap ${sigma} as an argument.)\n\nAlso, your fix_abp2d.cpp needed to be changed since all particles moved to the right at first (check the before-correction folder). There are some changes I made; search for // correction!. Also, it wasn’t renormalised like 3D, so I renormalised when doing integration.\nWhat’s the reason you assigned lj/cut as 3.0? Is it to do with coordination shells? And what is v_tscaled in thermo data? Also, since thermo data produces such a huge file, I excluded saving time and pressure. Do we need these at some point?\nTo calculate the asymmetry order parameter, how should I allow the system to relax to collect statistics? For dumps/test/wet.ew.20.ly.120.gz, it seems to roughly relax after 4 million time steps to induce the asymmetric steady state. (The time taken to relax is a lot shorter in higher potential to induce a symmetric steady state.)\nAs noted in the paper, for values less than ew=30, the system quickly becomes unstable. How can I make my code stable?\n\nFor (1), it is now (24/12/02) a lot faster with reduced information being saved:\n---------------------------------------------------------------  \nLoop time of 1,275.74 on 16 procs for 2,500,001 steps with 14,400 atoms  \n\nPerformance: 846,568.754 tau/day, 1,959.650 timesteps/s, 28.219 Matom-step/s  \n99.4% CPU use with 16 MPI tasks x no OpenMP threads  \n\nMPI task timing breakdown:  \nSection | Min Time  | Avg Time  | Max Time  | %varavg | %total  \n---------------------------------------------------------------  \nPair    | 37.333     | 68.22      | 89.448     | 209.4   |  5.35  \nNeigh   | 8.6982     | 12.866     | 15.493     |  63.5   |  1.01  \nComm    | 54.905     | 77.189     | 110.42     | 201.1   |  6.05  \nOutput  | 4.0046     | 31.432     | 60.902     | 334.9   |  2.46  \nModify  | 747.32     | 845.8      | 928.32     | 157.5   | 66.30  \nOther   |            | 240.2      |            |         | 18.83  \n\nNlocal:            900 ave        1,317 max         491 min  \nHistogram: 1 1 0 1 5 5 1 0 1 1  \nNghost:        196.812 ave        269 max          69 min  \nHistogram: 2 1 0 2 1 0 1 0 3 6  \nNeighs:        2,118.69 ave      3,876 max         488 min  \nHistogram: 3 2 0 1 0 1 7 0 1 1  \n\nTotal # of neighbors = 33,899  \nAve neighs/atom = 2.3540972  \nNeighbor list builds = 112,125  \nDangerous builds = 0  \nTotal wall time: 0:21:16  \n---------------------------------------------------------------  \n\n\n2024/12/02 Project meeting\n\n\n\nFluctuation Theorem 1\n\n\n\n\n\nFluctuation Theorem 2\n\n\n\n\n\nFluctuation Theorem 3\n\n\n\n\n2024/12/3 After project meeting\n\nFor friction = 50, it boils down to how far a single particle moves in a single step of the self-propulsion force. For example, if it moves too far, it may not resolve the collision in a very dense system because the particle cannot observe the true collisions. Otherwise, it jumps across, which is not physical.\nHe mentioned this paper (which is cited by the SM paper) but couldn’t find anything about that specific choice of friction: https://iopscience.iop.org/article/10.1088/1367-2630/aa9d4b/pdf.\nHe said I don’t need minimisation anymore since particles are spaced without overlapping using overlap ${sigma}.\nFor pair_style lj/cut 3.0, LAMMPS checks how large the cutoff is for calculating the neighbour list. Then we use a smaller cutoff where the potential is truncated (or shifted) by the next commands. Setting it to just \\({r_c}\\) instead of 3.0 could be risky for ensuring correct calculations of neighbours. The number can be checked by seeing if the dynamics do not depend on the cutoff (e.g., obtaining the same trajectory, energies, etc.). 3.0 was an overcautious choice, but it’s good to be cautious. For example, neigh_modify every 1 delay 0 check yes ensures the neighbour list is checked every step. This is important because if a particle travels a long way, it could suddenly move into the dilute phase, especially if it’s likely an interfacial particle. Therefore, we need to keep the timestep small and make an extra neighbour list so that the results don’t depend on specific choices.\nRegarding tscaled, he said LJ units do not matter as much as in the case of equilibrium. So we are using this different, interesting timescale.\nNobody has a perfect answer for when the steady state happens. If some statistical features converge (or appear asymptotic), we might see that the system has passed the relaxation time. The good thing is that even if the initial conditions are different (e.g., by assigning a different seed that produces slightly different time evolution), the characteristic relaxation time remains fixed. Without special methods, it’s very difficult to know where the actual transition point is. However, the entire point is that there can be memory effects, where something does not change for some time. Away from the transition itself, I can have a reasonable estimate of the relaxation time.\nHe also said that to estimate whether the system is in the steady state or not, we can look at the energy because the energy is related to the number of neighbours particles have. He didn’t specifically have a systematic way of determining \\(\\tau_c\\) for all different trajectories. For example, he doesn’t have \\(\\tau_c\\) vs \\(\\epsilon\\), which he said is something I can investigate. He estimated \\(\\tau_c\\), then took a larger order of magnitude (like 10 times that value) to be safe. Beyond that, he collected the statistics.\nWhen they said the system becomes unstable in their paper, they meant the droplet detaches from the barrier, not the simulation. He said a ‘lost atoms’ error can’t really happen with small \\(\\epsilon\\) unless it’s a very large \\(\\epsilon\\). He said I should reduce \\(dt\\).",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-13",
    "href": "meetings.html#week-13",
    "title": "Project Meetings",
    "section": "Week 13",
    "text": "Week 13\n\n2024/12/9 Things to discuss\n\nMolsim is not successful. Should I ask them if I could be on the waiting list? Are there any active matter schools?\n\nOther schools:\nCCP5 Summer School\n\nInterfacial Soft Matter: Mechanics, Physical Chemistry and Interactions\n\nJune 8 - June 13, 2025\n\nHan-sur-Lesse Winterschool (in summer) on ‘Soft matter and biological physics’\n\nJune 16 – 20, 2025\n\n2025 IHES Summer School - Statistical Aspects of Nonlinear Physics\n\nJune 23 - July 4, 2025\n\n\n\nAre both of you leaving in the winter? It seems everyone is leaving for holidays after around the 20th.\nI think something is a bit confusing in the paper. Within SM, \\(L_x\\) is fixed as 240\\(\\sigma\\) as the total system size in the \\(x\\)-direction while varying \\(L_y\\) to 30, 60, 100, 120, …, 180\\(\\sigma\\). However, within the letter, in Fig. 2, it says \\(L_x = 120\\sigma\\) as well as saying \\(L_y = 60\\sigma\\) on page 3 (search in fact, the formation of bubbles that span the system parallel to the barrier was observed for systems of sizes up to \\(L_y = 60\\sigma\\)), which I believe should be written as \\(L_x = 240\\sigma\\) and \\(L_y = 120\\sigma\\), respectively, considering the context.\n\n\n\n2024/12/10 After project meeting\n\nRegarding 1\nHe said the relevance to my project would be 2 &gt; 1 &gt; 3, but number 2 seems to only allow Dutch students to join, so I should email them to clarify. I can still ask to be on the waiting list for MolSim, but he said it’s better to keep it aside for now.\n\n\nRegarding 2\nLast meeting this year: 16th Dec\nFirst meeting next year: 6th Jan\n\n\nRegarding 3\nMessages from Teams chat\n\nNigel: Hi Francesco, Sohyun had a question which, if I understood correctly, is the following: Imagine I am close to the transition from the wet state to the partially wet state, i.e., in the regime where the asymmetry order parameter is changing rapidly. In this region, the slab can fluctuate between asymmetric and symmetric configurations with respect to the barrier (we are in 2D). How does one measure the asymmetry order parameter? I guess one simply does a simple average over a long trajectory; you don’t confine the average to certain types of configurations. So the ability to transition from one state of symmetry to another in 2D is why the order parameter doesn’t take on a large value in the partial wetting regime.\nAnother question is what happens if there is an unbinding event during a trajectory, so the slab wanders off. Presumably, one shouldn’t include such trajectories in the average because they are doing something unrelated to the wetting behaviour…?\n\n\nFrancesco:\n1. Yes, the average is not confined to certain types of configurations. It is just a long-time average.\n2. If I remember correctly, the unbinding was monitored with quick space-time plots of the density profiles. The unbinding trajectories were discarded. This also gave me a sense of where to stop with decreasing epsilon (if there are no stable trajectories, it is over).\n\nMessages from Francesco\n\nHi Sohyun, I guess you must be right about the \\(L_x = 240\\) in 2D, as it seems to be the case also in Fig. 4. I will need to dig out the original scripts, but it seems that I clearly have used these large systems! Obviously, larger systems dampen the fluctuations, but they also take a long time to simulate…\n\n\nThis looks good! I only use Ovito Basic (the license is so expensive), but you can use the Python package Ovito if you want to do more. We can talk about it (once I am done with the enormous amount of marking I have now!).\n\n\nI have had a look at the stored data for 2D, and I found:\n- That the data plotted in the paper is averaged over many realisations (i.e. different seeds for the random number generator).\n- That in 2D for high epsilon, you can see some realisations jumping up and down roughly in the range that you showed me yesterday over 1000 \\(\\tau_r\\), while others jump less. In fact, this reminded me of the difficulties we had in assessing the order of the transition in 2D: I have apparently stored many space-time plots to check the trajectories and the intermittency, but we never truly got a single simple explanation. Comparing 2D with 3D, we realised that the interfaces in 2D have a characteristic dynamics, and all the bubble formation (that we essentially do not see in 3D) triggers these instabilities. We may want to sit down with Nigel and think about it carefully: on the one hand, the peculiar large fluctuations of the 2D dynamics seem to help with the formation of the gas in the vicinity of the barrier (good for drying), but it also introduces additional timescales (e.g. the slow relaxation that I show in the quench figures in the paper).\n\nAfter this…\n\nFrancesco: Well done for managing all these initial steps. They (sub2d.sh and sub3d.sh) look good to me. Obviously, you can have more than one job running, so for 3D, you could have submitted independent epsilon runs if you wanted.\n\n\nMe: Oh! I wanted to be merciful to others, but I’ll do it once it’s very urgent!\n\n\nFrancesco: Exactly. Do not worry about the others; the system manages that.\n\n\nMe: How many CPUs did you use in the past?\n\n\nFrancesco: I was on Catalyst, which was very different in its architecture… By the way, did you check that you always have 64 cores? I do not remember if BlueCrystal always has 64 cores per node. Blue Pebble, actually, right?\n\n\nMe: Yes, Blue Pebble. If I copy the relevant information from Slurm:\n\nCreated orthogonal box = (-50 -12 -12) to (50 12 12)\n  16 by 2 by 2 MPI processor grid\nCreated 43200 atoms\n  using lattice units in orthogonal box = (-50 -12 -12) to (50 12 12)\n  create_atoms CPU = 3.492 seconds\n \nLoop time of 20254.7 on 64 procs for 25000000 steps with 43200 atoms\n \nPerformance: 533209.921 tau/day, 1234.282 timesteps/s, 53.321 Matom-step/s\n99.4% CPU use with 64 MPI tasks x no OpenMP threads\n\nFrancesco: Well, this is LAMMPS; it does not truly tell what the machine has. Some CPUs can create virtual “processes” even if the physical cores are fewer. I typed:\nsinfo --Node --long\nIt seems that most have 64. Some are 48, though. Hopefully, you always get the ones you request! I’ll go back to my biophysics marking, but well done on progressing.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-1",
    "href": "meetings.html#week-1",
    "title": "Project Meetings",
    "section": "",
    "text": "Do I need to upload content to Pure?\n\nHow do I claim my research allowance?\n\nAre there any lectures recommended to audit?\n\nCan I work from home until I recover?",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-2",
    "href": "meetings.html#week-2",
    "title": "Project Meetings",
    "section": "Week 2",
    "text": "Week 2\n\n2024/9/24 My Research Allowance\nIf I don’t spend £2000 per year, it will be lost.\nSo I can pay my IOP.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "notes.html#week-12",
    "href": "notes.html#week-12",
    "title": "Weekly Notes",
    "section": "Week 12",
    "text": "Week 12\n\n2024/12/6 Learn\nhttps://www.acrc.bris.ac.uk/protected/hpc-docs/training/intro-to-linux/14_task01.html\nExplanation for fix codes:\n\nhttps://chatgpt.com/share/675260ec-86a0-800e-a845-5ad713be6d20\n\n\n\n  Enter password to view the content:\n  \n  Submit",
    "crumbs": [
      "Project Notes",
      "Weekly Notes"
    ]
  },
  {
    "objectID": "computations.html",
    "href": "computations.html",
    "title": "Computations",
    "section": "",
    "text": "The localised external potential added to the system (Turci and Wilding 2021):\n\nTurci, Francesco, and Nigel B. Wilding. 2021. “Wetting Transition of Active Brownian Particles on a Thin Membrane.” Physical Review Letters 127 (23): 238002. https://doi.org/10.1103/PhysRevLett.127.238002.\n\nV_{\\text{ext}}(x) = \\varepsilon_w \\left[ \\cos\\left(\\frac{\\pi x}{d}\\right) + 1 \\right] \\times H(d - x) H(x + d),\n\\tag{1.1}\nwhere H(x) is the Heaviside function, d = \\sigma, and \\varepsilon_w represents the repulsive barrier strength.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\nsigma = 1.0  # Particle diameter\nd = sigma    # Barrier width\new_values = np.arange(20, 55, 5)  # Barrier strength values from 20 to 50 incrementing by 5\n\n# Define the potential function\ndef V_ext(x, epsilon_w, d):\n    H = lambda x: np.heaviside(x, 0.5)  # Heaviside step function\n    return epsilon_w * (np.cos(np.pi * x / d) + 1) * H(d - x) * H(x + d)\n\n# x range\nx = np.linspace(-2 * d, 2 * d, 500)\n\n# Plot\nplt.figure(figsize=(10, 6))\nfor ew in ew_values:\n    V = V_ext(x, ew, d)\n    plt.plot(x, V, label=f\"$\\\\epsilon_w = {ew}$\")\n\nplt.axvline(-d, color='gray', linestyle='--', label=r\"$x = -d$\", linewidth=0.8)\nplt.axvline(d, color='gray', linestyle='--', label=r\"$x = d$\", linewidth=0.8)\nplt.axhline(0, color='black', linewidth=0.5)\nplt.xlabel(\"$x$\", fontsize=12)\nplt.ylabel(\"$V_{\\\\text{ext}}(x)$\", fontsize=12)\nplt.legend(fontsize=10, loc='upper right')\nplt.grid(alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1.1: External potential V_{\\text{ext}}(x) for different \\epsilon_w\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIntermediate values can be thought of as representing a thin porous membrane with nonzero crossing probability.\n\n\n\n\nCallout tip\n\n\n\n\n\n\n\nTip\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important.",
    "crumbs": [
      "Project Notes",
      "Computations"
    ]
  },
  {
    "objectID": "computations.html#colors",
    "href": "computations.html#colors",
    "title": "Quarto Document",
    "section": "1.1 Colors",
    "text": "1.1 Colors\n\nRed\nGreen\nBlue",
    "crumbs": [
      "Project Notes",
      "Quarto Document"
    ]
  },
  {
    "objectID": "computations.html#shapes",
    "href": "computations.html#shapes",
    "title": "Quarto Document",
    "section": "1.2 Shapes",
    "text": "1.2 Shapes\n\nSquare\nCircle\nTriangle",
    "crumbs": [
      "Project Notes",
      "Quarto Document"
    ]
  },
  {
    "objectID": "computations.html#textures",
    "href": "computations.html#textures",
    "title": "Quarto Document",
    "section": "1.3 Textures",
    "text": "1.3 Textures\n\nSmooth\nBumpy\nFuzzy",
    "crumbs": [
      "Project Notes",
      "Quarto Document"
    ]
  },
  {
    "objectID": "computations.html#equations",
    "href": "computations.html#equations",
    "title": "Computations",
    "section": "2.1 Equations",
    "text": "2.1 Equations\nThe localised external potential added to the system (Turci and Wilding 2021):\n\nTurci, Francesco, and Nigel B. Wilding. 2021. “Wetting Transition of Active Brownian Particles on a Thin Membrane.” Physical Review Letters 127 (23): 238002. https://doi.org/10.1103/PhysRevLett.127.238002.\n\nV_{\\text{ext}}(x) = \\varepsilon_w \\left[ \\cos\\left(\\frac{\\pi x}{d}\\right) + 1 \\right] \\times H(d - x) H(x + d),\n\\tag{2.1}\nwhere H(x) is the Heaviside function, d = \\sigma, and \\varepsilon_w represents the repulsive barrier strength.",
    "crumbs": [
      "Project Notes",
      "Computations"
    ]
  },
  {
    "objectID": "computations.html#sec-plot",
    "href": "computations.html#sec-plot",
    "title": "Computations",
    "section": "2.2 Plot",
    "text": "2.2 Plot\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Parameters\nsigma = 1.0  # Particle diameter\nd = sigma    # Barrier width\new_values = np.arange(20, 55, 5)  # Barrier strength values from 20 to 50 incrementing by 5\n\n# Define the potential function\ndef V_ext(x, epsilon_w, d):\n    H = lambda x: np.heaviside(x, 0.5)  # Heaviside step function\n    return epsilon_w * (np.cos(np.pi * x / d) + 1) * H(d - x) * H(x + d)\n\n# x range\nx = np.linspace(-2 * d, 2 * d, 500)\n\n# Plot\nplt.figure(figsize=(10, 6))\nfor ew in ew_values:\n    V = V_ext(x, ew, d)\n    plt.plot(x, V, label=f\"$\\\\epsilon_w = {ew}$\")\n\nplt.axvline(-d, color='gray', linestyle='--', label=r\"$x = -d$\", linewidth=0.8)\nplt.axvline(d, color='gray', linestyle='--', label=r\"$x = d$\", linewidth=0.8)\nplt.axhline(0, color='black', linewidth=0.5)\nplt.xlabel(\"$x$\", fontsize=12)\nplt.ylabel(\"$V_{\\\\text{ext}}(x)$\", fontsize=12)\nplt.legend(fontsize=10, loc='upper right')\nplt.grid(alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2.1: External Potential V_{\\text{ext}}(x) for Different \\epsilon_w\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIntermediate values can be thought of as representing a thin porous membrane with nonzero crossing probability.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that there are five types of callouts, including: note, tip, warning, caution, and important.",
    "crumbs": [
      "Project Notes",
      "Computations"
    ]
  },
  {
    "objectID": "computations.html#sec-equation",
    "href": "computations.html#sec-equation",
    "title": "Computations",
    "section": "2.1 Equation",
    "text": "2.1 Equation\n\ns = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2}\n\\tag{2.2}",
    "crumbs": [
      "Project Notes",
      "Computations"
    ]
  },
  {
    "objectID": "computations.html#equations-1",
    "href": "computations.html#equations-1",
    "title": "Computations",
    "section": "2.2 Equations",
    "text": "2.2 Equations\nThe localised external potential added to the system:\n\nV_{\\text{ext}}(x) = \\varepsilon_w \\left[ \\cos\\left(\\frac{\\pi x}{d}\\right) + 1 \\right] \\times H(d - x) H(x + d),\n\nwhere H(x) is the Heaviside function, d = \\sigma, and \\varepsilon_w represents the repulsive barrier strength.\n\nThis will render properly in Markdown with MathJax support, such as in Quarto. Let me know if you need further clarification or adjustments!",
    "crumbs": [
      "Project Notes",
      "Computations"
    ]
  },
  {
    "objectID": "computations.html#compute-property-modifier",
    "href": "computations.html#compute-property-modifier",
    "title": "Computations",
    "section": "4.1 Compute Property Modifier",
    "text": "4.1 Compute Property Modifier\nTo calculate a meaningful local density, I used the Coordination Number (from the Coordination Analysis) and converted it into density. The neighbor cutoff radius used in LAMMPS for the neighbor list is 1.422462 (derived as r_c = 2^{1/6} \\cdot \\sigma + 0.3, where 0.3 is the buffer added in the neighbor list: neighbor 0.3 bin).\n\nThe local density can be defined as: \n\\rho_{\\text{local}} = \\frac{\\text{Coordination Number}}{\\frac{4}{3} \\pi r_c^3}\n where r_c = 1.422462 is the cutoff radius. The denominator is the volume of a sphere with radius r_c, representing the local volume used for density estimation.\nSo, I filled in the Expression field with:\nCoordination / (4/3 * pi * 1.422462^3)\n\n\n\n\nModifcations",
    "crumbs": [
      "Project Notes",
      "Computations"
    ]
  },
  {
    "objectID": "meetings.html#messages-from-francesco",
    "href": "meetings.html#messages-from-francesco",
    "title": "Project Meetings",
    "section": "2024/11/08 Messages from Francesco",
    "text": "2024/11/08 Messages from Francesco\nHi Sohyun, given what you told me, you may want to have a look at the attached reference (Hagen, Teeffelen, and Löwen 2011) which discusses in detail teh properties of (isolated) ABPS\n\nHagen, Borge ten, Sven van Teeffelen, and Hartmut Löwen. 2011. “Brownian Motion of a Self-Propelled Particle.” Journal of Physics: Condensed Matter 23 (19): 194119.",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  },
  {
    "objectID": "meetings.html#week-9",
    "href": "meetings.html#week-9",
    "title": "Project Meetings",
    "section": "Week 9",
    "text": "Week 9\n\n2024/11/12 Teams chat\n\nFrancesco: Hi Sohyun, here are the draft notes on the Langevin equations that I mentioned earlier: they contain proofs for most of the key steps but also some minimal code to show you how the maths provides you with an algorithm to integrate such stochastic processes. The book is not complete (yet), but the relevant part on stochastic processes at equilibrium essentially is.\nhttps://atooms.frama.io/handbook/html/contents/langevin.html\n\n\nNigel: https://www.youtube.com/live/TmWuOZJlRE0\n\n\nFrancesco: I know the hexbugs; I wanted to buy some for teaching demonstrations (or open days…). I think the fact that they do not have an equation of state (differently from ABPs) makes things much more complicated, but it may be unavoidable (ABPs are indeed special).",
    "crumbs": [
      "Project Notes",
      "Project Meetings"
    ]
  }
]