---
title: Project Meetings
toc: true
bibliography: references/quarto.bib
reference-location: margin
citation-location: margin
---

## Week 1

### 2024/9/16 Questions

1. Do I need to upload content to Pure?  
2. How do I claim my research allowance?  
3. Are there any lectures recommended to audit?  
4. Can I work from home until I recover?  

## Week 2

### 2024/9/24 My Research Allowance

If I don’t spend £2000 per year, it will be lost.  
So I can pay my IOP.  

## Week 3

### 2024/9/30 Things to discuss

1. Meeting with Max on Friday at noon (4th of Oct), thinking of going to Budapest Café

2. ‘Setting Expectations’ document

3. Two conferences to join:

    • [The Dao of Complexity workshop](https://iop.eventsair.com/doc2024)

    • [The Statistical Physics of Cognition](http://complexity-physics.org/blog/2024/08/19/the-statistical-physics-of-cognition)

    So, a trip to London, how to sort out things with Clarity, and other arrangements.

4. Set up [RDSF](https://uob.sharepoint.com/sites/itservices/SitePages/filestores.aspx) data storage
(Though I checked, OneDrive for Business offers 2TB of storage: [Overview of OneDrive for Business](https://uob.sharepoint.com/sites/systemsupport/SitePages/onedrive-overview.aspx))

5. Brief plan discussion: reading Mary Coe's thesis, then *Understanding Molecular Simulation* book

6. Are there MSci students working on this project?
![MSci project proposal](images/notes/ProjectProposalsMsci2024-112.jpg)

## Week 4

### 2024/10/7 Things to discuss

1. Overleaf template for the thesis, as I will start writing what I learn for either the introduction or theory sections. Found one: [Link](https://www.overleaf.com/latex/templates/university-of-bristol-thesis-template/kzqrfvyxxcdm)

### 2024/10/7 After project meeting

Case study 4 from the molecular simulation book, p. 98  
And change to `fix nvt` command for LAMMPS  

Maria’s thesis: read the first part  

## Week 5

### 2024/10/12 Making a presentation

[241016 Overleaf Presentation for Project Meeting](https://www.overleaf.com/project/670f722528944d7d9b10009d)

### 2024/10/16 Project meeting

![Critical drying](images/meetings/241016 Critical Drying.jpg)

## Week 7

### 2024/10/28 Things to discuss

1. Ask about page 51 on *Molecular Dynamics Simulation* showing notes written on Zotero.

### 2024/10/28 Project meeting

![Programming](images/meetings/241028 Programming.jpg)

## Week 8

### 2024/11/4 Things to discuss {#sec-week8-project-meeting}

**The meaning of our project**

I'm afraid to say I'm not exactly certain about the importance of our initial project. To me, a naive student who has just finished my undergraduate in physics, physics operates by explaining experimental results in mathematical language. As a few examples,

- In the early 20th century, we realised that classical physics could not explain the ultraviolet catastrophe. So Planck suggested that light exists in quanta to explain the spectra we observe, which later led to Bohr's theory of electron orbits. Furthermore, when classical electrodynamics dictated that an orbiting electron around the nucleus should radiate energy and spiral inward, the new language of quantum mechanics was formulated to explain the stability of atoms. This process of experimental results leading to theoretical explanations, which further lead to contradictions with existing theories, gives birth to new frameworks that unite our understanding.

- The Michelson–Morley experiment investigating the existence of the ether disproved their hypothesis, supporting the constancy of the speed of light, $c$. This result led Einstein to create a theory which completely changed the very meanings of our familiar, intuitive concepts: space and time. Another example of how experimental results led to the unification of our understanding; for example, magnetism can be understood as electricity in special relativity.

- Even in statistical physics, the phase diagram of water has been known for a long time, but the critical point wasn't understood until the mid to late 20th century. It was not until Ken Wilson formulated the renormalisation group to explain this by rescaling physical theories (which I find one of the most beautiful results in theoretical physics).

I have chosen the active matter project because it's a framework that makes the most sense to me, due to my keen interest in philosophy throughout the years, which has made me already familiar with the active matter paradigm shift. If I describe briefly,

- The reason that Newtonian mechanics completely altered how scientific disciplines have progressed is because I believe it gave us what it means by our 'understanding'. Before Newton, Ptolemy's circles and epicycles could fully explain the orbits of planetary bodies. However, we don't consider this as 'understanding' the underlying mechanism because what Ptolemy did was to focus only on motions. What Newton did, on the other hand, was to identify the 'cause' of motion, which is force. By introducing that concept, he was able to derive his simple equation of universal gravity, which applies to many different things, not just planetary bodies, but also projectiles, pendulums, etc. So by his theory, we were able to unite many phenomena that we observe into one unified framework.

- However, he still couldn't explain how these forces arise, so he devised what are called 'active principles'. I could elaborate further, but I shall stop here. The important thing about this new revelation was that, from the Newtonian way of thinking, we conceived matter as passive and forces as active. We thought of matter as inert, dead, inanimate. No wonder the physicalist view in biology had failed by the end of the 19th century, which led to the 'century of the gene' in the 20th century, explaining everything in terms of gene expression. However, thinking only about genes couldn't explain many things in biology such as: what is the difference between animate and inanimate things? Why are there many phenotypes from the same genotype? So what Thomas Huxley hoped for at the end of the 19th century, the physical language to explain biological matter, has resurfaced at the beginning of the 21st century with the emergence of active matter, where soft matter physicists could contribute. All in all, at Oxford University, there is the phrase: 'Biology is soft matter come alive'. I would interpret it as 'active', though.

The significance of this new way of thinking is apparent to me. However, what is not clear is how observing a drying transition by active particles contributes to our understanding of drying phenomena. The reason I kept asking about real life examples is because I wasn't sure if our results (if we observe drying) would explain the experimental results that need to be explained. If there are such cases, this would be recognised as our correct understanding of drying phenomena, which leads us to think that moving out of equilibrium statistical physics is a more reasonable direction. Since we are dealing with such limited, specific systems where liquid and vapour coexist, which is already quite rare in nature, for this project meeting, I hoped to gain more understanding of the significance of our project.

### 2024/11/8 Messages from Francesco

> Hi Sohyun, given what you told me, you may want to have a look at the attached reference (see [@ten2011brownian]), which discusses in detail the properties of (isolated) ABPs.

## Week 9

### 2024/11/12 Teams chat

> **Francesco:** Hi Sohyun, here are the draft notes on the Langevin equations that I mentioned earlier: they contain proofs for most of the key steps but also some minimal code to show you how the maths provides you with an algorithm to integrate such stochastic processes. The book is not complete (yet), but the relevant part on stochastic processes at equilibrium essentially is.  
> [https://atooms.frama.io/handbook/html/contents/langevin.html](https://atooms.frama.io/handbook/html/contents/langevin.html)  

> **Nigel:** [https://www.youtube.com/live/TmWuOZJlRE0](https://www.youtube.com/live/TmWuOZJlRE0)  

> **Francesco:** I know the hexbugs; I wanted to buy some for teaching demonstrations (or open days...). I think the fact that they do not have an equation of state (differently from ABPs) makes things much more complicated, but it may be unavoidable (ABPs are indeed special).

## Week 10

### 2024/11/18 Things to discuss {#sec-week10-project-meeting}

1. I can mention that I’m not particularly interested in surface phase transitions unless there is a link to my vape (see [2024/11/14 - Skimming through papers](notes.qmd#sec-skimming-papers)).

2. I can also discuss the way I work, such as deriving mathematical equations and explaining how much beauty I perceive in those equations (see [2024/11/17 The Moment of My Realisation](#sec-equality-sign)).

3. At the moment, I’m still exploring which project I would like to pursue for the next four years. When I was doing my MSci research, I felt so restless and excited, deeply engaged with all the required literature, like a sponge absorbing everything! Now, I don’t feel the same enthusiasm for my specific project. That said, I’m reading *Active Particles in Complex and Crowded Environments* (@bechinger2016active) because it appears to be a good review of this field, readable and offering insights into future directions.

### 2024/11/20 Messages from Nigel

> Stephen Clark told me about this:  
> [https://chatgpt.com/g/g-NWXFRfEKx-paper-navigator](https://chatgpt.com/g/g-NWXFRfEKx-paper-navigator)  
> Probably you've seen it already.

## Week 11

### 2024/11/28 Critical Casimir Effect

From our project meeting, Nigel introduced another possible project: the critical Casimir effect in active fluids. The Casimir effect is probably one of the most important effects in physics along with the Aharonov-Bohm effect, the Hall effect, the Meissner effect (which I can’t remember the name exactly, but it describes that magnetic field lines cannot enter a superconductor), the Doppler effect, and, of course, the photoelectric effect.

The reason the Casimir effect is so interesting is this: everybody knows that two metal plates will attract to each other if one is positively charged and the other negatively charged. Somehow, plates also attract each other even if they are uncharged! This is the essence of the Casimir effect, named after Hendrik Casimir (see [Wikipedia - Casimir effect](https://en.wikipedia.org/wiki/Casimir_effect)). It basically arises due to quantum fluctuations, which create a pressure difference: the pressure between the plates is lower than outside, so the two plates are pushed towards each other. However, the force from the Casimir effect is very weak and can be measured only at very short distances.

Critical Casimir effect is a classical analogue of this quantum phenomenon, occurring in systems near a critical point of a phase transition. At criticality, the correlation length of fluctuations in an order parameter (such as density or magnetisation) diverges, leading to long-range correlations. When a critical fluid is confined between boundaries, such as two walls, the boundaries modify these fluctuations, imposing constraints that result in an effective force between the walls. This force is mediated by the critical fluctuations and depends on factors like the boundary conditions (e.g., symmetry breaking or preservation) and the distance between the boundaries.

How does this effect relate to active fluids? I found this paper: *Casimir effect in active matter systems* by @ray2014casimir

Oh my god, this is actually very interesting!

## Week 12

### 2024/11/28 Questions

(Postponed to Week 12 Project Meeting)  

1. I’m using `mpirun -np 16 ~/mylammps/src/lmp_mpi -in drying-2D.lmp`, but it’s still slow, and 32 is often not available. Did it also take this long?  
```
---------------------------------------------------------------  
Loop time of 1437.69 on 16 procs for 2,500,001 steps with 7,200 atoms  

Performance: 751,203.143 tau/day, 1,738.896 timesteps/s, 12.520 Matom-step/s  
98.6% CPU use with 16 MPI tasks x no OpenMP threads  

MPI task timing breakdown:  
Section | Min Time  | Avg Time  | Max Time  | %varavg | %total  
---------------------------------------------------------------  
Pair    | 6.237      | 31.572     | 88.773     | 591.0   |  2.20  
Neigh   | 1.8579     | 5.9445     | 14.931     | 214.1   |  0.41  
Comm    | 28.584     | 70.366     | 125.07     | 444.4   |  4.89  
Output  | 14.731     | 116.78     | 270.86     | 803.0   |  8.12  
Modify  | 185.53     | 424.09     | 970.39     | 1,533.8 | 29.50  
Other   |            | 788.9      |            |         | 54.88  

Nlocal:            450 ave        1,086 max         147 min  
Histogram: 8 2 0 1 0 1 0 0 1 3  
Nghost:           85.5 ave         201 max          26 min  
Histogram: 8 0 2 0 1 1 0 0 2 2  
Neighs:        1,040.62 ave      3,214 max          81 min  
Histogram: 9 1 0 1 0 1 0 0 1 3  

Total # of neighbors = 16,650  
Ave neighs/atom = 2.3125  
Neighbor list builds = 106,669  
Dangerous builds = 0  
Total wall time: 0:23:57  
---------------------------------------------------------------  
```

2. In the code of `wetting-2D.lmp`, I used `variable friction equal 50  # translational friction coefficient`, as I saw in `equilibrate.lmp`, but is there a specific reason for this value?  

3. I changed from `min_style fire` to `min_style cg` as the system is immediately unstable:  
```
—  
Setting up FIRE-style minimization ...  
  Unit style    : lj  
  Current step  : 0  
  Parameters for FIRE:  
    dmax  delaystep dtgrow dtshrink alpha0 alphashrink tmax tmin   integrator   halfstepback   abcfire  
     0.1     20      1.1     0.5     0.25     0.99      10  0.02 eulerimplicit      yes          no  

Per MPI rank memory allocation (min/avg/max) = 3.857 | 3.858 | 3.858 Mbytes  

   Step          Time        v_tscaled        PotEng        Density         Press     
         0   0              0              1.7111115e+25  0.5            5.1333344e+25  
ERROR: Lost atoms: original 7,200 current 4,594 (../thermo.cpp:494)  
Last command: minimize 1.0e-9 1.0e-9 1,000 1,000  
--------------------------------------------------------------------------  

`prterun` detected that one or more processes exited with non-zero status,  
thus causing the job to be terminated. The first process to do so was:  

   Process name: [prterun-bp1-login01-2890156@1,14] Exit code:    1  
--------------------------------------------------------------------------  
```

I’m not sure how to make it work with FIRE.  
(11/31 update: I added `overlap ${sigma}` as an argument.)  

4. Also, your `fix_abp2d.cpp` needed to be changed since all particles moved to the right at first (check the `before-correction` folder). There are some changes I made; search for `// correction!`. Also, it wasn’t renormalised like 3D, so I renormalised when doing integration.  

5. What’s the reason you assigned `lj/cut` as 3.0? Is it to do with coordination shells? And what is `v_tscaled` in thermo data? Also, since thermo data produces such a huge file, I excluded saving `time` and `pressure`. Do we need these at some point?  

6. To calculate the asymmetry order parameter, how should I allow the system to relax to collect statistics? For `dumps/test/wet.ew.20.ly.120.gz`, it seems to roughly relax after 4 million time steps to induce the asymmetric steady state. (The time taken to relax is a lot shorter in higher potential to induce a symmetric steady state.)  

7. As noted in the paper, for values less than `ew=30`, the system quickly becomes unstable. How can I make my code stable?  

For (1), it is now (24/12/02) a lot faster with reduced information being saved:  
```
---------------------------------------------------------------  
Loop time of 1,275.74 on 16 procs for 2,500,001 steps with 14,400 atoms  

Performance: 846,568.754 tau/day, 1,959.650 timesteps/s, 28.219 Matom-step/s  
99.4% CPU use with 16 MPI tasks x no OpenMP threads  

MPI task timing breakdown:  
Section | Min Time  | Avg Time  | Max Time  | %varavg | %total  
---------------------------------------------------------------  
Pair    | 37.333     | 68.22      | 89.448     | 209.4   |  5.35  
Neigh   | 8.6982     | 12.866     | 15.493     |  63.5   |  1.01  
Comm    | 54.905     | 77.189     | 110.42     | 201.1   |  6.05  
Output  | 4.0046     | 31.432     | 60.902     | 334.9   |  2.46  
Modify  | 747.32     | 845.8      | 928.32     | 157.5   | 66.30  
Other   |            | 240.2      |            |         | 18.83  

Nlocal:            900 ave        1,317 max         491 min  
Histogram: 1 1 0 1 5 5 1 0 1 1  
Nghost:        196.812 ave        269 max          69 min  
Histogram: 2 1 0 2 1 0 1 0 3 6  
Neighs:        2,118.69 ave      3,876 max         488 min  
Histogram: 3 2 0 1 0 1 7 0 1 1  

Total # of neighbors = 33,899  
Ave neighs/atom = 2.3540972  
Neighbor list builds = 112,125  
Dangerous builds = 0  
Total wall time: 0:21:16  
---------------------------------------------------------------  
```

### 2024/12/02 Project meeting

![Fluctuation Theorem 1](images/meetings/241202 Fluctuation Theorem 1.jpg)

![Fluctuation Theorem 2](images/meetings/241202 Fluctuation Theorem 2.jpg)

![Fluctuation Theorem 3](images/meetings/241202 Fluctuation Theorem 3.jpg)

### 2024/12/3 After project meeting  

1. For friction = 50, it boils down to how far a single particle moves in a single step of the self-propulsion force. For example, if it moves too far, it may not resolve the collision in a very dense system because the particle cannot observe the true collisions. Otherwise, it jumps across, which is not physical.  
He mentioned this paper (which is cited by the SM paper) but couldn’t find anything about that specific choice of friction: [https://iopscience.iop.org/article/10.1088/1367-2630/aa9d4b/pdf](https://iopscience.iop.org/article/10.1088/1367-2630/aa9d4b/pdf).  

2. He said I don’t need minimisation anymore since particles are spaced without overlapping using `overlap ${sigma}`.  

3. For `pair_style lj/cut 3.0`, LAMMPS checks how large the cutoff is for calculating the neighbour list. Then we use a smaller cutoff where the potential is truncated (or shifted) by the next commands. Setting it to just ${r_c}$ instead of 3.0 could be risky for ensuring correct calculations of neighbours. The number can be checked by seeing if the dynamics do not depend on the cutoff (e.g., obtaining the same trajectory, energies, etc.). 3.0 was an overcautious choice, but it’s good to be cautious. For example, `neigh_modify every 1 delay 0 check yes` ensures the neighbour list is checked every step. This is important because if a particle travels a long way, it could suddenly move into the dilute phase, especially if it’s likely an interfacial particle. Therefore, we need to keep the timestep small and make an extra neighbour list so that the results don’t depend on specific choices.  

4. Regarding `tscaled`, he said LJ units do not matter as much as in the case of equilibrium. So we are using this different, interesting timescale.  

5. Nobody has a perfect answer for when the steady state happens. If some statistical features converge (or appear asymptotic), we might see that the system has passed the relaxation time. The good thing is that even if the initial conditions are different (e.g., by assigning a different seed that produces slightly different time evolution), the characteristic relaxation time remains fixed. Without special methods, it’s very difficult to know where the actual transition point is. However, the entire point is that there can be memory effects, where something does not change for some time. Away from the transition itself, I can have a reasonable estimate of the relaxation time.  

6. He also said that to estimate whether the system is in the steady state or not, we can look at the energy because the energy is related to the number of neighbours particles have. He didn’t specifically have a systematic way of determining $\tau_c$ for all different trajectories. For example, he doesn’t have $\tau_c$ vs $\epsilon$, which he said is something I can investigate. He estimated $\tau_c$, then took a larger order of magnitude (like 10 times that value) to be safe. Beyond that, he collected the statistics.  

7. When they said the system becomes unstable in their paper, they meant the droplet detaches from the barrier, not the simulation. He said a ‘lost atoms’ error can’t really happen with small $\epsilon$ unless it’s a very large $\epsilon$. He said I should reduce $dt$.  

## Assessment Period - TB1

### 2024/12/9 Things to discuss

1. Molsim is not successful. *Should I ask them if I could be on the waiting list?* Are there any active matter schools?  

Other schools:  

[CCP5 Summer School](https://www.ccp5.ac.uk)  

[Interfacial Soft Matter: Mechanics, Physical Chemistry and Interactions](https://www.houches-school-physics.com/program/program-2025/interfacial-soft-matter-mechanics-physical-chemistry-and-interactions-1498390.kjsp?RH=1725456499536)
: *June 8 - June 13, 2025*

[Han-sur-Lesse Winterschool (in summer) on 'Soft matter and biological physics'](https://hslwinterschool.com)
: *June 16 – 20, 2025*

[2025 IHES Summer School - Statistical Aspects of Nonlinear Physics](https://indico.math.cnrs.fr/event/12319/overview)
: *June 23 - July 4, 2025* 

2. Are both of you leaving in the winter? It seems everyone is leaving for holidays after around the 20th.  

3. I think something is a bit confusing in the paper. Within SM, $L_x$ is fixed as 240$\sigma$ as the total system size in the $x$-direction while varying $L_y$ to 30, 60, 100, 120, …, 180$\sigma$. However, within the letter, in Fig. 2, it says $L_x = 120\sigma$ as well as saying $L_y = 60\sigma$ on page 3 (search *in fact, the formation of bubbles that span the system parallel to the barrier was observed for systems of sizes up to $L_y = 60\sigma$*), which I believe should be written as $L_x = 240\sigma$ and $L_y = 120\sigma$, respectively, considering the context.  

### 2024/12/10 After project meeting

#### Regarding 1

He said the relevance to my project would be 2 > 1 > 3, but number 2 seems to only allow Dutch students to join, so I should email them to clarify. I can still ask to be on the waiting list for MolSim, but he said it's better to keep it aside for now.

#### Regarding 2

Last meeting this year: 16th Dec  
First meeting next year: 6th Jan  

#### Regarding 3

<details>
<summary>Messages from Teams chat</summary>

> **Nigel:** Hi Francesco, Sohyun had a question which, if I understood correctly, is the following: Imagine I am close to the transition from the wet state to the partially wet state, i.e., in the regime where the asymmetry order parameter is changing rapidly. In this region, the slab can fluctuate between asymmetric and symmetric configurations with respect to the barrier (we are in 2D). How does one measure the asymmetry order parameter? I guess one simply does a simple average over a long trajectory; you don't confine the average to certain types of configurations. So the ability to transition from one state of symmetry to another in 2D is why the order parameter doesn't take on a large value in the partial wetting regime.  
> Another question is what happens if there is an unbinding event during a trajectory, so the slab wanders off. Presumably, one shouldn't include such trajectories in the average because they are doing something unrelated to the wetting behaviour...?

> **Francesco:**  
> 1. Yes, the average is not confined to certain types of configurations. It is just a long-time average.  
> 2. If I remember correctly, the unbinding was monitored with quick space-time plots of the density profiles. The unbinding trajectories were discarded. This also gave me a sense of where to stop with decreasing epsilon (if there are no stable trajectories, it is over).  

**Messages from Francesco**

> Hi Sohyun, I guess you must be right about the $L_x = 240$ in 2D, as it seems to be the case also in Fig. 4. I will need to dig out the original scripts, but it seems that I clearly have used these large systems! Obviously, larger systems dampen the fluctuations, but they also take a long time to simulate...

> This looks good! I only use Ovito Basic (the license is so expensive), but you can use the Python package `Ovito` if you want to do more. We can talk about it (once I am done with the enormous amount of marking I have now!).

> I have had a look at the stored data for 2D, and I found:  
> - That the data plotted in the paper is averaged over many realisations (i.e. different seeds for the random number generator).  
> - That in 2D for high epsilon, you can see some realisations jumping up and down roughly in the range that you showed me yesterday over 1000 $\tau_r$, while others jump less. In fact, this reminded me of the difficulties we had in assessing the order of the transition in 2D: I have apparently stored many space-time plots to check the trajectories and the intermittency, but we never truly got a single simple explanation. Comparing 2D with 3D, we realised that the interfaces in 2D have a characteristic dynamics, and all the bubble formation (that we essentially do not see in 3D) triggers these instabilities. We may want to sit down with Nigel and think about it carefully: on the one hand, the peculiar large fluctuations of the 2D dynamics seem to help with the formation of the gas in the vicinity of the barrier (good for drying), but it also introduces additional timescales (e.g. the slow relaxation that I show in the quench figures in the paper).

*After this...*

> **Francesco:** Well done for managing all these initial steps. They (sub2d.sh and sub3d.sh) look good to me. Obviously, you can have more than one job running, so for 3D, you could have submitted independent epsilon runs if you wanted.

> **Me:** Oh! I wanted to be merciful to others, but I'll do it once it's very urgent!

> **Francesco:** Exactly. Do not worry about the others; the system manages that.

> **Me:** How many CPUs did you use in the past?

> **Francesco:** I was on Catalyst, which was very different in its architecture... By the way, did you check that you always have 64 cores? I do not remember if BlueCrystal always has 64 cores per node. Blue Pebble, actually, right?

> **Me:** Yes, Blue Pebble. If I copy the relevant information from Slurm:

```
Created orthogonal box = (-50 -12 -12) to (50 12 12)
  16 by 2 by 2 MPI processor grid
Created 43200 atoms
  using lattice units in orthogonal box = (-50 -12 -12) to (50 12 12)
  create_atoms CPU = 3.492 seconds
 
Loop time of 20254.7 on 64 procs for 25000000 steps with 43200 atoms
 
Performance: 533209.921 tau/day, 1234.282 timesteps/s, 53.321 Matom-step/s
99.4% CPU use with 64 MPI tasks x no OpenMP threads
```

> **Francesco:** Well, this is LAMMPS; it does not truly tell what the machine has. Some CPUs can create virtual "processes" even if the physical cores are fewer. I typed:  
> `sinfo --Node --long`  
> It seems that most have 64. Some are 48, though. Hopefully, you always get the ones you request! I'll go back to my biophysics marking, but well done on progressing.

</details>

## Winter Vacation Week 1

### 2024/12/16 Things to discuss

1. I currently set the low-density MIPS value to 0.15 for 2D and 0.45 for 3D. Can you confirm if these are correct?

2. For 3D, the liquid slab already unbinds from the wall at $\epsilon_w = 2$ (also, the time evolution of $\mathcal{A}(t)$ fluctuates so strongly; see the plot). However, in your paper, it happens when it is less than $\epsilon_w = 1$. Do you think this just happened to be the case since I only had one realisation at a specific $L_y = 24\sigma$?

3. From the time evolution of $\mathcal{A}(t)$ plot for 3D, I see that it starts to fluctuate strongly near $\epsilon_w = 18$. Was this a clue about the approximate wetting point in the paper?

4. Until the next meeting (2025/1/6), I plan to use my time to study non-equilibrium statistical mechanics and stochastic processes for three weeks.

5. Do we have any empirical data that might allow me to infer the mechanisms for drying?

6. When do you normally have annual leave in summer? My mum said she needs to know at least half a year in advance so she can buy plane tickets with her mileage.

## Week 14

### 2025/01/21 Things to Discuss

1. I've been investigating active drying. To implement a physical dipole-dipole interaction between fluid dipoles and wall dipoles, I've tried creating custom code for `pair style` that loops over fluid-wall pairs. However, I kept running into segmentation faults (e.g., `Signal: Segmentation fault (11)`) and, in the end, could not handle domain decomposition for parallel runs, so I gave up. Instead, I introduced an effective **one-body** torque, where each fluid particle entering the region is oriented outward by a cross product, $\mathbf{\mu}_i \times \hat{\mathbf{n}}$, by varying the strength of the torque. Varying that quantity also didn't 'dry off' the surface. Francesco mentioned the quadratic potential from the surface tension talk, but I wasn't particularly inspired to pursue it.

2. Instead, I started working on the critical Casimir effect. For background reading, I consulted the following:

   - Wikipedia on the Casimir effect.
   - A resource I found very helpful: [The Casimir Effect: A Force from Nothing](https://physicsworld.com/a/the-casimir-effect-a-force-from-nothing/).
   - "Casimir Effect in Active Matter System" by D. Ray, C. Reichhardt, and C. J. Olson Reichhardt. Their work is not very exciting since it's a dilute system, and it's intuitive that increasing the density of particles within the plates would put more pressure on the plates.

   Additionally, I skimmed through other papers. It became clear that the **critical** Casimir effect in active systems has not been investigated yet (at least, not that I know of). So, I designed a simulation:

   - A box of size $120 \times 60 \times 60 \, \sigma^3$, following the geometry from the paper that inspired this work.
   - Separated one centred cosine potential into two separate ones, spreading on the $y$-$z$ plane, with the $z$-direction at the edge for easier visualisation (I'll draw this on the blackboard).
   - I read your 2021 paper on 3D active Brownian bulk criticality and used $\rho = 0.94$ and $\text{Pe} = 36$. Drastically increasing the density (from 0.75 to 0.94) resulted in lost atoms errors, so I reduced the time step scale from 0.00004 to 0.00002. Comparing that phase diagram from the paper with the [temperature-density phase diagram of water](https://physicsworld.com/a/the-casimir-effect-a-force-from-nothing/) was particularly inspiring. (since Pe is like the inverse temperature).
